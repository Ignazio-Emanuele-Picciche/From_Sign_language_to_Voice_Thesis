# TTS Audio Explainability - Workflow Visuale

## ğŸ”„ ARCHITETTURA DEL SISTEMA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASE 1: INFERENZA VIDEO                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ“¹ Video Sign Language (ASLLRP)                                    â”‚
â”‚         â”‚                                                            â”‚
â”‚         â”œâ”€ Frame Extraction (8 FPS)                                 â”‚
â”‚         â”‚                                                            â”‚
â”‚         â”œâ”€ ViViT Image Processor                                    â”‚
â”‚         â”‚    â””â”€ Resize, Normalize, Tensor conversion                â”‚
â”‚         â”‚                                                            â”‚
â”‚         â”œâ”€ ViViT Model (Video Vision Transformer)                   â”‚
â”‚         â”‚    â”œâ”€ Spatial attention (per-frame)                       â”‚
â”‚         â”‚    â”œâ”€ Temporal attention (across frames)                  â”‚
â”‚         â”‚    â””â”€ Classification head                                 â”‚
â”‚         â”‚                                                            â”‚
â”‚         â””â”€ OUTPUT:                                                  â”‚
â”‚              â”œâ”€ Emotion: "Positive" | "Negative"                    â”‚
â”‚              â”œâ”€ Confidence: 0.0 - 1.0 (or 0-100%)                   â”‚
â”‚              â””â”€ Logits: [logit_positive, logit_negative]            â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FASE 2: GENERAZIONE AUDIO TTS                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ“Š Emotion + Confidence                                            â”‚
â”‚         â”‚                                                            â”‚
â”‚         â”œâ”€ [src/tts/emotion_mapper.py]                             â”‚
â”‚         â”‚    Emotion-to-Prosody Mapping                             â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚         â”‚    â”‚ Positive: rate=+15%, pitch=+8%, vol=+5%â”‚             â”‚
â”‚         â”‚    â”‚ Negative: rate=-12%, pitch=-6%, vol=-3%â”‚             â”‚
â”‚         â”‚    â”‚ Scaled by confidence                  â”‚             â”‚
â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚         â†“                                                 â”‚
â”‚         â”‚    Prosody Params: {rate, pitch, volume}                  â”‚
â”‚         â”‚                                                            â”‚
â”‚         â”œâ”€ [src/tts/text_templates.py]                             â”‚
â”‚         â”‚    Text Preparation                                        â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚         â”‚    â”‚ 1. Get caption from dataset          â”‚               â”‚
â”‚         â”‚    â”‚ 2. Clean special characters          â”‚               â”‚
â”‚         â”‚    â”‚    - Remove quotes, backticks        â”‚               â”‚
â”‚         â”‚    â”‚    - Normalize apostrophes           â”‚               â”‚
â”‚         â”‚    â”‚ 3. Return clean text                 â”‚               â”‚
â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚         â†“                                                 â”‚
â”‚         â”‚    Clean Text: "I was happy about the news"               â”‚
â”‚         â”‚                                                            â”‚
â”‚         â””â”€ [src/tts/tts_generator.py]                              â”‚
â”‚              TTS Generation                                          â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚              â”‚ Edge-TTS (Microsoft Neural Voices) â”‚                 â”‚
â”‚              â”‚                                     â”‚                 â”‚
â”‚              â”‚ 1. Convert params:                 â”‚                 â”‚
â”‚              â”‚    - pitch: % â†’ Hz (+8% â†’ +12Hz)  â”‚                 â”‚
â”‚              â”‚    - rate: float â†’ int (+14.2% â†’ +14%)â”‚              â”‚
â”‚              â”‚    - volume: float â†’ int           â”‚                 â”‚
â”‚              â”‚                                     â”‚                 â”‚
â”‚              â”‚ 2. Synthesize:                     â”‚                 â”‚
â”‚              â”‚    edge_tts.Communicate(           â”‚                 â”‚
â”‚              â”‚        text=text,                  â”‚                 â”‚
â”‚              â”‚        voice="en-US-AriaNeural",   â”‚                 â”‚
â”‚              â”‚        rate="+14%",                â”‚                 â”‚
â”‚              â”‚        pitch="+12Hz",              â”‚                 â”‚
â”‚              â”‚        volume="+4%"                â”‚                 â”‚
â”‚              â”‚    )                               â”‚                 â”‚
â”‚              â”‚                                     â”‚                 â”‚
â”‚              â”‚ 3. Save to file                    â”‚                 â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                   â†“                                                 â”‚
â”‚              ğŸ”Š Audio File (.mp3)                                   â”‚
â”‚                 results/tts_audio/generated/                         â”‚
â”‚                 {video_name}_{emotion}.mp3                          â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FASE 3: AUDIO EXPLAINABILITY & VALIDATION                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ”Š Generated Audio + ğŸ“Š Target Prosody                             â”‚
â”‚         â”‚                                                            â”‚
â”‚         â”œâ”€ [src/explainability/audio/acoustic_analyzer.py]         â”‚
â”‚         â”‚    Feature Extraction                                      â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚         â”‚    â”‚ Praat-Parselmouth:                  â”‚                â”‚
â”‚         â”‚    â”‚  â”œâ”€ Pitch (F0): mean, std, range   â”‚                â”‚
â”‚         â”‚    â”‚  â”œâ”€ Jitter: pitch variability      â”‚                â”‚
â”‚         â”‚    â”‚  â”œâ”€ Shimmer: amplitude variability â”‚                â”‚
â”‚         â”‚    â”‚  â””â”€ HNR: harmonic-to-noise ratio   â”‚                â”‚
â”‚         â”‚    â”‚                                     â”‚                â”‚
â”‚         â”‚    â”‚ Librosa:                            â”‚                â”‚
â”‚         â”‚    â”‚  â”œâ”€ Energy: RMS, mean, std, max    â”‚                â”‚
â”‚         â”‚    â”‚  â”œâ”€ Rate: onset detection*         â”‚                â”‚
â”‚         â”‚    â”‚  â””â”€ Duration: total length         â”‚                â”‚
â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â”‚         â†“                                                 â”‚
â”‚         â”‚    Features: {pitch_hz, energy_db, rate_syll_sec}         â”‚
â”‚         â”‚                                                            â”‚
â”‚         â”œâ”€ [src/explainability/audio/prosody_validator.py]         â”‚
â”‚         â”‚    Validation                                              â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚         â”‚    â”‚ 1. Compare generated vs baseline   â”‚                â”‚
â”‚         â”‚    â”‚ 2. Calculate delta percentages     â”‚                â”‚
â”‚         â”‚    â”‚ 3. Compare with target params      â”‚                â”‚
â”‚         â”‚    â”‚ 4. Compute accuracy metrics        â”‚                â”‚
â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â”‚         â†“                                                 â”‚
â”‚         â”‚    Validation Report:                                     â”‚
â”‚         â”‚      {pitch_accuracy, rate_accuracy*, volume_accuracy}    â”‚
â”‚         â”‚                                                            â”‚
â”‚         â””â”€ [src/analysis/run_analysis.py]                          â”‚
â”‚              Statistical Analysis                                    â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚              â”‚ 1. Collect all features (n=200)    â”‚                â”‚
â”‚              â”‚                                     â”‚                â”‚
â”‚              â”‚ 2. Group by emotion:                â”‚                â”‚
â”‚              â”‚    - Positive: n=160                â”‚                â”‚
â”‚              â”‚    - Negative: n=40                 â”‚                â”‚
â”‚              â”‚                                     â”‚                â”‚
â”‚              â”‚ 3. Descriptive statistics:          â”‚                â”‚
â”‚              â”‚    - Mean, Std, Min, Max            â”‚                â”‚
â”‚              â”‚                                     â”‚                â”‚
â”‚              â”‚ 4. Statistical tests:               â”‚                â”‚
â”‚              â”‚    - Shapiro-Wilk (normality)      â”‚                â”‚
â”‚              â”‚    - Independent t-test            â”‚                â”‚
â”‚              â”‚    - Cohen's d (effect size)       â”‚                â”‚
â”‚              â”‚                                     â”‚                â”‚
â”‚              â”‚ 5. Visualizations:                  â”‚                â”‚
â”‚              â”‚    - Box plots                      â”‚                â”‚
â”‚              â”‚    - Swarm plots                    â”‚                â”‚
â”‚              â”‚    - Statistical summary            â”‚                â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                   â†“                                                 â”‚
â”‚              ğŸ“Š Results:                                            â”‚
â”‚                 - audio_analysis_results.csv                         â”‚
â”‚                 - emotion_comparison_plots.png                       â”‚
â”‚                 - statistical_report.txt                             â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    âœ… VALIDAZIONE COMPLETA

              Pitch: p<0.001*** (Significant!)
              Cohen's d = 0.637 (Medium effect)

              â†’ Sistema funziona correttamente âœ“

* Note: Speaking rate non funziona su audio TTS (limitazione tecnica)
```

---

## ğŸ“ FILE MAPPING

```
test_golden_labels_vivit.py  â”€â”€â”
                               â”œâ”€â†’ [FASE 1] Video â†’ Emotion
video_dataset.py              â”€â”˜

emotion_mapper.py            â”€â”€â”
text_templates.py            â”€â”€â”¼â”€â†’ [FASE 2] Emotion â†’ Audio
tts_generator.py             â”€â”€â”˜

acoustic_analyzer.py         â”€â”€â”
prosody_validator.py         â”€â”€â”¼â”€â†’ [FASE 3] Audio â†’ Validation
audio_comparison.py          â”€â”€â”¤
statistical_tests.py         â”€â”€â”¤
run_analysis.py              â”€â”€â”˜

analyze_golden_labels_audio.sh â†’ [SHORTCUT] Run all analysis
```

---

## ğŸ”¢ DATA FLOW

```
Input:
  Video: 256351.mp4 (sign language)
  Golden Label: "Positive"
  Caption: "I was like, "Oh, wow, that`s fine.""

â†“ FASE 1: ViViT Inference

Output:
  Predicted: "Positive"
  Confidence: 0.923 (92.3%)

â†“ FASE 2: TTS Generation

Intermediate:
  Prosody: {rate: "+13.8%", pitch: "+7.4%", volume: "+4.6%"}
  Clean Text: "I was like, Oh, wow, that's fine."

Output:
  Audio: 256351_positive.mp3
  Duration: 2.8 seconds
  Size: ~220 KB

â†“ FASE 3: Analysis

Features Extracted:
  Pitch: 221.5 Hz
  Energy: -28.3 dB
  Rate: 0.0 syll/sec*

Validation:
  Target pitch: +8% â†’ Measured: +7.4% â†’ Accuracy: 92.5%

Statistical Analysis (across all n=200):
  Positive pitch: 219.7 Â± 8.9 Hz
  Negative pitch: 214.0 Â± 8.7 Hz
  Difference: +2.6% (p<0.001***)

Final Output:
  âœ… Sistema valido: Differenze significative rilevate
```

---

## ğŸ¯ DECISION TREE: "Quando Usare Quale Parte?"

```
Vuoi...

â”œâ”€ Classificare nuovi video?
â”‚  â””â”€â†’ Usa: test_golden_labels_vivit.py (senza --generate_tts)
â”‚
â”œâ”€ Generare audio da video?
â”‚  â””â”€â†’ Usa: test_golden_labels_vivit.py --generate_tts
â”‚
â”œâ”€ Generare audio standalone (senza video)?
â”‚  â””â”€â†’ Usa: src/tts/tts_generator.py direttamente
â”‚      Example:
â”‚        from src.tts.tts_generator import generate_emotional_audio
â”‚        generate_emotional_audio("Positive", 0.95, "test", "output/", caption="Hello")
â”‚
â”œâ”€ Analizzare audio giÃ  generati?
â”‚  â””â”€â†’ Usa: ./analyze_golden_labels_audio.sh
â”‚      O: python src/analysis/run_analysis.py --audio_dir <path>
â”‚
â”œâ”€ Test veloce (pochi sample)?
â”‚  â””â”€â†’ Genera 8 audio manualmente + run_analysis.py
â”‚
â”œâ”€ Modificare parametri prosodici?
â”‚  â””â”€â†’ Edita: src/tts/emotion_mapper.py (PROSODY_MAPPING)
â”‚
â”œâ”€ Cambiare voce TTS?
â”‚  â””â”€â†’ Edita: src/tts/tts_generator.py (DEFAULT_VOICE)
â”‚      Opzioni: en-US-AriaNeural, en-US-GuyNeural, etc.
â”‚
â””â”€ Aggiungere nuove features acustiche?
   â””â”€â†’ Edita: src/explainability/audio/acoustic_analyzer.py
```

---

## ğŸ”§ TROUBLESHOOTING VISUALE

```
Problema: "Audio dice 'quote', 'slash', 'backtick'"
  â†“
Causa: Caratteri speciali nel caption
  â†“
Dove guardare: src/tts/text_templates.py
  â†“
Funzione: clean_text_for_tts()
  â†“
Fix: âœ… GiÃ  implementato
  â”œâ”€ Rimuove: " ' ` / \ | [ ] { } < > _ * # @ &
  â””â”€ Normalizza spazi e apostrofi

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Problema: "Speaking rate sempre 0.0"
  â†“
Causa: Onset detection (librosa) non funziona su TTS
  â†“
Dove guardare: src/explainability/audio/acoustic_analyzer.py
  â†“
Funzione: extract_rate_features()
  â†“
Fix: âŒ Limitazione tecnica
  â””â”€ Soluzione: Usa solo pitch ed energy

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Problema: "Edge-TTS error: Invalid pitch '+7%'"
  â†“
Causa: Pitch deve essere in Hz, non percentuale
  â†“
Dove guardare: src/tts/tts_generator.py
  â†“
Funzione: convert_pitch_to_hz()
  â†“
Fix: âœ… GiÃ  implementato
  â””â”€ Converte: +8% â†’ +12Hz (baseline 150Hz)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Problema: "p-value non significativo"
  â†“
Possibili cause:
  â”œâ”€ Sample size troppo piccolo (n<30)
  â”œâ”€ Alta variabilitÃ  intra-gruppo
  â”œâ”€ Effect size realmente piccolo
  â””â”€ Dataset sbilanciato
  â†“
Soluzioni:
  â”œâ”€ Aumenta n (genera piÃ¹ audio)
  â”œâ”€ Aumenta parametri prosodici (+25% invece di +15%)
  â”œâ”€ Bilancia dataset (50% Positive, 50% Negative)
  â””â”€ Riporta come limitazione in tesi
```

---

## ğŸ“Š PERFORMANCE METRICS FLOW

```
Generated Audio (n=200)
        â”‚
        â”œâ”€ Feature Extraction
        â”‚    â”œâ”€ Pitch: 5-10 sec/file
        â”‚    â”œâ”€ Energy: 1-2 sec/file
        â”‚    â””â”€ Rate: 2-3 sec/file*
        â”‚
        â”œâ”€ Statistical Tests
        â”‚    â”œâ”€ Shapiro-Wilk: <1 sec
        â”‚    â”œâ”€ t-test: <1 sec
        â”‚    â””â”€ Cohen's d: <1 sec
        â”‚
        â””â”€ Visualization
             â”œâ”€ Box plots: 5-10 sec
             â””â”€ Save PNG: 1-2 sec

Total Time: ~20-30 min for 200 files

* Rate detection attempts but returns 0
```

---

## ğŸ“ THESIS INTEGRATION FLOWCHART

```
Thesis Chapter/Section
        â”‚
        â”œâ”€ Introduction
        â”‚    â””â”€ Mention: Multimodal emotion transfer (sign â†’ speech)
        â”‚
        â”œâ”€ Related Work
        â”‚    â”œâ”€ Sign language emotion recognition
        â”‚    â”œâ”€ TTS with emotion
        â”‚    â””â”€ Audio explainability (novel contribution)
        â”‚
        â”œâ”€ Methodology
        â”‚    â”œâ”€ 3.1: ViViT for emotion classification
        â”‚    â”œâ”€ 3.2: Emotion-to-Prosody mapping
        â”‚    â”œâ”€ 3.3: TTS generation (Edge-TTS)
        â”‚    â””â”€ 3.4: Audio explainability framework â† NEW SECTION
        â”‚         â”œâ”€ Acoustic feature extraction
        â”‚         â”œâ”€ Statistical validation
        â”‚         â””â”€ Implementation details
        â”‚
        â”œâ”€ Results
        â”‚    â”œâ”€ 4.1: ViViT classification results
        â”‚    â”œâ”€ 4.2: TTS generation results (200 audio files)
        â”‚    â””â”€ 4.3: Audio explainability results â† NEW SECTION
        â”‚         â”œâ”€ TABLE: Descriptive statistics
        â”‚         â”œâ”€ FIGURE: Box plots comparison
        â”‚         â”œâ”€ TABLE: Statistical test results
        â”‚         â””â”€ TEXT: Interpretation
        â”‚
        â”œâ”€ Discussion
        â”‚    â”œâ”€ Validation successful (p<0.001 for pitch)
        â”‚    â”œâ”€ Limitations (speaking rate, dataset imbalance)
        â”‚    â””â”€ Practical implications
        â”‚
        â””â”€ Conclusion & Future Work
             â”œâ”€ Novel contribution validated
             â”œâ”€ Suggestions: neural TTS, more emotions, balanced dataset
             â””â”€ Applications: accessibility, assistive tech
```

---

**Ultimo aggiornamento**: 23 Ottobre 2025  
**Autore**: Ignazio Emanuele Picciche
