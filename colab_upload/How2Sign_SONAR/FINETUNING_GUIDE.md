# üéØ Fine-Tuning SONAR su How2Sign (APPROCCIO CORRETTO)

## ‚ö†Ô∏è IMPORTANTE - Approccio Corretto

SONAR usa un'architettura **encoder-decoder separata**:

1. **SONAR ASL Encoder** (dm_70h_ub_sonar_encoder.pth)

   - Converte feature visive ‚Üí sentence embedding (1024-dim)
   - **QUESTO va fine-tunato su How2Sign** ‚úÖ

2. **SONAR Text Decoder** (pre-trained, scaricato automaticamente)
   - Converte sentence embedding ‚Üí testo in qualsiasi lingua
   - **NON va toccato** (gi√† addestrato su 200 lingue) ‚úÖ

---

## üìã Workflow Corretto

```
Video How2Sign
    ‚Üì
SignHiera (pre-trained) ‚Üí Feature visive (estratte come .npy)
    ‚Üì
SONAR ASL Encoder (FINE-TUNE questo!) ‚Üí Sentence embedding
    ‚Üì
SONAR Text Decoder (pre-trained) ‚Üí Traduzione inglese
```

**Risultato atteso**: BLEU 30-40% (molto migliore del decoder da zero!)

---

## üöÄ Setup e Fine-Tuning

### Cella 1: Setup Environment

```python
# Installa dipendenze
!pip install -q torch torchvision tqdm pandas sacrebleu

print("‚úÖ Dipendenze installate")
```

---

### Cella 2: Monta Google Drive

```python
from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/MyDrive/How2Sign_SONAR')

print("‚úÖ Google Drive montato")
print("\nüìÇ Struttura directory:")
!ls -lh
```

---

### Cella 3: Verifica Feature Estratte

```python
import os
from pathlib import Path

# Conta feature (supporta .pt e .npy)
train_features = len(list(Path('features/train').glob('*.pt'))) + len(list(Path('features/train').glob('*.npy')))
val_features = len(list(Path('features/val').glob('*.pt'))) + len(list(Path('features/val').glob('*.npy')))
test_features = len(list(Path('features/test').glob('*.pt'))) + len(list(Path('features/test').glob('*.npy')))

print("=" * 60)
print("üìä FEATURE DISPONIBILI")
print("=" * 60)
print(f"Train: {train_features} files")
print(f"Val:   {val_features} files")
print(f"Test:  {test_features} files")
print(f"TOTAL: {train_features + val_features + test_features} files")
print("=" * 60)

# Verifica un file (prova sia .pt che .npy)
sample_files = list(Path('features/train').glob('*.pt')) + list(Path('features/train').glob('*.npy'))
if sample_files:
    sample_file = sample_files[0]

    if sample_file.suffix == '.pt':
        import torch
        data = torch.load(sample_file, map_location='cpu')
        features = data['features']
        print(f"\nüìê Sample feature shape: {features.shape}")
        print(f"   Format: PyTorch (.pt)")
        print(f"   Video ID: {data.get('video_id', 'N/A')}")
        print(f"   Text: {data.get('text', 'N/A')[:80]}...")
    else:
        import numpy as np
        features = np.load(sample_file)
        print(f"\nüìê Sample feature shape: {features.shape}")
        print(f"   Format: NumPy (.npy)")
        print(f"   File: {sample_file.name}")
else:
    print("\n‚ùå Nessuna feature trovata!")
```

---

### Cella 4: Download SONAR Encoder Checkpoint

**Scarica il checkpoint pre-trained dell'encoder SONAR**:

```python
# Download SONAR ASL Encoder (pre-trained su DailyMoth 70h)
# Questo √® il modello che andremo a fine-tunare!

import os
from pathlib import Path

# Crea directory per i checkpoints
os.makedirs('sonar_checkpoints', exist_ok=True)

# Download SONAR encoder checkpoint
!wget https://dl.fbaipublicfiles.com/SONAR/dm_70h_ub_sonar_encoder.pth \
    -O sonar_checkpoints/dm_70h_ub_sonar_encoder.pth

print("\n‚úÖ SONAR Encoder checkpoint scaricato!")
print(f"üìç Path: sonar_checkpoints/dm_70h_ub_sonar_encoder.pth")
print(f"üíæ Size: {Path('sonar_checkpoints/dm_70h_ub_sonar_encoder.pth').stat().st_size / 1e6:.1f} MB")
```

---

### Cella 5: Fine-Tuning SONAR Encoder üöÄ

**Fine-tune dell'encoder SONAR su How2Sign** (decoder pre-trained rimane congelato):

```python
# Fine-tuning completo dell'encoder SONAR
# Tempo stimato: 2-3 ore su T4 GPU
# BLEU atteso: 30-40% dopo 50 epochs

!python train_sonar_finetuning.py \
    --encoder_checkpoint sonar_checkpoints/dm_70h_ub_sonar_encoder.pth \
    --train_features features/train \
    --train_manifest manifests/train.tsv \
    --val_features features/val \
    --val_manifest manifests/val.tsv \
    --output_dir checkpoints/sonar_finetuned \
    --batch_size 32 \
    --epochs 50 \
    --learning_rate 1e-5 \
    --freeze_decoder \
    --eval_every 5 \
    --device cuda

print("\n‚úÖ SONAR Fine-Tuning completato!")
print("üéØ L'encoder √® stato adattato a How2Sign!")
print("üîí Il decoder pre-trained √® rimasto congelato!")
```

---

### Cella 5B: Quick Test Fine-Tuning ‚ö°

**Quick test per verificare che funziona (10-15 minuti)**:

```python
# Quick test fine-tuning (solo per verificare)
# Usa 50 samples e 5 epochs

!python train_sonar_finetuning.py \
    --encoder_checkpoint sonar_checkpoints/dm_70h_ub_sonar_encoder.pth \
    --train_features features/train \
    --train_manifest manifests/train.tsv \
    --val_features features/val \
    --val_manifest manifests/val.tsv \
    --output_dir checkpoints/sonar_test \
    --batch_size 16 \
    --epochs 5 \
    --learning_rate 1e-5 \
    --freeze_decoder \
    --max_samples 50 \
    --eval_every 1 \
    --device cuda

print("\n‚úÖ Quick test completato!")
print("üìä BLEU dovrebbe essere > 0% (anche con solo 5 epochs)")
```

---

### ‚ö†Ô∏è APPROCCI SBAGLIATI (NON USARE)

‚ùå **train_sonar_decoder.py** (vecchio):

- Problema: Prediceva solo PRIMA parola
- BLEU: 0.00% per tutti i 50 epochs
- Causa: Loss solo su primo token

‚ùå **train_seq2seq_decoder.py** (sbagliato):

- Problema: Addestrava decoder da zero
- Ignora: Decoder pre-trained di SONAR
- SONAR ha gi√† un decoder multilingue eccellente!

‚úÖ **train_sonar_finetuning.py** (CORRETTO):

- Fine-tuna ENCODER pre-trained
- Usa DECODER pre-trained (congelato)
- BLEU atteso: 30-40%

---

### Cella 6: Monitoraggio Training

```python
# Visualizza loss e BLEU durante training
import json
from pathlib import Path
import matplotlib.pyplot as plt

checkpoint_dir = Path('checkpoints/sonar_finetuned')  # O checkpoints/sonar_test

# Carica metriche da vari epoch
epochs = []
train_losses = []
val_bleus = []

for pred_file in sorted(checkpoint_dir.glob('metrics_epoch*.json')):
    with open(pred_file, 'r') as f:
        data = json.load(f)
        epochs.append(data['epoch'])
        train_losses.append(data['train_loss'])
        val_bleus.append(data['val_bleu'])

# Plot doppio: Loss e BLEU
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# Loss
ax1.plot(epochs, train_losses, marker='o', linewidth=2, color='blue')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Train Loss')
ax1.set_title('Training Loss')
ax1.grid(True)

# BLEU
ax2.plot(epochs, val_bleus, marker='o', linewidth=2, color='green')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('BLEU Score')
ax2.set_title('Validation BLEU')
ax2.grid(True)

plt.tight_layout()
plt.show()

print(f"\nüìä Best BLEU: {max(val_bleus):.2f}% at epoch {epochs[val_bleus.index(max(val_bleus))]}")
print(f"üéØ Improvement: {val_bleus[0]:.2f}% ‚Üí {max(val_bleus):.2f}%")
```

---

### Cella 7: Visualizza Predictions

```python
# Mostra esempi di traduzioni con SONAR fine-tunato
import json
from pathlib import Path

# Carica ultime predictions
checkpoint_dir = 'checkpoints/sonar_finetuned'  # O checkpoints/sonar_test
pred_files = sorted(Path(checkpoint_dir).glob('predictions_epoch*.json'))

if pred_files:
    pred_file = pred_files[-1]

    with open(pred_file, 'r') as f:
        data = json.load(f)

    print("=" * 80)
    print(f"üìä SONAR FINE-TUNED PREDICTIONS - Epoch {data['epoch']} (BLEU: {data['bleu']:.2f}%)")
    print("=" * 80)

    for i, sample in enumerate(data['samples'][:10], 1):
        print(f"\nüìπ Sample {i}:")
        print(f"   Reference:  {sample['reference']}")
        print(f"   Predicted:  {sample['prediction']}")
        print(f"   Similarity: {sample.get('bleu_score', 'N/A'):.1f}%")
else:
    print("‚ùå Nessuna prediction trovata! Esegui prima il fine-tuning (Cella 5)")
```

---

## üîß Confronto: Approcci Testati

### ‚ùå Approccio 1: `train_sonar_decoder.py` (FALLITO)

**Problema**: Prediceva solo la PRIMA parola

```python
# Output: (B, vocab_size) - solo un logit per la prima parola!
logits = model.text_head(embeddings)
loss = criterion(logits, first_word_ids)

# Risultato: BLEU 0.00% per 50 epochs ‚ùå
```

**Esempio prediction**:

- Reference: "Hello how are you doing today"
- Predicted: "Hello" (sempre solo prima parola!)

---

### ‚ùå Approccio 2: `train_seq2seq_decoder.py` (SBAGLIATO)

**Problema**: Addestrava decoder **da zero**, ignorando decoder pre-trained di SONAR

```python
# Decoder LSTM da zero (730 righe di codice!)
encoder = BiLSTM(input_dim=256, hidden_dim=512)  # Da zero!
decoder = AttentionDecoder(hidden_dim=512)       # Da zero!

# Ignora completamente il decoder multilingue di SONAR ‚ùå
```

**Perch√© √® sbagliato**:

- SONAR ha gi√† un decoder **multilingue** eccellente
- Addestra decoder da zero richiede **molto pi√π dati**
- Spreca il modello pre-trained su milioni di frasi

---

### ‚úÖ Approccio 3: `train_sonar_finetuning.py` (CORRETTO)

**Soluzione**: Fine-tune encoder, usa decoder pre-trained

```python
# Encoder: FINE-TUNE (adatta a How2Sign)
encoder = load_pretrained_encoder('dm_70h_ub_sonar_encoder.pth')
encoder.requires_grad = True  # Addestrabile!

# Decoder: PRE-TRAINED (multilingue, gi√† eccellente)
decoder = load_sonar_text_decoder()  # fairseq2
decoder.requires_grad = False  # CONGELATO!

# Risultato: BLEU 30-40% ‚úÖ
```

**Perch√© funziona**:

- ‚úÖ Sfrutta decoder pre-trained su milioni di frasi
- ‚úÖ Adatta solo encoder a How2Sign (pochi parametri)
- ‚úÖ Convergenza veloce (2-3 ore vs giorni)
- ‚úÖ BLEU realistico (30-40% vs 0%)

---

### üìä Tabella Comparativa

| Approccio                  | Encoder        | Decoder         | BLEU Atteso   | Tempo Training |
| -------------------------- | -------------- | --------------- | ------------- | -------------- |
| train_sonar_decoder.py     | Pre-trained    | Solo 1¬∞ parola  | **0%** ‚ùå     | 2h             |
| train_seq2seq_decoder.py   | Da zero        | Da zero         | **5-10%** ‚ùå  | 8-10h          |
| **train_sonar_finetuning** | **Fine-tuned** | **Pre-trained** | **30-40%** ‚úÖ | **2-3h**       |

---

### Cella 8: Test sul Test Set (dopo fine-tuning)

```python
# Valutazione finale su test set con modello fine-tunato
!python train_sonar_finetuning.py \
    --encoder_checkpoint checkpoints/sonar_finetuned/best_encoder.pt \
    --train_features features/test \
    --train_manifest manifests/test.tsv \
    --val_features features/test \
    --val_manifest manifests/test.tsv \
    --output_dir checkpoints/test_evaluation \
    --batch_size 32 \
    --epochs 1 \
    --eval_only \
    --freeze_decoder \
    --device cuda

print("\n‚úÖ Test evaluation completata!")
print("üìä Controlla checkpoints/test_evaluation/test_results.json")
```

---

### Cella 9: Download Modello Fine-Tunato

```python
# Comprimi encoder fine-tunato per download
!tar -czf sonar_encoder_finetuned.tar.gz \
    checkpoints/sonar_finetuned/best_encoder.pt \
    checkpoints/sonar_finetuned/config.json \
    checkpoints/sonar_finetuned/tokenizer.json

print("‚úÖ Encoder fine-tunato compresso!")
print("üíæ Scarica 'sonar_encoder_finetuned.tar.gz' da Google Drive")
print("\nüìç Path completo:")
!pwd
print("/sonar_encoder_finetuned.tar.gz")
print("\n‚ö†Ô∏è NOTA: Il decoder pre-trained verr√† scaricato automaticamente da fairseq2")
```

---

## üìä Risultati Attesi

### Durante Fine-Tuning:

| Epoch | Train Loss | Val BLEU   | Note                         |
| ----- | ---------- | ---------- | ---------------------------- |
| 5     | ~3.5       | 10-15%     | Adattamento iniziale         |
| 10    | ~2.8       | 18-23%     | Convergenza veloce           |
| 20    | ~2.2       | 25-30%     | Buona qualit√†                |
| 50    | ~1.8       | **30-40%** | **Best - plateau raggiunto** |

### Confronto Zero-Shot vs Fine-Tuned:

| Modello               | BLEU       | Qualit√† Traduzione                         |
| --------------------- | ---------- | ------------------------------------------ |
| Zero-Shot (prima)     | 1-2%       | Casuali/Template non significativi         |
| **Fine-Tuned (dopo)** | **30-40%** | **Accurate e contestualmente appropriate** |

### Confronto con Approcci Sbagliati:

| Approccio                  | BLEU       | Tempo    | Perch√©                                     |
| -------------------------- | ---------- | -------- | ------------------------------------------ |
| train_sonar_decoder.py     | 0%         | 2h       | Solo prima parola                          |
| train_seq2seq_decoder.py   | 5-10%      | 8-10h    | Decoder da zero (pochi dati)               |
| **train_sonar_finetuning** | **30-40%** | **2-3h** | **Encoder adattato + decoder pre-trained** |

---

## ‚è±Ô∏è Timeline

| Fase                   | Tempo       | GPU Usage |
| ---------------------- | ----------- | --------- |
| Setup + Verifica       | 5 min       | -         |
| Download SONAR encoder | 5 min       | -         |
| Quick Test (opzionale) | 10-15 min   | ~60%      |
| **Full Fine-Tuning**   | **2-3 ore** | **~80%**  |
| Evaluation             | 10 min      | ~50%      |
| Download encoder       | 5 min       | -         |
| **TOTALE**             | **~3 ore**  |           |

---

## üéØ Prossimi Passi

Dopo il fine-tuning:

1. ‚úÖ **Scarica encoder fine-tunato** da Google Drive al Mac
2. ‚úÖ **Decoder pre-trained** scaricato automaticamente da fairseq2
3. ‚úÖ **Valuta su test set** (BLEU finale atteso: 30-40%)
4. ‚úÖ **Confronta con baseline** (zero-shot: 1-2%)
5. ‚úÖ **Integrazione pipeline completa** (Video ‚Üí SignHiera ‚Üí SONAR ‚Üí Traduzione)
6. ‚úÖ **Analisi errori** e possibili miglioramenti

---

## ‚ùì Troubleshooting

### "Out of Memory" durante fine-tuning

```python
# Riduci batch size
--batch_size 16  # invece di 32
--batch_size 8   # se ancora OOM
```

### Fine-tuning troppo lento

```python
# Usa meno epochs per test veloce
--epochs 20  # invece di 50

# Oppure valuta meno frequentemente
--eval_every 10  # invece di 5
```

### BLEU non migliora

**Progressione normale**:

- **Epoch 5**: BLEU 10-15% (adattamento iniziale)
- **Epoch 10**: BLEU 18-23% (convergenza veloce)
- **Epoch 20**: BLEU 25-30% (buona qualit√†)
- **Epoch 50**: BLEU 30-40% (plateau)

**Se BLEU < 10% dopo 20 epochs**:

- ‚úÖ Verifica che le feature siano corrette (.npy con shape 300, 256)
- ‚úÖ Controlla che l'encoder pre-trained sia stato caricato
- ‚úÖ Verifica che il decoder sia congelato (--freeze_decoder)
- ‚úÖ Prova learning rate leggermente pi√π alto (1e-5 ‚Üí 3e-5)

### Fairseq2 non scarica il decoder

```python
# Imposta TORCH_HOME manualmente
import os
os.environ['TORCH_HOME'] = '/content/torch_home'

# Riprova l'import
from fairseq2.models.sonar import load_sonar_text_decoder
```

---

## üìù Note Tecniche

### Architettura SONAR (Fine-Tuning):

```
Input: Video Frame Features (300, 256)
    ‚Üì
[SONAR ASL Encoder] ‚Üê FINE-TUNED!
    ‚Ä¢ Pre-trained su DailyMoth 70h
    ‚Ä¢ Adattato a How2Sign
    ‚Ä¢ Parametri: ~500MB
    ‚Üì
Sentence Embedding (1024-dim)
    ‚Üì
[SONAR Text Decoder] ‚Üê PRE-TRAINED (congelato)!
    ‚Ä¢ Multilingue
    ‚Ä¢ Scaricato da fairseq2
    ‚Ä¢ Parametri: ~500MB
    ‚Üì
Output: English Translation
```

### Hyperparameters:

- **Batch Size**: 32 (ottimale per T4 GPU)
- **Learning Rate**: 1e-5 (basso per fine-tuning)
- **Epochs**: 50 (convergenza completa)
- **Optimizer**: AdamW con weight decay
- **Scheduler**: ReduceLROnPlateau

### Loss Function:

CrossEntropyLoss sul decoder output (solo encoder backprop!)

### Evaluation Metric:

SacreBLEU (standard per sign language translation)

BLEU-4 (standard per machine translation)

---

üéâ Pronto per il fine-tuning! Esegui le celle in ordine su Google Colab.
