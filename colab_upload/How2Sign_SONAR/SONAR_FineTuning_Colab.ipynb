{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906737bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ Training Completato!\n",
    "\n",
    "### ğŸ“‹ Checklist Finale:\n",
    "\n",
    "- âœ… Dataset verificato (features + manifests)\n",
    "- âœ… fairseq2 installato correttamente\n",
    "- âœ… Quick test eseguito (5 epochs)\n",
    "- âœ… Training completo (50 epochs)\n",
    "- âœ… BLEU score calcolato su validation set\n",
    "- âœ… Checkpoint salvati e backuppati\n",
    "- âœ… Risultati visualizzati e analizzati\n",
    "\n",
    "### ğŸ¯ Prossimi Passi:\n",
    "\n",
    "1. **Test su Test Set**: Esegui inferenza su `manifests/test.tsv`\n",
    "2. **Confronto Modelli**: Compara con baseline e altri approcci\n",
    "3. **Error Analysis**: Analizza predizioni errate per miglioramenti\n",
    "4. **Deployment**: Prepara modello per utilizzo in produzione\n",
    "\n",
    "### ğŸ“Š BLEU Score Atteso:\n",
    "\n",
    "- **Target**: 30-40% BLEU\n",
    "- **Baseline**: ~0% (approcci naive)\n",
    "- **SOTR paper**: ~35% BLEU su How2Sign\n",
    "\n",
    "---\n",
    "\n",
    "**Fine del Notebook** ğŸ“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de296da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Crea backup directory con timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_dir = Path(f\"backups/sonar_full_{timestamp}\")\n",
    "backup_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ’¾ BACKUP CHECKPOINTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Files da backuppare\n",
    "files_to_backup = [\n",
    "    \"checkpoints/sonar_full_finetuned/best_model.pt\",\n",
    "    \"checkpoints/sonar_full_finetuned/training_log.json\",\n",
    "    \"checkpoints/sonar_full_finetuned/training_curves.png\",\n",
    "    \"results_validation.json\",\n",
    "    \"results_validation.csv\",\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“‚ Backup directory: {backup_dir}\\n\")\n",
    "\n",
    "for file_path in files_to_backup:\n",
    "    src = Path(file_path)\n",
    "    if src.exists():\n",
    "        dst = backup_dir / src.name\n",
    "        shutil.copy2(src, dst)\n",
    "        size_mb = dst.stat().st_size / (1024 * 1024)\n",
    "        print(f\"âœ… {src.name:<30} ({size_mb:>6.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  {src.name:<30} (NOT FOUND)\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Backup completato in: {backup_dir}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e62e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9ï¸âƒ£ Backup Checkpoints su Drive\n",
    "\n",
    "Assicurati di salvare i checkpoint migliori!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Carica risultati inferenza\n",
    "results_path = Path(\"results_validation.json\")\n",
    "\n",
    "if results_path.exists():\n",
    "    with open(results_path, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ğŸ“Š RISULTATI VALIDATION SET\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    print(f\"\\nğŸ¯ Metriche Globali:\")\n",
    "    print(f\"   BLEU Score: {results.get('bleu', 'N/A'):.2f}%\")\n",
    "    print(f\"   Samples: {results.get('n_samples', 'N/A')}\")\n",
    "\n",
    "    # Mostra sample predictions\n",
    "    if \"predictions\" in results:\n",
    "        print(f\"\\nğŸ“ Sample Predictions (primi 10):\")\n",
    "        print(\"â”€\" * 70)\n",
    "\n",
    "        df = pd.DataFrame(results[\"predictions\"][:10])\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            print(f\"\\n{idx+1}. Video: {row['video_id']}\")\n",
    "            print(f\"   Reference:  {row['reference']}\")\n",
    "            print(f\"   Prediction: {row['prediction']}\")\n",
    "            print(f\"   {'â”€' * 66}\")\n",
    "\n",
    "        # Salva tutti i risultati in CSV\n",
    "        df_full = pd.DataFrame(results[\"predictions\"])\n",
    "        csv_path = \"results_validation.csv\"\n",
    "        df_full.to_csv(csv_path, index=False)\n",
    "        print(f\"\\nğŸ’¾ Tutti i risultati salvati in: {csv_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "else:\n",
    "    print(f\"âŒ File risultati non trovato: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e7750",
   "metadata": {},
   "source": [
    "### ğŸ“Š Analisi Predizioni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726af2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esegui inferenza su validation set completo\n",
    "!python run_inference.py \\\n",
    "    --checkpoint checkpoints/sonar_full_finetuned/best_model.pt \\\n",
    "    --features_dir features/val \\\n",
    "    --manifest manifests/val.tsv \\\n",
    "    --output results_validation.json \\\n",
    "    --batch_size 32 \\\n",
    "    --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa055ef2",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Test Inference su Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Carica best model\n",
    "checkpoint_path = Path(\"checkpoints/sonar_full_finetuned/best_model.pt\")\n",
    "log_path = Path(\"checkpoints/sonar_full_finetuned/training_log.json\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“Š RISULTATI FINALI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "    print(f\"\\nğŸ† BEST MODEL:\")\n",
    "    print(f\"   Checkpoint: {checkpoint_path}\")\n",
    "    print(f\"   Epoch: {ckpt.get('epoch', 'N/A')}\")\n",
    "    print(f\"   BLEU Score: {ckpt.get('val_bleu', 0):.2f}%\")\n",
    "    print(\n",
    "        f\"   Train Loss: {ckpt.get('train_loss', 'N/A'):.4f}\"\n",
    "        if \"train_loss\" in ckpt\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    # Plot training curves\n",
    "    if log_path.exists():\n",
    "        with open(log_path, \"r\") as f:\n",
    "            log = json.load(f)\n",
    "\n",
    "        epochs = [e[\"epoch\"] for e in log]\n",
    "        bleus = [e.get(\"val_bleu\", 0) for e in log]\n",
    "        losses = [e.get(\"train_loss\", 0) for e in log]\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "        # BLEU curve\n",
    "        ax1.plot(epochs, bleus, \"b-o\", linewidth=2, markersize=6)\n",
    "        ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
    "        ax1.set_ylabel(\"BLEU Score (%)\", fontsize=12)\n",
    "        ax1.set_title(\"Validation BLEU Score\", fontsize=14, fontweight=\"bold\")\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.axhline(\n",
    "            y=max(bleus),\n",
    "            color=\"r\",\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.5,\n",
    "            label=f\"Best: {max(bleus):.2f}%\",\n",
    "        )\n",
    "        ax1.legend()\n",
    "\n",
    "        # Loss curve\n",
    "        ax2.plot(epochs, losses, \"r-o\", linewidth=2, markersize=6)\n",
    "        ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
    "        ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "        ax2.set_title(\"Training Loss\", fontsize=14, fontweight=\"bold\")\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            \"checkpoints/sonar_full_finetuned/training_curves.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"\\nğŸ“ˆ Training curves salvate in: training_curves.png\")\n",
    "\n",
    "    # Statistiche training\n",
    "    print(f\"\\nğŸ“Š STATISTICHE:\")\n",
    "    print(f\"   Total epochs: {len(log) if log_path.exists() else 'N/A'}\")\n",
    "    print(f\"   Best BLEU: {max(bleus):.2f}%\" if log_path.exists() else \"\")\n",
    "    print(f\"   Final Loss: {losses[-1]:.4f}\" if log_path.exists() and losses else \"\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nâŒ Checkpoint non trovato!\")\n",
    "    print(f\"   Path: {checkpoint_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290bd50f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7ï¸âƒ£ Analisi Risultati Finali\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "log_file = Path(\"checkpoints/sonar_full_finetuned/training_log.json\")\n",
    "\n",
    "if not log_file.exists():\n",
    "    print(f\"â³ Waiting for training to start...\")\n",
    "    print(f\"   Log file: {log_file}\")\n",
    "else:\n",
    "    # Monitor ogni 30 secondi\n",
    "    for _ in range(100):  # Max 50 minuti di monitoring\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        try:\n",
    "            with open(log_file, \"r\") as f:\n",
    "                log = json.load(f)\n",
    "\n",
    "            print(\"=\" * 70)\n",
    "            print(\"ğŸ“Š TRAINING PROGRESS\")\n",
    "            print(\"=\" * 70)\n",
    "\n",
    "            # Mostra ultimi 10 epoch\n",
    "            recent = log[-10:] if len(log) > 10 else log\n",
    "\n",
    "            for entry in recent:\n",
    "                epoch = entry.get(\"epoch\", \"?\")\n",
    "                train_loss = entry.get(\"train_loss\", 0)\n",
    "                val_bleu = entry.get(\"val_bleu\", 0)\n",
    "                print(\n",
    "                    f\"Epoch {epoch:>3}: Loss={train_loss:>7.4f} | BLEU={val_bleu:>5.2f}%\"\n",
    "                )\n",
    "\n",
    "            # Best model so far\n",
    "            best_entry = max(log, key=lambda x: x.get(\"val_bleu\", 0))\n",
    "            print(\"\\n\" + \"â”€\" * 70)\n",
    "            print(\n",
    "                f\"ğŸ† BEST: Epoch {best_entry['epoch']} | BLEU = {best_entry['val_bleu']:.2f}%\"\n",
    "            )\n",
    "            print(\"=\" * 70)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error reading log: {e}\")\n",
    "\n",
    "        time.sleep(30)  # Aggiorna ogni 30 secondi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0216e6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ DIAGNOSTICA: Embedding Analysis\n",
    "\n",
    "Prima di aspettare il full training, analizziamo **cosa sta producendo l'encoder**!\n",
    "\n",
    "Possibili problemi:\n",
    "\n",
    "1. **Embeddings collassati** (tutti uguali) â†’ BLEU 0%\n",
    "2. **Embeddings non normalizzati** â†’ incompatibili con SONAR decoder\n",
    "3. **Decoder riceve formato sbagliato** â†’ output random\n",
    "4. **Features ASL troppo diverse** da SONAR space â†’ decoder confuso\n",
    "\n",
    "Questa cella esegue analisi diagnostica sugli embeddings prodotti dall'encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001606fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ANALISI EMBEDDINGS PRODOTTI DALL'ENCODER\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import modello\n",
    "from train_sonar_finetuning import ASLToTextModel\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”¬ ANALISI EMBEDDINGS ENCODER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Carica modello con checkpoint best\n",
    "checkpoint_path = Path(\"checkpoints/sonar_full_test/best_model.pt\")\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"\\nğŸ“¦ Caricamento modello: {checkpoint_path}\")\n",
    "    \n",
    "    model = ASLToTextModel(\n",
    "        encoder_checkpoint=\"checkpoints/sonar_encoder_finetuned/best_encoder.pt\",\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    \n",
    "    # Carica stato del checkpoint\n",
    "    ckpt = torch.load(checkpoint_path, map_location=model.device)\n",
    "    model.encoder.load_state_dict(ckpt['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"   âœ… Modello caricato (epoch {ckpt['epoch']})\")\n",
    "    print(f\"   Device: {model.device}\")\n",
    "    \n",
    "    # Carica 50 sample dal validation set\n",
    "    print(f\"\\nğŸ“Š Analisi su 50 validation samples...\")\n",
    "    \n",
    "    manifest = pd.read_csv(\"manifests/val.tsv\", sep=\"\\t\")\n",
    "    features_dir = Path(\"features/val\")\n",
    "    \n",
    "    embeddings_list = []\n",
    "    texts_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, row in manifest.head(50).iterrows():\n",
    "            video_id = row['id']\n",
    "            text = row['text']\n",
    "            \n",
    "            # Carica features\n",
    "            npy_path = features_dir / f\"{video_id}.npy\"\n",
    "            pt_path = features_dir / f\"{video_id}.pt\"\n",
    "            \n",
    "            if npy_path.exists():\n",
    "                features = torch.from_numpy(np.load(npy_path)).float()\n",
    "            elif pt_path.exists():\n",
    "                data = torch.load(pt_path, map_location=\"cpu\")\n",
    "                features = data['features']\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Forward attraverso encoder\n",
    "            features = features.unsqueeze(0).to(model.device)  # [1, T, 256]\n",
    "            embedding = model.encoder(features, lengths=torch.tensor([features.shape[1]]))  # [1, 1024]\n",
    "            \n",
    "            embeddings_list.append(embedding.cpu())\n",
    "            texts_list.append(text)\n",
    "    \n",
    "    embeddings = torch.cat(embeddings_list, dim=0)  # [N, 1024]\n",
    "    \n",
    "    print(f\"\\nâœ… Analizzati {len(embeddings)} samples\")\n",
    "    print(f\"   Shape: {embeddings.shape}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # ANALISI 1: Statistiche Embeddings\n",
    "    # ============================================================================\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"ğŸ“Š STATISTICHE EMBEDDINGS\")\n",
    "    print(f\"=\" * 70)\n",
    "    \n",
    "    norms = torch.norm(embeddings, dim=1)\n",
    "    means = embeddings.mean(dim=1)\n",
    "    stds = embeddings.std(dim=1)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Norme L2:\")\n",
    "    print(f\"   Mean: {norms.mean():.4f}\")\n",
    "    print(f\"   Std:  {norms.std():.4f}\")\n",
    "    print(f\"   Min:  {norms.min():.4f}\")\n",
    "    print(f\"   Max:  {norms.max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Mean per sample:\")\n",
    "    print(f\"   Mean: {means.mean():.4f}\")\n",
    "    print(f\"   Std:  {means.std():.4f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Std per sample:\")\n",
    "    print(f\"   Mean: {stds.mean():.4f}\")\n",
    "    print(f\"   Std:  {stds.std():.4f}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # ANALISI 2: DiversitÃ  Embeddings (Collapse Detection)\n",
    "    # ============================================================================\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"ğŸ” ANALISI DIVERSITÃ€ (Collapse Detection)\")\n",
    "    print(f\"=\" * 70)\n",
    "    \n",
    "    # Cosine similarity tra tutti i pairs\n",
    "    embeddings_norm = embeddings / embeddings.norm(dim=1, keepdim=True)\n",
    "    similarity_matrix = embeddings_norm @ embeddings_norm.T\n",
    "    \n",
    "    # Rimuovi diagonale (self-similarity = 1)\n",
    "    mask = ~torch.eye(len(embeddings), dtype=bool)\n",
    "    off_diagonal_sims = similarity_matrix[mask]\n",
    "    \n",
    "    print(f\"\\nğŸ“ Cosine Similarity (off-diagonal):\")\n",
    "    print(f\"   Mean: {off_diagonal_sims.mean():.4f}\")\n",
    "    print(f\"   Std:  {off_diagonal_sims.std():.4f}\")\n",
    "    print(f\"   Min:  {off_diagonal_sims.min():.4f}\")\n",
    "    print(f\"   Max:  {off_diagonal_sims.max():.4f}\")\n",
    "    \n",
    "    if off_diagonal_sims.mean() > 0.95:\n",
    "        print(f\"\\n   âŒ PROBLEMA: Embeddings troppo simili! (collapse)\")\n",
    "        print(f\"      L'encoder produce output quasi identici per tutti i sample\")\n",
    "    elif off_diagonal_sims.mean() > 0.80:\n",
    "        print(f\"\\n   âš ï¸  WARNING: Embeddings molto simili (possibile collapse)\")\n",
    "    else:\n",
    "        print(f\"\\n   âœ… OK: Embeddings sufficientemente diversificati\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # ANALISI 3: Confronto con SONAR Text Embeddings\n",
    "    # ============================================================================\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"ğŸ¯ CONFRONTO CON SONAR TEXT EMBEDDINGS\")\n",
    "    print(f\"=\" * 70)\n",
    "    \n",
    "    # Genera embeddings SONAR per gli stessi testi\n",
    "    print(f\"\\nâ³ Generazione SONAR embeddings per {len(texts_list)} testi...\")\n",
    "    target_embeddings = model.encode_texts(texts_list)  # [N, 1024]\n",
    "    \n",
    "    # Norme SONAR\n",
    "    target_norms = torch.norm(target_embeddings, dim=1)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Norme L2 SONAR:\")\n",
    "    print(f\"   Mean: {target_norms.mean():.4f}\")\n",
    "    print(f\"   Std:  {target_norms.std():.4f}\")\n",
    "    print(f\"   Min:  {target_norms.min():.4f}\")\n",
    "    print(f\"   Max:  {target_norms.max():.4f}\")\n",
    "    \n",
    "    # Confronto norme\n",
    "    print(f\"\\nğŸ“Š CONFRONTO NORME:\")\n",
    "    print(f\"   Encoder ASL: {norms.mean():.4f} Â± {norms.std():.4f}\")\n",
    "    print(f\"   SONAR Text:  {target_norms.mean():.4f} Â± {target_norms.std():.4f}\")\n",
    "    print(f\"   Differenza:  {abs(norms.mean() - target_norms.mean()):.4f}\")\n",
    "    \n",
    "    if abs(norms.mean() - target_norms.mean()) > 10:\n",
    "        print(f\"\\n   âŒ PROBLEMA: Norme molto diverse!\")\n",
    "        print(f\"      Encoder produce embeddings con scala sbagliata\")\n",
    "    elif abs(norms.mean() - target_norms.mean()) > 5:\n",
    "        print(f\"\\n   âš ï¸  WARNING: Norme abbastanza diverse\")\n",
    "    else:\n",
    "        print(f\"\\n   âœ… OK: Norme simili\")\n",
    "    \n",
    "    # Cosine similarity ASL vs SONAR (corrispondenti)\n",
    "    embeddings_norm_asl = embeddings / embeddings.norm(dim=1, keepdim=True)\n",
    "    target_norm = target_embeddings / target_embeddings.norm(dim=1, keepdim=True)\n",
    "    \n",
    "    cosine_sims = (embeddings_norm_asl * target_norm).sum(dim=1)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Cosine Similarity ASLâ†’SONAR (stesso testo):\")\n",
    "    print(f\"   Mean: {cosine_sims.mean():.4f}\")\n",
    "    print(f\"   Std:  {cosine_sims.std():.4f}\")\n",
    "    print(f\"   Min:  {cosine_sims.min():.4f}\")\n",
    "    print(f\"   Max:  {cosine_sims.max():.4f}\")\n",
    "    \n",
    "    if cosine_sims.mean() < 0.3:\n",
    "        print(f\"\\n   âŒ PROBLEMA: Embeddings ASL molto diversi da SONAR!\")\n",
    "        print(f\"      L'encoder non sta imparando a mappare nello spazio SONAR\")\n",
    "    elif cosine_sims.mean() < 0.5:\n",
    "        print(f\"\\n   âš ï¸  WARNING: Similarity bassa, training potrebbe essere lento\")\n",
    "    else:\n",
    "        print(f\"\\n   âœ… OK: Encoder sta mappando correttamente nello spazio SONAR\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # ANALISI 4: Test Decoder su Sample Embeddings\n",
    "    # ============================================================================\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"ğŸ§ª TEST DECODER SU SAMPLE EMBEDDINGS\")\n",
    "    print(f\"=\" * 70)\n",
    "    \n",
    "    # Decodifica primi 5 embeddings\n",
    "    print(f\"\\nğŸ“ Decodifica primi 5 samples:\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    \n",
    "    for i in range(min(5, len(embeddings))):\n",
    "        embedding = embeddings[i:i+1].to(model.device)\n",
    "        reference = texts_list[i]\n",
    "        \n",
    "        # Decodifica\n",
    "        prediction = model.decode(embedding)[0]\n",
    "        \n",
    "        print(f\"\\n{i+1}. Reference:  {reference}\")\n",
    "        print(f\"   Prediction: {prediction}\")\n",
    "        \n",
    "        # Quick BLEU\n",
    "        if prediction.lower() == reference.lower():\n",
    "            print(f\"   âœ… EXACT MATCH!\")\n",
    "        elif any(word in prediction.lower() for word in reference.lower().split()[:3]):\n",
    "            print(f\"   âš ï¸  Partial match\")\n",
    "        else:\n",
    "            print(f\"   âŒ NO MATCH\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # RIEPILOGO DIAGNOSTICA\n",
    "    # ============================================================================\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"ğŸ“‹ RIEPILOGO DIAGNOSTICA\")\n",
    "    print(f\"=\" * 70)\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    if off_diagonal_sims.mean() > 0.95:\n",
    "        issues.append(\"ğŸ”´ COLLAPSE: Embeddings tutti uguali\")\n",
    "    \n",
    "    if abs(norms.mean() - target_norms.mean()) > 10:\n",
    "        issues.append(\"ğŸ”´ SCALA: Norme molto diverse da SONAR\")\n",
    "    \n",
    "    if cosine_sims.mean() < 0.3:\n",
    "        issues.append(\"ğŸ”´ MAPPING: Encoder non mappa in SONAR space\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"\\nâŒ PROBLEMI RILEVATI ({len(issues)}):\")\n",
    "        for issue in issues:\n",
    "            print(f\"   {issue}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ SOLUZIONI PROPOSTE:\")\n",
    "        if \"COLLAPSE\" in str(issues):\n",
    "            print(f\"   1. Aumenta learning rate (es. 1e-3)\")\n",
    "            print(f\"   2. Riduci batch size (es. 8)\")\n",
    "            print(f\"   3. Aggiungi dropout nell'encoder\")\n",
    "        \n",
    "        if \"SCALA\" in str(issues):\n",
    "            print(f\"   1. Normalizza output encoder (L2 norm)\")\n",
    "            print(f\"   2. Scala target embeddings alla stessa norma\")\n",
    "        \n",
    "        if \"MAPPING\" in str(issues):\n",
    "            print(f\"   1. Usa Cosine Loss invece di MSE\")\n",
    "            print(f\"   2. Pre-training piÃ¹ lungo su encoder\")\n",
    "            print(f\"   3. Aumenta epochs (es. 100)\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… NESSUN PROBLEMA CRITICO RILEVATO!\")\n",
    "        print(f\"\\n   L'architettura sembra corretta.\")\n",
    "        print(f\"   BLEU basso (0.02%) probabilmente dovuto a:\")\n",
    "        print(f\"   - Quick test troppo piccolo (100 samples)\")\n",
    "        print(f\"   - Training troppo breve (5 epochs)\")\n",
    "        print(f\"\\n   ğŸ‘‰ Aspetta risultati FULL TRAINING (50 epochs)!\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "\n",
    "else:\n",
    "    print(f\"\\nâŒ Checkpoint non trovato: {checkpoint_path}\")\n",
    "    print(f\"   Esegui prima il Quick Test!\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e706e22d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ Fix Automatico (Esegui SOLO se diagnostica rileva problemi)\n",
    "\n",
    "Questa cella applica fix comuni basati sui problemi rilevati:\n",
    "\n",
    "1. **Normalizzazione embeddings L2** â†’ risolve problemi di scala\n",
    "2. **Cosine Loss** invece di MSE â†’ migliore per embeddings normalizzati\n",
    "3. **Gradient monitoring** â†’ rileva collapse/esplosione durante training\n",
    "4. **Logging avanzato** â†’ loss, grad_norm, cosine_sim in tempo reale\n",
    "5. **Validation metrics** â†’ BLEU + cosine similarity\n",
    "\n",
    "**âš ï¸ ESEGUI SOLO DOPO AVER ANALIZZATO LA DIAGNOSTICA!**\n",
    "\n",
    "**Metodo alternativo:** Usa `apply_training_fixes.py` (giÃ  in Google Drive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19747a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš ï¸ NOTA IMPORTANTE: Quando Usare Questi Fix?\n",
    "\n",
    "**NON ESEGUIRE ADESSO!** Aspetta prima i risultati del Full Training in corso.\n",
    "\n",
    "### ğŸ“Š Quando Eseguire:\n",
    "\n",
    "```\n",
    "âœ… Se BLEU â‰¥ 30% â†’ Non fare nulla! Training ok!\n",
    "âŒ Se BLEU < 5%  â†’ ALLORA esegui diagnostica e fix\n",
    "```\n",
    "\n",
    "### ğŸ¯ Workflow Corretto:\n",
    "\n",
    "1. **ORA**: Aspetta che finisca Full Training (50 epochs)\n",
    "2. **DOPO**: Guarda BLEU nella cella \"Analisi Risultati Finali\"\n",
    "3. **SE MALE**: Esegui diagnostica â†’ fix â†’ re-test\n",
    "4. **SE BENE**: Festeggia! ğŸ‰\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188223e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš¨ RISULTATO TRAINING: BLEU 0.13% â†’ PROBLEMA RILEVATO!\n",
    "\n",
    "### ğŸ“Š Situazione:\n",
    "- âœ… Training completato (10 epochs)\n",
    "- âŒ **BLEU: 0.13%** (target: 30-40%)\n",
    "- ğŸ”´ **Problema confermato**: serve diagnostica!\n",
    "\n",
    "### ğŸ¯ AZIONI IMMEDIATE:\n",
    "\n",
    "**STEP 1: DIAGNOSTICA** (Esegui ORA la cella sotto â†“)\n",
    "- Identifica il problema esatto (collapse/scala/mapping)\n",
    "\n",
    "**STEP 2: FIX AUTOMATICO** (Solo dopo diagnostica)\n",
    "- Applica correzioni basate sul problema trovato\n",
    "\n",
    "**STEP 3: QUICK TEST IMPROVED** (Verifica fix)\n",
    "- Test veloce (5 epochs, 50 samples) per confermare miglioramento\n",
    "\n",
    "**STEP 4: RE-TRAINING** (Se fix funziona)\n",
    "- Rilancia con script improved\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8d294",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… FIX GIÃ€ APPLICATI! Re-Training con Script Migliorato\n",
    "\n",
    "**IMPORTANTE:** I fix sono giÃ  stati applicati a `train_sonar_finetuning.py`!\n",
    "\n",
    "Il messaggio \"Pattern non trovato\" significa che lo script **ha giÃ  i fix**! ğŸ‰\n",
    "\n",
    "### ğŸš€ Rilancia Training con Script Aggiornato:\n",
    "\n",
    "Usa la cella sotto per ri-testare con gli stessi parametri.\n",
    "\n",
    "**Cosa aspettarsi:**\n",
    "- âœ… Loss iniziale ~1.0 (non piÃ¹ 0.0009)\n",
    "- âœ… Cosine similarity aumenta progressivamente  \n",
    "- âœ… Gradient norm visibile (0.1-1.0)\n",
    "- âœ… BLEU dovrebbe essere > 5% (vs 0.13%)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f63ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# RE-TRAINING con SCRIPT MIGLIORATO (fix giÃ  applicati)\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "print(f\"ğŸ“‚ Working directory: {os.getcwd()}\\n\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸš€ RE-TRAINING CON FIX APPLICATI\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nğŸ“Š Fix inclusi:\")\n",
    "print(\"   âœ… Normalizzazione L2 output encoder\")\n",
    "print(\"   âœ… Cosine Loss invece di MSE\")\n",
    "print(\"   âœ… Gradient norm monitoring\")\n",
    "print(\"   âœ… Logging avanzato (loss + grad_norm + cosine_sim)\")\n",
    "print(\"   âœ… Validation metrics estese (BLEU + cosine)\")\n",
    "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "\n",
    "# STESSO comando di prima, ma ora lo script ha i fix!\n",
    "!python train_sonar_finetuning.py \\\n",
    "    --encoder_checkpoint checkpoints/sonar_encoder_finetuned/best_encoder.pt \\\n",
    "    --train_features features/train \\\n",
    "    --train_manifest manifests/train.tsv \\\n",
    "    --val_features features/val \\\n",
    "    --val_manifest manifests/val.tsv \\\n",
    "    --output_dir checkpoints/sonar_finetuned_FIXED \\\n",
    "    --epochs 10 \\\n",
    "    --batch_size 32 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --eval_every 2 \\\n",
    "    --save_every 5 \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… RE-TRAINING COMPLETATO!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nğŸ“Š Controlla i risultati:\")\n",
    "print(\"   - Loss dovrebbe essere ~1.0 inizialmente (non 0.0009)\")\n",
    "print(\"   - Cosine similarity dovrebbe aumentare progressivamente\")\n",
    "print(\"   - Gradient norm dovrebbe essere stabile (0.1-1.0)\")\n",
    "print(\"   - BLEU atteso: > 5% (miglioramento rispetto a 0.13%)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METODO 1: Usa script Python standalone (CONSIGLIATO)\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ APPLICAZIONE FIX CON SCRIPT STANDALONE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verifica che lo script esista\n",
    "from pathlib import Path\n",
    "\n",
    "fix_script = Path(\"apply_training_fixes.py\")\n",
    "\n",
    "if not fix_script.exists():\n",
    "    print(f\"\\nâš ï¸  Script apply_training_fixes.py non trovato!\")\n",
    "    print(f\"   Assicurati di averlo caricato su Google Drive\")\n",
    "    print(f\"\\nğŸ’¡ Path atteso: /content/drive/MyDrive/How2Sign_SONAR/apply_training_fixes.py\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Script trovato: {fix_script}\")\n",
    "    print(f\"\\nâ³ Esecuzione fix automatici...\\n\")\n",
    "    \n",
    "    # Esegui lo script di fix\n",
    "    !python apply_training_fixes.py\n",
    "    \n",
    "    # Verifica risultato\n",
    "    improved = Path(\"train_sonar_finetuning_IMPROVED.py\")\n",
    "    \n",
    "    if improved.exists():\n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(f\"âœ… SCRIPT MIGLIORATO CREATO!\")\n",
    "        print(f\"=\" * 70)\n",
    "        print(f\"\\nğŸ“ File: {improved}\")\n",
    "        print(f\"   Size: {improved.stat().st_size / 1024:.1f} KB\")\n",
    "        \n",
    "        print(f\"\\nğŸ§ª Prossimo passo:\")\n",
    "        print(f\"   Esegui la cella 'Test Quick con Script Migliorato'\")\n",
    "        print(f\"   per verificare che i fix funzionino!\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ Errore nella creazione dello script migliorato\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf013fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§ª Test Quick con Script Migliorato\n",
    "\n",
    "Test rapido (5 epochs, 50 samples) per verificare che i fix funzionino.\n",
    "\n",
    "**Cosa aspettarsi:**\n",
    "\n",
    "- âœ… Loss iniziale ~1.0 (non piÃ¹ 0.0009)\n",
    "- âœ… Cosine similarity aumenta progressivamente\n",
    "- âœ… Gradient norm stabile (non zero, non esplosivo)\n",
    "- âœ… BLEU dovrebbe essere > 0% giÃ  dopo poche epochs\n",
    "\n",
    "**Se funziona:** Sostituisci lo script originale e rilancia full training!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Test dello script migliorato (VELOCE: 5 epochs, 50 samples)\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "print(f\"ğŸ“‚ Working directory: {os.getcwd()}\\n\")\n",
    "\n",
    "# Verifica che lo script migliorato esista\n",
    "from pathlib import Path\n",
    "improved_script = Path(\"train_sonar_finetuning_IMPROVED.py\")\n",
    "\n",
    "if not improved_script.exists():\n",
    "    print(\"âŒ Script migliorato non trovato!\")\n",
    "    print(\"   Esegui prima la cella di Fix Automatico!\")\n",
    "else:\n",
    "    print(\"âœ… Script migliorato trovato\")\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"ğŸ§ª QUICK TEST CON SCRIPT MIGLIORATO\")\n",
    "    print(f\"{'=' * 70}\\n\")\n",
    "    \n",
    "    !python train_sonar_finetuning_IMPROVED.py \\\n",
    "        --encoder_checkpoint checkpoints/sonar_encoder_finetuned/best_encoder.pt \\\n",
    "        --train_features features/train \\\n",
    "        --train_manifest manifests/train.tsv \\\n",
    "        --val_features features/val \\\n",
    "        --val_manifest manifests/val.tsv \\\n",
    "        --output_dir checkpoints/sonar_test_improved \\\n",
    "        --epochs 5 \\\n",
    "        --batch_size 16 \\\n",
    "        --learning_rate 1e-4 \\\n",
    "        --max_samples 50 \\\n",
    "        --device cuda\n",
    "    \n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"âœ… TEST COMPLETATO!\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    \n",
    "    # Analizza risultati\n",
    "    import json\n",
    "    log_file = Path(\"checkpoints/sonar_test_improved/training_log.json\")\n",
    "    \n",
    "    if log_file.exists():\n",
    "        with open(log_file) as f:\n",
    "            log = json.load(f)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š CONFRONTO LOSS:\")\n",
    "        print(f\"   Epoch 1: {log[0]['train_loss']:.4f}\")\n",
    "        print(f\"   Epoch 5: {log[-1]['train_loss']:.4f}\")\n",
    "        print(f\"   Variazione: {(log[0]['train_loss'] - log[-1]['train_loss']):.4f}\")\n",
    "        \n",
    "        if 'val_cosine_sim' in log[-1]:\n",
    "            print(f\"\\nğŸ¯ COSINE SIMILARITY:\")\n",
    "            print(f\"   Final: {log[-1]['val_cosine_sim']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ BLEU Score:\")\n",
    "        print(f\"   Final: {log[-1]['val_bleu']:.2f}%\")\n",
    "        \n",
    "        # Confronto con vecchio approccio\n",
    "        old_log = Path(\"checkpoints/sonar_full_test/training_log.json\")\n",
    "        if old_log.exists():\n",
    "            with open(old_log) as f:\n",
    "                old_data = json.load(f)\n",
    "            \n",
    "            print(f\"\\n{'=' * 70}\")\n",
    "            print(f\"ğŸ“Š CONFRONTO VECCHIO vs NUOVO:\")\n",
    "            print(f\"{'=' * 70}\")\n",
    "            print(f\"\\n   Metrica          | VECCHIO  | NUOVO    | Delta\")\n",
    "            print(f\"   {'-' * 60}\")\n",
    "            print(f\"   Loss iniziale    | {old_data[0]['train_loss']:.4f}   | {log[0]['train_loss']:.4f}   | {(log[0]['train_loss'] - old_data[0]['train_loss']):+.4f}\")\n",
    "            print(f\"   Loss finale      | {old_data[-1]['train_loss']:.4f}   | {log[-1]['train_loss']:.4f}   | {(log[-1]['train_loss'] - old_data[-1]['train_loss']):+.4f}\")\n",
    "            print(f\"   BLEU finale      | {old_data[-1]['val_bleu']:.2f}%   | {log[-1]['val_bleu']:.2f}%   | {(log[-1]['val_bleu'] - old_data[-1]['val_bleu']):+.2f}%\")\n",
    "            \n",
    "            if log[-1]['val_bleu'] > old_data[-1]['val_bleu']:\n",
    "                print(f\"\\n   âœ… MIGLIORAMENTO! Lo script improved funziona meglio!\")\n",
    "            else:\n",
    "                print(f\"\\n   âš ï¸  Risultati simili, potrebbe servire training piÃ¹ lungo\")\n",
    "    \n",
    "    print(f\"\\n{'=' * 70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35a466",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ Riepilogo Workflow Diagnostica & Fix\n",
    "\n",
    "### ğŸ”„ Workflow Completo:\n",
    "\n",
    "```\n",
    "1. Quick Test Originale (in corso)\n",
    "   â†“\n",
    "2. ğŸ”¬ DIAGNOSTICA (analizza embeddings)\n",
    "   â”œâ”€ âœ… Tutto OK â†’ aspetta full training\n",
    "   â””â”€ âŒ Problemi â†’ vai a step 3\n",
    "   â†“\n",
    "3. ğŸ”§ FIX AUTOMATICO (applica correzioni)\n",
    "   â†“\n",
    "4. ğŸ§ª QUICK TEST IMPROVED (verifica fix)\n",
    "   â”œâ”€ âœ… Migliora â†’ sostituisci script\n",
    "   â””â”€ âŒ Peggiora â†’ rivedi diagnostica\n",
    "   â†“\n",
    "5. ğŸš€ FULL TRAINING (50 epochs, 1252 samples)\n",
    "   â†“\n",
    "6. ğŸ¯ BLEU Target: 30-40%\n",
    "```\n",
    "\n",
    "### ğŸ“Š Metriche da Monitorare:\n",
    "\n",
    "| Metrica | Range OK | Problema se... |\n",
    "|---------|----------|----------------|\n",
    "| **Loss (Cosine)** | 0.5-1.5 | < 0.1 o > 1.8 |\n",
    "| **Cosine Sim** | 0.3-0.8 | < 0.1 (no mapping) |\n",
    "| **Grad Norm** | 0.1-1.0 | â‰ˆ0 (collapse) o >10 (esplosione) |\n",
    "| **BLEU (5 ep)** | 1-5% | < 0.5% (problema grave) |\n",
    "| **BLEU (50 ep)** | 30-40% | < 5% (architettura sbagliata) |\n",
    "\n",
    "### ğŸ“ Documentazione:\n",
    "\n",
    "Vedi `DIAGNOSTIC_AND_FIX_GUIDE.md` per guida completa!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bc1ce",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Monitoring Training (Esegui in Parallelo)\n",
    "\n",
    "Mentre il training Ã¨ in corso, puoi monitorare i progressi con questa cella.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323aec31",
   "metadata": {},
   "source": [
    "## ğŸ†• MODIFICA: Training da Zero (No Checkpoint)\n",
    "\n",
    "**IMPORTANTE:** Lo script Ã¨ stato modificato per supportare il training **da zero** senza bisogno di un checkpoint pre-esistente.\n",
    "\n",
    "### Cosa Ã¨ cambiato:\n",
    "\n",
    "- âŒ **Prima**: Richiedeva `--encoder_checkpoint checkpoints/sonar_encoder_finetuned/best_encoder.pt`\n",
    "- âœ… **Ora**: Se ometti `--encoder_checkpoint`, inizializza l'encoder da zero (random weights)\n",
    "\n",
    "### PerchÃ©:\n",
    "\n",
    "- Il checkpoint precedente `best_encoder.pt` non esiste piÃ¹ (BLEU 0.13% era inutilizzabile)\n",
    "- Meglio ripartire da zero con i **FIX applicati** piuttosto che usare pesi corrotti\n",
    "\n",
    "### Cosa aspettarsi:\n",
    "\n",
    "- **Loss iniziale**: ~1.0-1.5 (sano, range normale per cosine loss)\n",
    "- **BLEU a 10 epochs**: 5-15% (giÃ  molto meglio di 0.13%!)\n",
    "- **BLEU a 50 epochs**: 30-40% (target finale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ğŸ”„ RE-TRAINING DA ZERO CON FIX APPLICATI (senza checkpoint pre-esistente)\n",
    "\n",
    "# IMPORTANTE: Assicurati di essere nella directory corretta!\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "print(f\"ğŸ“‚ Working directory: {os.getcwd()}\\n\")\n",
    "\n",
    "# NOTA: Nessun --encoder_checkpoint (training from scratch)\n",
    "!python train_sonar_finetuning.py \\\n",
    "    --train_features features/train \\\n",
    "    --train_manifest manifests/train.tsv \\\n",
    "    --val_features features/val \\\n",
    "    --val_manifest manifests/val.tsv \\\n",
    "    --output_dir checkpoints/sonar_finetuned_FIXED \\\n",
    "    --epochs 10 \\\n",
    "    --batch_size 32 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --eval_every 2 \\\n",
    "    --save_every 5 \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… TRAINING COMPLETATO!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e2ceca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£ Training Completo (50 epochs, full dataset)\n",
    "\n",
    "âš ï¸ **ESEGUI SOLO SE IL QUICK TEST Ãˆ ANDATO BENE!**\n",
    "\n",
    "â±ï¸ Tempo stimato: **2-4 ore** su GPU T4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Verifica checkpoint salvato\n",
    "test_ckpt = Path(\"checkpoints/sonar_full_test/best_model.pt\")\n",
    "if test_ckpt.exists():\n",
    "    print(\"âœ… Quick test completato con successo!\")\n",
    "    print(f\"   Checkpoint: {test_ckpt}\")\n",
    "\n",
    "    # Carica info checkpoint\n",
    "    import torch\n",
    "\n",
    "    ckpt = torch.load(test_ckpt, map_location=\"cpu\")\n",
    "    print(f\"\\nğŸ“Š Risultati:\")\n",
    "    print(f\"   Best Epoch: {ckpt.get('epoch', 'N/A')}\")\n",
    "    print(f\"   Best BLEU: {ckpt.get('val_bleu', 0):.2f}%\")\n",
    "    print(\n",
    "        f\"   Train Loss: {ckpt.get('train_loss', 'N/A'):.4f}\"\n",
    "        if \"train_loss\" in ckpt\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nğŸš€ Procedi con il training completo nella prossima cella!\")\n",
    "else:\n",
    "    print(\"âŒ Quick test fallito - verifica errori sopra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18dbdc",
   "metadata": {},
   "source": [
    "### ğŸ“Š Verifica Risultati Quick Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Quick test - 5 epochs, 100 samples per verificare setup\n",
    "\n",
    "# IMPORTANTE: Assicurati di essere nella directory corretta!\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "print(f\"ğŸ“‚ Working directory: {os.getcwd()}\")\n",
    "print(f\"ğŸ“„ Script exists: {os.path.exists('train_sonar_finetuning.py')}\\n\")\n",
    "\n",
    "!python train_sonar_finetuning.py \\\n",
    "    --encoder_checkpoint checkpoints/sonar_encoder_finetuned/best_encoder.pt \\\n",
    "    --train_features features/train \\\n",
    "    --train_manifest manifests/train.tsv \\\n",
    "    --val_features features/val \\\n",
    "    --val_manifest manifests/val.tsv \\\n",
    "    --output_dir checkpoints/sonar_full_test \\\n",
    "    --epochs 5 \\\n",
    "    --batch_size 16 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --max_samples 100 \\\n",
    "    --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8fb878",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4ï¸âƒ£ Quick Test (5 epochs, 100 samples)\n",
    "\n",
    "Prima di lanciare il training completo, facciamo un test veloce per verificare che tutto funzioni.\n",
    "\n",
    "**âœ… LO SCRIPT Ãˆ STATO AGGIORNATO!**\n",
    "\n",
    "Modifiche principali:\n",
    "- âœ… Usa API SONAR corretta (`sonar-space` package)\n",
    "- âœ… Import da `sonar.inference_pipelines.text` invece di `fairseq2.models.sonar`\n",
    "- âœ… Decoder SONAR reale (non piÃ¹ placeholder)\n",
    "- âœ… Target embeddings calcolati da testi veri\n",
    "- âœ… Gradient clipping per stabilitÃ \n",
    "- âœ… Fix nome colonna `id` (era `video_id`)\n",
    "- âœ… Auto-filtra sample senza features (salta file mancanti)\n",
    "- âœ… Padding dinamico per features con lunghezze diverse\n",
    "- âœ… Media temporale esclude padding (usa lunghezze reali)\n",
    "- âœ… Fix inference mode con `.clone().detach()` per target embeddings\n",
    "- âœ… **NUOVO**: Fix decoder SONAR usa torch.Tensor (non numpy)\n",
    "\n",
    "Vedi dettagli completi in: `SONAR_SCRIPT_FIX.md`\n",
    "\n",
    "---\n",
    "\n",
    "**âš ï¸ PREREQUISITO**: Assicurati di aver eseguito:\n",
    "\n",
    "1. âœ… Cella 1 (Mount Drive)\n",
    "2. âœ… Cella 2 (Verifica Dataset)\n",
    "3. âœ… Cella 3-bis (Verifica Setup) â†’ SONAR deve essere installato!\n",
    "4. âœ… Cella \"Verifica Struttura Manifest\" â†’ Controlla quante features sono disponibili\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’¡ NOTA IMPORTANTE**: Lo script gestisce automaticamente:\n",
    "\n",
    "- âœ… Sample senza features (filtrati all'inizio)\n",
    "- âœ… Features con lunghezze diverse (padding dinamico)\n",
    "- âœ… Media temporale corretta (esclude padding)\n",
    "- âœ… Inference mode compatibile con backpropagation\n",
    "- âœ… SONAR decoder compatibile con PyTorch tensors\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1f902",
   "metadata": {},
   "source": [
    "### âœ… Verifica Pre-Training\n",
    "\n",
    "**Esegui questa cella PRIMA del Quick Test** per verificare che tutto sia pronto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f0f40",
   "metadata": {},
   "source": [
    "### ğŸ” Verifica Struttura Manifest (IMPORTANTE!)\n",
    "\n",
    "**Esegui questa cella per verificare che il manifest abbia le colonne corrette.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ” VERIFICA STRUTTURA MANIFEST E FEATURES DISPONIBILI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Carica train manifest\n",
    "train_tsv = Path(\"manifests/train.tsv\")\n",
    "\n",
    "if train_tsv.exists():\n",
    "    df = pd.read_csv(train_tsv, sep=\"\\t\", nrows=5)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Manifest: {train_tsv}\")\n",
    "    print(f\"\\nğŸ“Š Colonne presenti:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"   - {col}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ Prime 3 righe:\")\n",
    "    print(df.head(3).to_string(index=False))\n",
    "    \n",
    "    # Verifica colonne richieste\n",
    "    print(f\"\\nâœ… Verifica colonne richieste dallo script:\")\n",
    "    \n",
    "    required_cols = {\n",
    "        \"id\": \"Identificatore video (RICHIESTO)\",\n",
    "        \"text\": \"Testo di riferimento (RICHIESTO)\",\n",
    "        \"duration\": \"Durata video (opzionale)\"\n",
    "    }\n",
    "    \n",
    "    for col, desc in required_cols.items():\n",
    "        if col in df.columns:\n",
    "            print(f\"   âœ… '{col}' - {desc}\")\n",
    "        else:\n",
    "            print(f\"   âŒ '{col}' - {desc} - MANCANTE!\")\n",
    "    \n",
    "    # Check se usa vecchio formato 'video_id'\n",
    "    if 'video_id' in df.columns:\n",
    "        print(f\"\\nâš ï¸  ATTENZIONE: Manifest usa 'video_id' invece di 'id'\")\n",
    "        print(f\"   Lo script Ã¨ stato aggiornato per usare 'id'\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    # NUOVO: Conta features disponibili\n",
    "    print(\"\\nğŸ” VERIFICA FEATURES DISPONIBILI:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    df_full = pd.read_csv(train_tsv, sep=\"\\t\")\n",
    "    features_dir = Path(\"features/train\")\n",
    "    \n",
    "    available = 0\n",
    "    missing = 0\n",
    "    \n",
    "    for idx, row in df_full.iterrows():\n",
    "        video_id = row['id'] if 'id' in row else row.get('video_id', '')\n",
    "        npy_path = features_dir / f\"{video_id}.npy\"\n",
    "        pt_path = features_dir / f\"{video_id}.pt\"\n",
    "        \n",
    "        if npy_path.exists() or pt_path.exists():\n",
    "            available += 1\n",
    "        else:\n",
    "            missing += 1\n",
    "    \n",
    "    total = len(df_full)\n",
    "    coverage = (available / total * 100) if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\n\udcca TRAIN SET:\")\n",
    "    print(f\"   Total manifest: {total}\")\n",
    "    print(f\"   âœ… Features disponibili: {available} ({coverage:.1f}%)\")\n",
    "    print(f\"   âŒ Features mancanti: {missing} ({100-coverage:.1f}%)\")\n",
    "    \n",
    "    if missing > 0:\n",
    "        print(f\"\\nâš ï¸  NOTA: Lo script salterÃ  automaticamente i {missing} sample senza features\")\n",
    "        print(f\"   Il training userÃ  solo i {available} sample con features disponibili\")\n",
    "    \n",
    "    # Ripeti per validation\n",
    "    val_tsv = Path(\"manifests/val.tsv\")\n",
    "    if val_tsv.exists():\n",
    "        df_val = pd.read_csv(val_tsv, sep=\"\\t\")\n",
    "        features_dir_val = Path(\"features/val\")\n",
    "        \n",
    "        available_val = 0\n",
    "        missing_val = 0\n",
    "        \n",
    "        for idx, row in df_val.iterrows():\n",
    "            video_id = row['id'] if 'id' in row else row.get('video_id', '')\n",
    "            npy_path = features_dir_val / f\"{video_id}.npy\"\n",
    "            pt_path = features_dir_val / f\"{video_id}.pt\"\n",
    "            \n",
    "            if npy_path.exists() or pt_path.exists():\n",
    "                available_val += 1\n",
    "            else:\n",
    "                missing_val += 1\n",
    "        \n",
    "        total_val = len(df_val)\n",
    "        coverage_val = (available_val / total_val * 100) if total_val > 0 else 0\n",
    "        \n",
    "        print(f\"\\nğŸ“Š VALIDATION SET:\")\n",
    "        print(f\"   Total manifest: {total_val}\")\n",
    "        print(f\"   âœ… Features disponibili: {available_val} ({coverage_val:.1f}%)\")\n",
    "        print(f\"   âŒ Features mancanti: {missing_val} ({100-coverage_val:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâŒ Manifest non trovato: {train_tsv}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… CHECKLIST PRE-TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "checks_passed = 0\n",
    "total_checks = 5\n",
    "\n",
    "# 1. Verifica directory corretta\n",
    "print(\"\\n1ï¸âƒ£ Verifica directory di lavoro...\")\n",
    "expected_dir = \"/content/drive/MyDrive/How2Sign_SONAR\"\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "if current_dir == expected_dir:\n",
    "    print(f\"   âœ… Directory corretta: {current_dir}\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"   âŒ Directory errata!\")\n",
    "    print(f\"      Attuale: {current_dir}\")\n",
    "    print(f\"      Attesa:  {expected_dir}\")\n",
    "    print(f\"   ğŸ”§ Esegui: os.chdir('{expected_dir}')\")\n",
    "\n",
    "# 2. Verifica script esiste\n",
    "print(\"\\n2ï¸âƒ£ Verifica script train_sonar_finetuning.py...\")\n",
    "script_path = Path(\"train_sonar_finetuning.py\")\n",
    "if script_path.exists():\n",
    "    print(f\"   âœ… Script trovato: {script_path}\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"   âŒ Script NON trovato!\")\n",
    "    print(f\"   ğŸ”§ Assicurati di aver caricato lo script su Drive\")\n",
    "\n",
    "# 3. Verifica SONAR installato\n",
    "print(\"\\n3ï¸âƒ£ Verifica SONAR installato...\")\n",
    "try:\n",
    "    from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline\n",
    "\n",
    "    print(f\"   âœ… SONAR importato correttamente\")\n",
    "    checks_passed += 1\n",
    "except ImportError:\n",
    "    print(f\"   âŒ SONAR non installato!\")\n",
    "    print(f\"   ğŸ”§ Torna alle celle di installazione\")\n",
    "\n",
    "# 4. Verifica encoder checkpoint\n",
    "print(\"\\n4ï¸âƒ£ Verifica encoder checkpoint...\")\n",
    "encoder_path = Path(\"checkpoints/sonar_encoder_finetuned/best_encoder.pt\")\n",
    "if encoder_path.exists():\n",
    "    print(f\"   âœ… Encoder checkpoint trovato\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"   âŒ Encoder checkpoint NON trovato!\")\n",
    "    print(f\"   ğŸ”§ Path: {encoder_path}\")\n",
    "\n",
    "# 5. Verifica features e manifests\n",
    "print(\"\\n5ï¸âƒ£ Verifica dataset...\")\n",
    "train_manifest = Path(\"manifests/train.tsv\")\n",
    "val_manifest = Path(\"manifests/val.tsv\")\n",
    "train_features = Path(\"features/train\")\n",
    "val_features = Path(\"features/val\")\n",
    "\n",
    "if all(\n",
    "    [\n",
    "        train_manifest.exists(),\n",
    "        val_manifest.exists(),\n",
    "        train_features.exists(),\n",
    "        val_features.exists(),\n",
    "    ]\n",
    "):\n",
    "    print(f\"   âœ… Dataset completo (features + manifests)\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"   âŒ Dataset incompleto!\")\n",
    "    print(f\"      train.tsv: {train_manifest.exists()}\")\n",
    "    print(f\"      val.tsv: {val_manifest.exists()}\")\n",
    "    print(f\"      features/train: {train_features.exists()}\")\n",
    "    print(f\"      features/val: {val_features.exists()}\")\n",
    "\n",
    "# Risultato finale\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ğŸ“Š RISULTATO: {checks_passed}/{total_checks} controlli superati\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if checks_passed == total_checks:\n",
    "    print(\"\\nğŸ‰ TUTTO PRONTO!\")\n",
    "    print(\"ğŸ‘‰ Procedi con il Quick Test nella cella successiva\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  {total_checks - checks_passed} problemi da risolvere\")\n",
    "    print(\"ğŸ‘‰ Risolvi i problemi sopra prima di continuare\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3bd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSTALLA DIPENDENZE AGGIUNTIVE\n",
    "# ============================================================================\n",
    "# NOTA: Questo presuppone che tu abbia GIÃ€ eseguito setup iniziale:\n",
    "#   1. pip install numpy>=2,<2.3\n",
    "#   2. pip install torch 2.9.0 + cu126\n",
    "#   3. pip install fairseq2 --no-deps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“¦ INSTALLAZIONE DIPENDENZE AGGIUNTIVE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Installa dipendenze mancanti di fairseq2 (mantenendo numpy 2.x)\n",
    "print(\"\\n1ï¸âƒ£ Installazione componenti fairseq2...\")\n",
    "!pip install fairseq2n==0.7.0\n",
    "\n",
    "# INSTALLA SONAR (pacchetto SEPARATO da fairseq2!)\n",
    "print(\"\\n2ï¸âƒ£ Installazione SONAR (sonar-space)...\")\n",
    "!pip install \"sonar-space>=0.5.0\"\n",
    "\n",
    "# Dipendenze aggiuntive\n",
    "print(\"\\n3ï¸âƒ£ Installazione dipendenze extra...\")\n",
    "!pip install sentencepiece pyyaml tqdm sacrebleu pandas\n",
    "\n",
    "# Verifica installazione SONAR\n",
    "print(\"\\n4ï¸âƒ£ Verifica installazione SONAR...\")\n",
    "!pip show sonar-space\n",
    "\n",
    "# RIAVVIO RUNTIME NECESSARIO per caricare nuovi moduli\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âš ï¸  IMPORTANTE: RIAVVIA IL RUNTIME ORA!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nğŸ“ Dopo il riavvio:\")\n",
    "print(\"   1. Riesegui dalla Cella 1 (Mount Drive)\")\n",
    "print(\"   2. Salta la Cella 3 (giÃ  eseguita)\")\n",
    "print(\"   3. Continua con Cella 3-bis (Verifica)\")\n",
    "print(\"\\nâš ï¸  Runtime â†’ Restart runtime\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45238542",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Installa Dipendenze\n",
    "\n",
    "âš ï¸ **PREREQUISITO**: Assicurati di aver giÃ  eseguito PRIMA del notebook:\n",
    "\n",
    "```python\n",
    "# Setup iniziale (ESEGUI PRIMA DEL NOTEBOOK)\n",
    "!pip install -U \"numpy>=2,<2.3\"\n",
    "!pip install -U torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install -U --no-deps fairseq2 --extra-index-url https://fair.pkg.atmeta.com/fairseq2/whl/pt2.9.0/cu126\n",
    "```\n",
    "\n",
    "Questa cella installa:\n",
    "\n",
    "1. **fairseq2n** - Componente nativo con modelli base\n",
    "2. **sonar-space** - Pacchetto SONAR (SEPARATO da fairseq2!)\n",
    "3. **Dipendenze extra** - sentencepiece, pyyaml, sacrebleu, etc.\n",
    "\n",
    "**IMPORTANTE**: SONAR NON Ã¨ parte di fairseq2, Ã¨ un progetto separato!\n",
    "\n",
    "Lo script `train_sonar_finetuning.py` Ã¨ stato **RISCRITTO** per usare l'API corretta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cb5a4",
   "metadata": {},
   "source": [
    "### ğŸ” Diagnostica Pre-Installazione\n",
    "\n",
    "Esegui questa cella PRIMA della cella 3 per vedere cosa Ã¨ giÃ  installato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ” DIAGNOSTICA PACCHETTI INSTALLATI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "packages_to_check = [\n",
    "    (\"numpy\", \"NumPy\"),\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"fairseq2\", \"fairseq2\"),\n",
    "    (\"fairseq2n\", \"fairseq2n\"),\n",
    "    (\"sonar-space\", \"SONAR\"),\n",
    "    (\"sentencepiece\", \"SentencePiece\"),\n",
    "    (\"sacrebleu\", \"SacreBLEU\"),\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“¦ Pacchetti installati:\\n\")\n",
    "\n",
    "for package, name in packages_to_check:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"show\", package], capture_output=True, text=True\n",
    "    )\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        # Estrai versione\n",
    "        for line in result.stdout.split(\"\\n\"):\n",
    "            if line.startswith(\"Version:\"):\n",
    "                version = line.split(\"Version:\")[1].strip()\n",
    "                print(f\"âœ… {name:<20} v{version}\")\n",
    "                break\n",
    "    else:\n",
    "        print(f\"âŒ {name:<20} NON INSTALLATO\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“ PROSSIMI PASSI:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Controlla se sonar-space Ã¨ installato\n",
    "sonar_result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"show\", \"sonar-space\"], capture_output=True, text=True\n",
    ")\n",
    "\n",
    "if sonar_result.returncode != 0:\n",
    "    print(\"\\nâš ï¸  sonar-space NON Ã¨ installato!\")\n",
    "    print(\"   â†’ Procedi con Cella 3 per installarlo\")\n",
    "else:\n",
    "    print(\"\\nâœ… sonar-space Ã¨ giÃ  installato!\")\n",
    "    print(\"   â†’ Salta Cella 3 e vai a Cella 3-bis (Verifica)\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"âœ… VERIFICA SETUP COMPLETO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verifica PyTorch\n",
    "import torch\n",
    "\n",
    "print(f\"\\nğŸ”¥ PyTorch: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ CUDA not available - training su CPU (molto lento!)\")\n",
    "\n",
    "# Verifica numpy\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\nğŸ“Š NumPy: {np.__version__}\")\n",
    "if not np.__version__.startswith(\"2.\"):\n",
    "    print(f\"   âŒ ERROR: NumPy dovrebbe essere 2.x, trovato {np.__version__}\")\n",
    "    print(f\"   ğŸ”§ SOLUZIONE: Esegui setup iniziale di nuovo\")\n",
    "else:\n",
    "    print(f\"   âœ… NumPy versione corretta\")\n",
    "\n",
    "# Verifica fairseq2\n",
    "print(f\"\\nğŸ” Verifica fairseq2...\")\n",
    "try:\n",
    "    import fairseq2\n",
    "\n",
    "    print(f\"   âœ… fairseq2: v{fairseq2.__version__}\")\n",
    "\n",
    "    # Verifica fairseq2n\n",
    "    import fairseq2n\n",
    "\n",
    "    print(f\"   âœ… fairseq2n disponibile\")\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"   âŒ ModuleNotFoundError: {e}\")\n",
    "    print(f\"\\nğŸ”§ PROBLEMA: Modulo mancante\")\n",
    "    print(f\"   SOLUZIONE:\")\n",
    "    print(f\"   1. Torna alla Cella 3\")\n",
    "    print(f\"   2. Riesegui l'installazione\")\n",
    "    print(f\"   3. Riavvia runtime\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ ERROR: {e}\")\n",
    "\n",
    "# Verifica SONAR (pacchetto SEPARATO!)\n",
    "print(f\"\\nğŸ¯ Verifica SONAR (sonar-space)...\")\n",
    "try:\n",
    "    import sonar\n",
    "\n",
    "    print(f\"   âœ… sonar: disponibile\")\n",
    "\n",
    "    # Test import pipelines SONAR\n",
    "    from sonar.inference_pipelines.text import (\n",
    "        TextToEmbeddingModelPipeline,\n",
    "        EmbeddingToTextModelPipeline,\n",
    "    )\n",
    "\n",
    "    print(f\"   âœ… SONAR text pipelines importate!\")\n",
    "\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"ğŸ‰ TUTTO PRONTO PER IL TRAINING!\")\n",
    "    print(f\"=\" * 70)\n",
    "    print(f\"\\nğŸ‘‰ Procedi con Cella 4 (Quick Test)\")\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"   âŒ ModuleNotFoundError: {e}\")\n",
    "    print(f\"\\nğŸ”§ PROBLEMA: SONAR non installato\")\n",
    "    print(f\"   SOLUZIONE:\")\n",
    "    print(f\"   1. Torna alla Cella 3\")\n",
    "    print(f\"   2. Verifica che sonar-space sia installato\")\n",
    "    print(f\"   3. Riavvia runtime\")\n",
    "    print(f\"   4. Riesegui Celle 1, 2, poi questa\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ ERROR: {e}\")\n",
    "    print(f\"   Tipo: {type(e).__name__}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test identico a quello che DOVREBBE fare lo script\n",
    "print(\"ğŸ§ª Test importazione SONAR (pacchetto corretto)...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prima verifica se il pacchetto Ã¨ installato\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"\\nğŸ“¦ Verifica pacchetto sonar-space installato...\")\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"show\", \"sonar-space\"], capture_output=True, text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… sonar-space Ã¨ installato!\")\n",
    "    print(f\"\\n{result.stdout}\")\n",
    "else:\n",
    "    print(\"âŒ sonar-space NON Ã¨ installato!\")\n",
    "    print(\"\\nğŸ”§ INSTALLA ORA:\")\n",
    "    print('   !pip install \"sonar-space>=0.5.0\"')\n",
    "    print(\"\\nPoi riavvia il runtime e riprova.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ§ª Test import SONAR pipelines...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "SONAR_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    # SONAR Ã¨ un pacchetto SEPARATO da fairseq2!\n",
    "    from sonar.inference_pipelines.text import (\n",
    "        TextToEmbeddingModelPipeline,\n",
    "        EmbeddingToTextModelPipeline,\n",
    "    )\n",
    "\n",
    "    SONAR_AVAILABLE = True\n",
    "    print(\"âœ… SUCCESS: SONAR text pipelines importati!\")\n",
    "    print(f\"   SONAR_AVAILABLE = {SONAR_AVAILABLE}\")\n",
    "    print(\"\\nğŸ‰ SONAR funziona correttamente!\")\n",
    "    print(\"\\nâœ… Lo script train_sonar_finetuning.py Ã¨ stato AGGIORNATO!\")\n",
    "    print(\"   - Usa: from sonar.inference_pipelines.text import ...\")\n",
    "    print(\"   - Dovrebbe funzionare correttamente ora!\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ImportError: {e}\")\n",
    "    print(f\"   SONAR_AVAILABLE = {SONAR_AVAILABLE}\")\n",
    "    print(\"\\nğŸ”´ PROBLEMA: SONAR non importabile!\")\n",
    "    print(\"\\nğŸ’¡ SOLUZIONE:\")\n",
    "    print(\"   1. Torna alla Cella 3 e riesegui (senza -q)\")\n",
    "    print(\"   2. Verifica che l'installazione completi senza errori\")\n",
    "    print(\"   3. Runtime â†’ Restart runtime\")\n",
    "    print(\"   4. Riesegui Celle 1, 2, poi questa\")\n",
    "    print(\"\\nâš ï¸  Se persiste, prova:\")\n",
    "    print(\"   !pip uninstall -y sonar-space\")\n",
    "    print('   !pip install \"sonar-space==0.5.0\" --no-cache-dir')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Errore: {e}\")\n",
    "    print(f\"   Tipo: {type(e).__name__}\")\n",
    "    print(f\"   SONAR_AVAILABLE = {SONAR_AVAILABLE}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96941a",
   "metadata": {},
   "source": [
    "### ğŸ”§ Installazione Manuale SONAR\n",
    "\n",
    "**ESEGUI QUESTA CELLA** se il test sopra ha mostrato che `sonar-space` non Ã¨ installato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ed94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ INSTALLAZIONE MANUALE SONAR-SPACE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Installazione con output completo (no -q)\n",
    "print(\"\\nğŸ“¦ Installazione sonar-space con dipendenze...\")\n",
    "!pip install \"sonar-space>=0.5.0\" --no-cache-dir\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… INSTALLAZIONE COMPLETATA!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verifica immediata\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"show\", \"sonar-space\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\nâœ… sonar-space Ã¨ stato installato correttamente!\")\n",
    "    print(f\"\\n{result.stdout}\")\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"âš ï¸  RIAVVIA IL RUNTIME ORA!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nğŸ“ Dopo il riavvio:\")\n",
    "    print(\"   1. Riesegui Celle 1, 2\")\n",
    "    print(\"   2. Esegui cella 'Test Importazione SONAR'\")\n",
    "    print(\"   3. Se funziona âœ… â†’ Procedi con Quick Test\")\n",
    "else:\n",
    "    print(\"\\nâŒ Installazione fallita!\")\n",
    "    print(\"\\nğŸ”§ ERRORI DA VERIFICARE:\")\n",
    "    print(\"   - CompatibilitÃ  versioni PyTorch/fairseq2?\")\n",
    "    print(\"   - Dipendenze mancanti?\")\n",
    "    print(\"\\nğŸ’¡ Prova versione specifica:\")\n",
    "    print('   !pip install \"sonar-space==0.5.0\" --no-cache-dir')\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e3756b",
   "metadata": {},
   "source": [
    "### ğŸ”§ Alternativa: Installazione con Versione Specifica\n",
    "\n",
    "**Esegui SOLO se l'installazione sopra ha dato errori**. Usa versione esatta invece di `>=0.5.0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ INSTALLAZIONE SONAR-SPACE (Versione Esatta)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Disinstalla prima se esiste\n",
    "print(\"\\n1ï¸âƒ£ Rimozione versione precedente (se esiste)...\")\n",
    "!pip uninstall -y sonar-space\n",
    "\n",
    "# Installa versione specifica 0.5.0\n",
    "print(\"\\n2ï¸âƒ£ Installazione sonar-space==0.5.0...\")\n",
    "!pip install \"sonar-space==0.5.0\" --no-cache-dir -v\n",
    "\n",
    "# Verifica\n",
    "print(\"\\n3ï¸âƒ£ Verifica installazione...\")\n",
    "!pip show sonar-space\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âš ï¸  RIAVVIA IL RUNTIME!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nDopo riavvio: Celle 1, 2 â†’ Test Importazione\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0cb8a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### âœ… AGGIORNAMENTO: train_sonar_finetuning.py Ã¨ stato CORRETTO!\n",
    "\n",
    "**Problema (RISOLTO)**: Lo script cercava di importare:\n",
    "```python\n",
    "from fairseq2.models.sonar import load_sonar_text_decoder  # âŒ NON ESISTE\n",
    "```\n",
    "\n",
    "**Soluzione (APPLICATA)**: Lo script ora usa:\n",
    "```python\n",
    "from sonar.inference_pipelines.text import (\n",
    "    TextToEmbeddingModelPipeline,\n",
    "    EmbeddingToTextModelPipeline,\n",
    ")\n",
    "```\n",
    "\n",
    "**Dettagli**:\n",
    "- **Nome pacchetto**: `sonar-space` (su PyPI)\n",
    "- **Import corretto**: `from sonar.inference_pipelines.text import ...`\n",
    "- **Documentazione**: https://github.com/facebookresearch/SONAR\n",
    "\n",
    "**âœ… Lo script Ã¨ stato riscritto e dovrebbe funzionare dopo l'installazione di sonar-space!**\n",
    "\n",
    "Vedi dettagli completi in: `SONAR_SCRIPT_FIX.md`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ae365",
   "metadata": {},
   "source": [
    "### ğŸ§ª Test Importazione SONAR (pacchetto corretto)\n",
    "\n",
    "**PROBLEMA RISOLTO**: `fairseq2.models.sonar` NON ESISTE!\n",
    "\n",
    "SONAR Ã¨ un **pacchetto separato** chiamato `sonar-space`, non parte di fairseq2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9430b",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ bis - Verifica Setup (DOPO RIAVVIO)\n",
    "\n",
    "âœ… **Esegui questa cella DOPO aver riavviato il runtime dalla cella precedente**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“Š VERIFICA DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Conta features (supporta .pt e .npy)\n",
    "train_features = len(list(Path(\"features/train\").glob(\"*.pt\"))) + len(\n",
    "    list(Path(\"features/train\").glob(\"*.npy\"))\n",
    ")\n",
    "val_features = len(list(Path(\"features/val\").glob(\"*.pt\"))) + len(\n",
    "    list(Path(\"features/val\").glob(\"*.npy\"))\n",
    ")\n",
    "test_features = len(list(Path(\"features/test\").glob(\"*.pt\"))) + len(\n",
    "    list(Path(\"features/test\").glob(\"*.npy\"))\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“¦ FEATURES DISPONIBILI:\")\n",
    "print(f\"   Train: {train_features:>4} files\")\n",
    "print(f\"   Val:   {val_features:>4} files\")\n",
    "print(f\"   Test:  {test_features:>4} files\")\n",
    "print(f\"   {'â”€' * 20}\")\n",
    "print(f\"   TOTAL: {train_features + val_features + test_features:>4} files\")\n",
    "\n",
    "# 2. Verifica manifests\n",
    "print(\"\\nğŸ“‹ MANIFESTS:\")\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    manifest_path = Path(f\"manifests/{split}.tsv\")\n",
    "    if manifest_path.exists():\n",
    "        n_lines = sum(1 for _ in open(manifest_path)) - 1  # -1 header\n",
    "        print(f\"   âœ… {split}.tsv: {n_lines} samples\")\n",
    "    else:\n",
    "        print(f\"   âŒ {split}.tsv: NOT FOUND\")\n",
    "\n",
    "# 3. Verifica sample feature\n",
    "sample_files = list(Path(\"features/train\").glob(\"*.pt\")) + list(\n",
    "    Path(\"features/train\").glob(\"*.npy\")\n",
    ")\n",
    "if sample_files:\n",
    "    sample_file = sample_files[0]\n",
    "    print(f\"\\nğŸ“ SAMPLE FEATURE:\")\n",
    "\n",
    "    if sample_file.suffix == \".pt\":\n",
    "        import torch\n",
    "\n",
    "        data = torch.load(sample_file, map_location=\"cpu\")\n",
    "        features = data[\"features\"]\n",
    "        print(f\"   Shape: {features.shape}\")\n",
    "        print(f\"   Format: PyTorch (.pt)\")\n",
    "        print(f\"   Video ID: {data.get('video_id', 'N/A')}\")\n",
    "        print(f\"   Text: {data.get('text', 'N/A')[:60]}...\")\n",
    "    else:\n",
    "        import numpy as np\n",
    "\n",
    "        features = np.load(sample_file)\n",
    "        print(f\"   Shape: {features.shape}\")\n",
    "        print(f\"   Format: NumPy (.npy)\")\n",
    "        print(f\"   File: {sample_file.name}\")\n",
    "else:\n",
    "    print(\"\\nâŒ Nessuna feature trovata!\")\n",
    "\n",
    "# 4. Verifica encoder checkpoint\n",
    "encoder_ckpt = Path(\"checkpoints/sonar_encoder_finetuned/best_encoder.pt\")\n",
    "print(f\"\\nğŸ” ENCODER CHECKPOINT:\")\n",
    "if encoder_ckpt.exists():\n",
    "    import torch\n",
    "\n",
    "    ckpt = torch.load(encoder_ckpt, map_location=\"cpu\")\n",
    "    print(f\"   âœ… Found: {encoder_ckpt}\")\n",
    "    print(f\"   Epoch: {ckpt.get('epoch', 'N/A')}\")\n",
    "    print(\n",
    "        f\"   Val Loss: {ckpt.get('val_loss', 'N/A'):.4f}\"\n",
    "        if \"val_loss\" in ckpt\n",
    "        else \"   Val Loss: N/A\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"   âš ï¸ NOT FOUND - training partirÃ  da zero\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b5d14",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Verifica Dataset e Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01fa42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Cambia directory al progetto\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "\n",
    "print(\"âœ… Google Drive montato\")\n",
    "print(\"\\nğŸ“‚ Struttura directory:\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25224618",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Mount Google Drive e Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0c7fb",
   "metadata": {},
   "source": [
    "# ğŸ“ SONAR Encoder-Decoder Fine-Tuning su How2Sign\n",
    "\n",
    "Questo notebook esegue il fine-tuning completo di **SONAR Encoder + SONAR Decoder** per traduzione ASLâ†’English.\n",
    "\n",
    "## ğŸ“‹ Pipeline:\n",
    "\n",
    "1. **SONAR Encoder** (fine-tuned su ASL) â†’ Embedding 1024-dim\n",
    "2. **SONAR Decoder** (pre-trained multilingue) â†’ Testo inglese\n",
    "\n",
    "## ğŸ¯ Obiettivo:\n",
    "\n",
    "- BLEU Score atteso: **30-40%** (vs 0% con approcci errati)\n",
    "- Dataset: How2Sign (train, val, test)\n",
    "\n",
    "---\n",
    "\n",
    "**Autore**: Ignazio Picciche  \n",
    "**Data**: Novembre 2024\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
