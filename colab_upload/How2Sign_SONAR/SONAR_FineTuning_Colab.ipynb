{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906737bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ Training Completato!\n",
    "\n",
    "### ğŸ“‹ Checklist Finale:\n",
    "\n",
    "- âœ… Dataset verificato (features + manifests)\n",
    "- âœ… fairseq2 installato correttamente\n",
    "- âœ… Quick test eseguito (5 epochs)\n",
    "- âœ… Training completo (50 epochs)\n",
    "- âœ… BLEU score calcolato su validation set\n",
    "- âœ… Checkpoint salvati e backuppati\n",
    "- âœ… Risultati visualizzati e analizzati\n",
    "\n",
    "### ğŸ¯ Prossimi Passi:\n",
    "\n",
    "1. **Test su Test Set**: Esegui inferenza su `manifests/test.tsv`\n",
    "2. **Confronto Modelli**: Compara con baseline e altri approcci\n",
    "3. **Error Analysis**: Analizza predizioni errate per miglioramenti\n",
    "4. **Deployment**: Prepara modello per utilizzo in produzione\n",
    "\n",
    "### ğŸ“Š BLEU Score Atteso:\n",
    "\n",
    "- **Target**: 30-40% BLEU\n",
    "- **Baseline**: ~0% (approcci naive)\n",
    "- **SOTR paper**: ~35% BLEU su How2Sign\n",
    "\n",
    "---\n",
    "\n",
    "**Fine del Notebook** ğŸ“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de296da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Crea backup directory con timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_dir = Path(f\"backups/sonar_full_{timestamp}\")\n",
    "backup_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ’¾ BACKUP CHECKPOINTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Files da backuppare\n",
    "files_to_backup = [\n",
    "    \"checkpoints/sonar_full_finetuned/best_model.pt\",\n",
    "    \"checkpoints/sonar_full_finetuned/training_log.json\",\n",
    "    \"checkpoints/sonar_full_finetuned/training_curves.png\",\n",
    "    \"results_validation.json\",\n",
    "    \"results_validation.csv\",\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“‚ Backup directory: {backup_dir}\\n\")\n",
    "\n",
    "for file_path in files_to_backup:\n",
    "    src = Path(file_path)\n",
    "    if src.exists():\n",
    "        dst = backup_dir / src.name\n",
    "        shutil.copy2(src, dst)\n",
    "        size_mb = dst.stat().st_size / (1024 * 1024)\n",
    "        print(f\"âœ… {src.name:<30} ({size_mb:>6.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  {src.name:<30} (NOT FOUND)\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Backup completato in: {backup_dir}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e62e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9ï¸âƒ£ Backup Checkpoints su Drive\n",
    "\n",
    "Assicurati di salvare i checkpoint migliori!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Carica risultati inferenza\n",
    "results_path = Path(\"results_validation.json\")\n",
    "\n",
    "if results_path.exists():\n",
    "    with open(results_path, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ğŸ“Š RISULTATI VALIDATION SET\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    print(f\"\\nğŸ¯ Metriche Globali:\")\n",
    "    print(f\"   BLEU Score: {results.get('bleu', 'N/A'):.2f}%\")\n",
    "    print(f\"   Samples: {results.get('n_samples', 'N/A')}\")\n",
    "\n",
    "    # Mostra sample predictions\n",
    "    if \"predictions\" in results:\n",
    "        print(f\"\\nğŸ“ Sample Predictions (primi 10):\")\n",
    "        print(\"â”€\" * 70)\n",
    "\n",
    "        df = pd.DataFrame(results[\"predictions\"][:10])\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            print(f\"\\n{idx+1}. Video: {row['video_id']}\")\n",
    "            print(f\"   Reference:  {row['reference']}\")\n",
    "            print(f\"   Prediction: {row['prediction']}\")\n",
    "            print(f\"   {'â”€' * 66}\")\n",
    "\n",
    "        # Salva tutti i risultati in CSV\n",
    "        df_full = pd.DataFrame(results[\"predictions\"])\n",
    "        csv_path = \"results_validation.csv\"\n",
    "        df_full.to_csv(csv_path, index=False)\n",
    "        print(f\"\\nğŸ’¾ Tutti i risultati salvati in: {csv_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "else:\n",
    "    print(f\"âŒ File risultati non trovato: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e7750",
   "metadata": {},
   "source": [
    "### ğŸ“Š Analisi Predizioni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726af2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esegui inferenza su validation set completo\n",
    "!python run_inference.py \\\n",
    "    --checkpoint checkpoints/sonar_full_finetuned/best_model.pt \\\n",
    "    --features_dir features/val \\\n",
    "    --manifest manifests/val.tsv \\\n",
    "    --output results_validation.json \\\n",
    "    --batch_size 32 \\\n",
    "    --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa055ef2",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Test Inference su Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Carica best model\n",
    "checkpoint_path = Path(\"checkpoints/sonar_full_finetuned/best_model.pt\")\n",
    "log_path = Path(\"checkpoints/sonar_full_finetuned/training_log.json\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“Š RISULTATI FINALI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "    print(f\"\\nğŸ† BEST MODEL:\")\n",
    "    print(f\"   Checkpoint: {checkpoint_path}\")\n",
    "    print(f\"   Epoch: {ckpt.get('epoch', 'N/A')}\")\n",
    "    print(f\"   BLEU Score: {ckpt.get('val_bleu', 0):.2f}%\")\n",
    "    print(\n",
    "        f\"   Train Loss: {ckpt.get('train_loss', 'N/A'):.4f}\"\n",
    "        if \"train_loss\" in ckpt\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    # Plot training curves\n",
    "    if log_path.exists():\n",
    "        with open(log_path, \"r\") as f:\n",
    "            log = json.load(f)\n",
    "\n",
    "        epochs = [e[\"epoch\"] for e in log]\n",
    "        bleus = [e.get(\"val_bleu\", 0) for e in log]\n",
    "        losses = [e.get(\"train_loss\", 0) for e in log]\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "        # BLEU curve\n",
    "        ax1.plot(epochs, bleus, \"b-o\", linewidth=2, markersize=6)\n",
    "        ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
    "        ax1.set_ylabel(\"BLEU Score (%)\", fontsize=12)\n",
    "        ax1.set_title(\"Validation BLEU Score\", fontsize=14, fontweight=\"bold\")\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.axhline(\n",
    "            y=max(bleus),\n",
    "            color=\"r\",\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.5,\n",
    "            label=f\"Best: {max(bleus):.2f}%\",\n",
    "        )\n",
    "        ax1.legend()\n",
    "\n",
    "        # Loss curve\n",
    "        ax2.plot(epochs, losses, \"r-o\", linewidth=2, markersize=6)\n",
    "        ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
    "        ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "        ax2.set_title(\"Training Loss\", fontsize=14, fontweight=\"bold\")\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            \"checkpoints/sonar_full_finetuned/training_curves.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"\\nğŸ“ˆ Training curves salvate in: training_curves.png\")\n",
    "\n",
    "    # Statistiche training\n",
    "    print(f\"\\nğŸ“Š STATISTICHE:\")\n",
    "    print(f\"   Total epochs: {len(log) if log_path.exists() else 'N/A'}\")\n",
    "    print(f\"   Best BLEU: {max(bleus):.2f}%\" if log_path.exists() else \"\")\n",
    "    print(f\"   Final Loss: {losses[-1]:.4f}\" if log_path.exists() and losses else \"\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nâŒ Checkpoint non trovato!\")\n",
    "    print(f\"   Path: {checkpoint_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290bd50f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7ï¸âƒ£ Analisi Risultati Finali\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "log_file = Path(\"checkpoints/sonar_full_finetuned/training_log.json\")\n",
    "\n",
    "if not log_file.exists():\n",
    "    print(f\"â³ Waiting for training to start...\")\n",
    "    print(f\"   Log file: {log_file}\")\n",
    "else:\n",
    "    # Monitor ogni 30 secondi\n",
    "    for _ in range(100):  # Max 50 minuti di monitoring\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        try:\n",
    "            with open(log_file, \"r\") as f:\n",
    "                log = json.load(f)\n",
    "\n",
    "            print(\"=\" * 70)\n",
    "            print(\"ğŸ“Š TRAINING PROGRESS\")\n",
    "            print(\"=\" * 70)\n",
    "\n",
    "            # Mostra ultimi 10 epoch\n",
    "            recent = log[-10:] if len(log) > 10 else log\n",
    "\n",
    "            for entry in recent:\n",
    "                epoch = entry.get(\"epoch\", \"?\")\n",
    "                train_loss = entry.get(\"train_loss\", 0)\n",
    "                val_bleu = entry.get(\"val_bleu\", 0)\n",
    "                print(\n",
    "                    f\"Epoch {epoch:>3}: Loss={train_loss:>7.4f} | BLEU={val_bleu:>5.2f}%\"\n",
    "                )\n",
    "\n",
    "            # Best model so far\n",
    "            best_entry = max(log, key=lambda x: x.get(\"val_bleu\", 0))\n",
    "            print(\"\\n\" + \"â”€\" * 70)\n",
    "            print(\n",
    "                f\"ğŸ† BEST: Epoch {best_entry['epoch']} | BLEU = {best_entry['val_bleu']:.2f}%\"\n",
    "            )\n",
    "            print(\"=\" * 70)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error reading log: {e}\")\n",
    "\n",
    "        time.sleep(30)  # Aggiorna ogni 30 secondi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bc1ce",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Monitoring Training (Esegui in Parallelo)\n",
    "\n",
    "Mentre il training Ã¨ in corso, puoi monitorare i progressi con questa cella.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training completo - Full dataset, 50 epochs\n",
    "\n",
    "# IMPORTANTE: Assicurati di essere nella directory corretta!\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "print(f\"ğŸ“‚ Working directory: {os.getcwd()}\\n\")\n",
    "\n",
    "!python train_sonar_finetuning.py \\\n",
    "    --encoder_checkpoint checkpoints/sonar_encoder_finetuned/best_encoder.pt \\\n",
    "    --train_features features/train \\\n",
    "    --train_manifest manifests/train.tsv \\\n",
    "    --val_features features/val \\\n",
    "    --val_manifest manifests/val.tsv \\\n",
    "    --output_dir checkpoints/sonar_full_finetuned \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 32 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --eval_every 5 \\\n",
    "    --save_every 10 \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… TRAINING COMPLETATO!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e2ceca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5ï¸âƒ£ Training Completo (50 epochs, full dataset)\n",
    "\n",
    "âš ï¸ **ESEGUI SOLO SE IL QUICK TEST Ãˆ ANDATO BENE!**\n",
    "\n",
    "â±ï¸ Tempo stimato: **2-4 ore** su GPU T4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Verifica checkpoint salvato\n",
    "test_ckpt = Path(\"checkpoints/sonar_full_test/best_model.pt\")\n",
    "if test_ckpt.exists():\n",
    "    print(\"âœ… Quick test completato con successo!\")\n",
    "    print(f\"   Checkpoint: {test_ckpt}\")\n",
    "\n",
    "    # Carica info checkpoint\n",
    "    import torch\n",
    "\n",
    "    ckpt = torch.load(test_ckpt, map_location=\"cpu\")\n",
    "    print(f\"\\nğŸ“Š Risultati:\")\n",
    "    print(f\"   Best Epoch: {ckpt.get('epoch', 'N/A')}\")\n",
    "    print(f\"   Best BLEU: {ckpt.get('val_bleu', 0):.2f}%\")\n",
    "    print(\n",
    "        f\"   Train Loss: {ckpt.get('train_loss', 'N/A'):.4f}\"\n",
    "        if \"train_loss\" in ckpt\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nğŸš€ Procedi con il training completo nella prossima cella!\")\n",
    "else:\n",
    "    print(\"âŒ Quick test fallito - verifica errori sopra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18dbdc",
   "metadata": {},
   "source": [
    "### ğŸ“Š Verifica Risultati Quick Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Quick test - 5 epochs, 100 samples per verificare setup\n",
    "\n",
    "# IMPORTANTE: Assicurati di essere nella directory corretta!\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "print(f\"ğŸ“‚ Working directory: {os.getcwd()}\")\n",
    "print(f\"ğŸ“„ Script exists: {os.path.exists('train_sonar_finetuning.py')}\\n\")\n",
    "\n",
    "!python train_sonar_finetuning.py \\\n",
    "    --encoder_checkpoint checkpoints/sonar_encoder_finetuned/best_encoder.pt \\\n",
    "    --train_features features/train \\\n",
    "    --train_manifest manifests/train.tsv \\\n",
    "    --val_features features/val \\\n",
    "    --val_manifest manifests/val.tsv \\\n",
    "    --output_dir checkpoints/sonar_full_test \\\n",
    "    --epochs 5 \\\n",
    "    --batch_size 16 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --max_samples 100 \\\n",
    "    --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8fb878",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4ï¸âƒ£ Quick Test (5 epochs, 100 samples)\n",
    "\n",
    "Prima di lanciare il training completo, facciamo un test veloce per verificare che tutto funzioni.\n",
    "\n",
    "**âœ… LO SCRIPT Ãˆ STATO AGGIORNATO!**\n",
    "\n",
    "Modifiche principali:\n",
    "- âœ… Usa API SONAR corretta (`sonar-space` package)\n",
    "- âœ… Import da `sonar.inference_pipelines.text` invece di `fairseq2.models.sonar`\n",
    "- âœ… Decoder SONAR reale (non piÃ¹ placeholder)\n",
    "- âœ… Target embeddings calcolati da testi veri\n",
    "- âœ… Gradient clipping per stabilitÃ \n",
    "\n",
    "Vedi dettagli completi in: `SONAR_SCRIPT_FIX.md`\n",
    "\n",
    "---\n",
    "\n",
    "**âš ï¸ PREREQUISITO**: Assicurati di aver eseguito:\n",
    "\n",
    "1. âœ… Cella 1 (Mount Drive)\n",
    "2. âœ… Cella 2 (Verifica Dataset)\n",
    "3. âœ… Cella 3-bis (Verifica Setup) â†’ SONAR deve essere installato!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1f902",
   "metadata": {},
   "source": [
    "### âœ… Verifica Pre-Training\n",
    "\n",
    "**Esegui questa cella PRIMA del Quick Test** per verificare che tutto sia pronto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… CHECKLIST PRE-TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "checks_passed = 0\n",
    "total_checks = 5\n",
    "\n",
    "# 1. Verifica directory corretta\n",
    "print(\"\\n1ï¸âƒ£ Verifica directory di lavoro...\")\n",
    "expected_dir = \"/content/drive/MyDrive/How2Sign_SONAR\"\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "if current_dir == expected_dir:\n",
    "    print(f\"   âœ… Directory corretta: {current_dir}\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"   âŒ Directory errata!\")\n",
    "    print(f\"      Attuale: {current_dir}\")\n",
    "    print(f\"      Attesa:  {expected_dir}\")\n",
    "    print(f\"   ğŸ”§ Esegui: os.chdir('{expected_dir}')\")\n",
    "\n",
    "# 2. Verifica script esiste\n",
    "print(\"\\n2ï¸âƒ£ Verifica script train_sonar_finetuning.py...\")\n",
    "script_path = Path(\"train_sonar_finetuning.py\")\n",
    "if script_path.exists():\n",
    "    print(f\"   âœ… Script trovato: {script_path}\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"   âŒ Script NON trovato!\")\n",
    "    print(f\"   ğŸ”§ Assicurati di aver caricato lo script su Drive\")\n",
    "\n",
    "# 3. Verifica SONAR installato\n",
    "print(\"\\n3ï¸âƒ£ Verifica SONAR installato...\")\n",
    "try:\n",
    "    from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline\n",
    "\n",
    "    print(f\"   âœ… SONAR importato correttamente\")\n",
    "    checks_passed += 1\n",
    "except ImportError:\n",
    "    print(f\"   âŒ SONAR non installato!\")\n",
    "    print(f\"   ğŸ”§ Torna alle celle di installazione\")\n",
    "\n",
    "# 4. Verifica encoder checkpoint\n",
    "print(\"\\n4ï¸âƒ£ Verifica encoder checkpoint...\")\n",
    "encoder_path = Path(\"checkpoints/sonar_encoder_finetuned/best_encoder.pt\")\n",
    "if encoder_path.exists():\n",
    "    print(f\"   âœ… Encoder checkpoint trovato\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"   âŒ Encoder checkpoint NON trovato!\")\n",
    "    print(f\"   ğŸ”§ Path: {encoder_path}\")\n",
    "\n",
    "# 5. Verifica features e manifests\n",
    "print(\"\\n5ï¸âƒ£ Verifica dataset...\")\n",
    "train_manifest = Path(\"manifests/train.tsv\")\n",
    "val_manifest = Path(\"manifests/val.tsv\")\n",
    "train_features = Path(\"features/train\")\n",
    "val_features = Path(\"features/val\")\n",
    "\n",
    "if all(\n",
    "    [\n",
    "        train_manifest.exists(),\n",
    "        val_manifest.exists(),\n",
    "        train_features.exists(),\n",
    "        val_features.exists(),\n",
    "    ]\n",
    "):\n",
    "    print(f\"   âœ… Dataset completo (features + manifests)\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"   âŒ Dataset incompleto!\")\n",
    "    print(f\"      train.tsv: {train_manifest.exists()}\")\n",
    "    print(f\"      val.tsv: {val_manifest.exists()}\")\n",
    "    print(f\"      features/train: {train_features.exists()}\")\n",
    "    print(f\"      features/val: {val_features.exists()}\")\n",
    "\n",
    "# Risultato finale\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"ğŸ“Š RISULTATO: {checks_passed}/{total_checks} controlli superati\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if checks_passed == total_checks:\n",
    "    print(\"\\nğŸ‰ TUTTO PRONTO!\")\n",
    "    print(\"ğŸ‘‰ Procedi con il Quick Test nella cella successiva\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  {total_checks - checks_passed} problemi da risolvere\")\n",
    "    print(\"ğŸ‘‰ Risolvi i problemi sopra prima di continuare\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3bd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSTALLA DIPENDENZE AGGIUNTIVE\n",
    "# ============================================================================\n",
    "# NOTA: Questo presuppone che tu abbia GIÃ€ eseguito setup iniziale:\n",
    "#   1. pip install numpy>=2,<2.3\n",
    "#   2. pip install torch 2.9.0 + cu126\n",
    "#   3. pip install fairseq2 --no-deps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“¦ INSTALLAZIONE DIPENDENZE AGGIUNTIVE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Installa dipendenze mancanti di fairseq2 (mantenendo numpy 2.x)\n",
    "print(\"\\n1ï¸âƒ£ Installazione componenti fairseq2...\")\n",
    "!pip install fairseq2n==0.7.0\n",
    "\n",
    "# INSTALLA SONAR (pacchetto SEPARATO da fairseq2!)\n",
    "print(\"\\n2ï¸âƒ£ Installazione SONAR (sonar-space)...\")\n",
    "!pip install \"sonar-space>=0.5.0\"\n",
    "\n",
    "# Dipendenze aggiuntive\n",
    "print(\"\\n3ï¸âƒ£ Installazione dipendenze extra...\")\n",
    "!pip install sentencepiece pyyaml tqdm sacrebleu pandas\n",
    "\n",
    "# Verifica installazione SONAR\n",
    "print(\"\\n4ï¸âƒ£ Verifica installazione SONAR...\")\n",
    "!pip show sonar-space\n",
    "\n",
    "# RIAVVIO RUNTIME NECESSARIO per caricare nuovi moduli\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âš ï¸  IMPORTANTE: RIAVVIA IL RUNTIME ORA!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nğŸ“ Dopo il riavvio:\")\n",
    "print(\"   1. Riesegui dalla Cella 1 (Mount Drive)\")\n",
    "print(\"   2. Salta la Cella 3 (giÃ  eseguita)\")\n",
    "print(\"   3. Continua con Cella 3-bis (Verifica)\")\n",
    "print(\"\\nâš ï¸  Runtime â†’ Restart runtime\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45238542",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Installa Dipendenze\n",
    "\n",
    "âš ï¸ **PREREQUISITO**: Assicurati di aver giÃ  eseguito PRIMA del notebook:\n",
    "\n",
    "```python\n",
    "# Setup iniziale (ESEGUI PRIMA DEL NOTEBOOK)\n",
    "!pip install -U \"numpy>=2,<2.3\"\n",
    "!pip install -U torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install -U --no-deps fairseq2 --extra-index-url https://fair.pkg.atmeta.com/fairseq2/whl/pt2.9.0/cu126\n",
    "```\n",
    "\n",
    "Questa cella installa:\n",
    "\n",
    "1. **fairseq2n** - Componente nativo con modelli base\n",
    "2. **sonar-space** - Pacchetto SONAR (SEPARATO da fairseq2!)\n",
    "3. **Dipendenze extra** - sentencepiece, pyyaml, sacrebleu, etc.\n",
    "\n",
    "**IMPORTANTE**: SONAR NON Ã¨ parte di fairseq2, Ã¨ un progetto separato!\n",
    "\n",
    "Lo script `train_sonar_finetuning.py` Ã¨ stato **RISCRITTO** per usare l'API corretta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cb5a4",
   "metadata": {},
   "source": [
    "### ğŸ” Diagnostica Pre-Installazione\n",
    "\n",
    "Esegui questa cella PRIMA della cella 3 per vedere cosa Ã¨ giÃ  installato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ” DIAGNOSTICA PACCHETTI INSTALLATI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "packages_to_check = [\n",
    "    (\"numpy\", \"NumPy\"),\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"fairseq2\", \"fairseq2\"),\n",
    "    (\"fairseq2n\", \"fairseq2n\"),\n",
    "    (\"sonar-space\", \"SONAR\"),\n",
    "    (\"sentencepiece\", \"SentencePiece\"),\n",
    "    (\"sacrebleu\", \"SacreBLEU\"),\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“¦ Pacchetti installati:\\n\")\n",
    "\n",
    "for package, name in packages_to_check:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"show\", package], capture_output=True, text=True\n",
    "    )\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        # Estrai versione\n",
    "        for line in result.stdout.split(\"\\n\"):\n",
    "            if line.startswith(\"Version:\"):\n",
    "                version = line.split(\"Version:\")[1].strip()\n",
    "                print(f\"âœ… {name:<20} v{version}\")\n",
    "                break\n",
    "    else:\n",
    "        print(f\"âŒ {name:<20} NON INSTALLATO\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ“ PROSSIMI PASSI:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Controlla se sonar-space Ã¨ installato\n",
    "sonar_result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"show\", \"sonar-space\"], capture_output=True, text=True\n",
    ")\n",
    "\n",
    "if sonar_result.returncode != 0:\n",
    "    print(\"\\nâš ï¸  sonar-space NON Ã¨ installato!\")\n",
    "    print(\"   â†’ Procedi con Cella 3 per installarlo\")\n",
    "else:\n",
    "    print(\"\\nâœ… sonar-space Ã¨ giÃ  installato!\")\n",
    "    print(\"   â†’ Salta Cella 3 e vai a Cella 3-bis (Verifica)\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"âœ… VERIFICA SETUP COMPLETO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verifica PyTorch\n",
    "import torch\n",
    "\n",
    "print(f\"\\nğŸ”¥ PyTorch: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ CUDA not available - training su CPU (molto lento!)\")\n",
    "\n",
    "# Verifica numpy\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\nğŸ“Š NumPy: {np.__version__}\")\n",
    "if not np.__version__.startswith(\"2.\"):\n",
    "    print(f\"   âŒ ERROR: NumPy dovrebbe essere 2.x, trovato {np.__version__}\")\n",
    "    print(f\"   ğŸ”§ SOLUZIONE: Esegui setup iniziale di nuovo\")\n",
    "else:\n",
    "    print(f\"   âœ… NumPy versione corretta\")\n",
    "\n",
    "# Verifica fairseq2\n",
    "print(f\"\\nğŸ” Verifica fairseq2...\")\n",
    "try:\n",
    "    import fairseq2\n",
    "\n",
    "    print(f\"   âœ… fairseq2: v{fairseq2.__version__}\")\n",
    "\n",
    "    # Verifica fairseq2n\n",
    "    import fairseq2n\n",
    "\n",
    "    print(f\"   âœ… fairseq2n disponibile\")\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"   âŒ ModuleNotFoundError: {e}\")\n",
    "    print(f\"\\nğŸ”§ PROBLEMA: Modulo mancante\")\n",
    "    print(f\"   SOLUZIONE:\")\n",
    "    print(f\"   1. Torna alla Cella 3\")\n",
    "    print(f\"   2. Riesegui l'installazione\")\n",
    "    print(f\"   3. Riavvia runtime\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ ERROR: {e}\")\n",
    "\n",
    "# Verifica SONAR (pacchetto SEPARATO!)\n",
    "print(f\"\\nğŸ¯ Verifica SONAR (sonar-space)...\")\n",
    "try:\n",
    "    import sonar\n",
    "\n",
    "    print(f\"   âœ… sonar: disponibile\")\n",
    "\n",
    "    # Test import pipelines SONAR\n",
    "    from sonar.inference_pipelines.text import (\n",
    "        TextToEmbeddingModelPipeline,\n",
    "        EmbeddingToTextModelPipeline,\n",
    "    )\n",
    "\n",
    "    print(f\"   âœ… SONAR text pipelines importate!\")\n",
    "\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"ğŸ‰ TUTTO PRONTO PER IL TRAINING!\")\n",
    "    print(f\"=\" * 70)\n",
    "    print(f\"\\nğŸ‘‰ Procedi con Cella 4 (Quick Test)\")\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"   âŒ ModuleNotFoundError: {e}\")\n",
    "    print(f\"\\nğŸ”§ PROBLEMA: SONAR non installato\")\n",
    "    print(f\"   SOLUZIONE:\")\n",
    "    print(f\"   1. Torna alla Cella 3\")\n",
    "    print(f\"   2. Verifica che sonar-space sia installato\")\n",
    "    print(f\"   3. Riavvia runtime\")\n",
    "    print(f\"   4. Riesegui Celle 1, 2, poi questa\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ ERROR: {e}\")\n",
    "    print(f\"   Tipo: {type(e).__name__}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test identico a quello che DOVREBBE fare lo script\n",
    "print(\"ğŸ§ª Test importazione SONAR (pacchetto corretto)...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prima verifica se il pacchetto Ã¨ installato\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"\\nğŸ“¦ Verifica pacchetto sonar-space installato...\")\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"show\", \"sonar-space\"], capture_output=True, text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… sonar-space Ã¨ installato!\")\n",
    "    print(f\"\\n{result.stdout}\")\n",
    "else:\n",
    "    print(\"âŒ sonar-space NON Ã¨ installato!\")\n",
    "    print(\"\\nğŸ”§ INSTALLA ORA:\")\n",
    "    print('   !pip install \"sonar-space>=0.5.0\"')\n",
    "    print(\"\\nPoi riavvia il runtime e riprova.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ§ª Test import SONAR pipelines...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "SONAR_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    # SONAR Ã¨ un pacchetto SEPARATO da fairseq2!\n",
    "    from sonar.inference_pipelines.text import (\n",
    "        TextToEmbeddingModelPipeline,\n",
    "        EmbeddingToTextModelPipeline,\n",
    "    )\n",
    "\n",
    "    SONAR_AVAILABLE = True\n",
    "    print(\"âœ… SUCCESS: SONAR text pipelines importati!\")\n",
    "    print(f\"   SONAR_AVAILABLE = {SONAR_AVAILABLE}\")\n",
    "    print(\"\\nğŸ‰ SONAR funziona correttamente!\")\n",
    "    print(\"\\nâœ… Lo script train_sonar_finetuning.py Ã¨ stato AGGIORNATO!\")\n",
    "    print(\"   - Usa: from sonar.inference_pipelines.text import ...\")\n",
    "    print(\"   - Dovrebbe funzionare correttamente ora!\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ImportError: {e}\")\n",
    "    print(f\"   SONAR_AVAILABLE = {SONAR_AVAILABLE}\")\n",
    "    print(\"\\nğŸ”´ PROBLEMA: SONAR non importabile!\")\n",
    "    print(\"\\nğŸ’¡ SOLUZIONE:\")\n",
    "    print(\"   1. Torna alla Cella 3 e riesegui (senza -q)\")\n",
    "    print(\"   2. Verifica che l'installazione completi senza errori\")\n",
    "    print(\"   3. Runtime â†’ Restart runtime\")\n",
    "    print(\"   4. Riesegui Celle 1, 2, poi questa\")\n",
    "    print(\"\\nâš ï¸  Se persiste, prova:\")\n",
    "    print(\"   !pip uninstall -y sonar-space\")\n",
    "    print('   !pip install \"sonar-space==0.5.0\" --no-cache-dir')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Errore: {e}\")\n",
    "    print(f\"   Tipo: {type(e).__name__}\")\n",
    "    print(f\"   SONAR_AVAILABLE = {SONAR_AVAILABLE}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96941a",
   "metadata": {},
   "source": [
    "### ğŸ”§ Installazione Manuale SONAR\n",
    "\n",
    "**ESEGUI QUESTA CELLA** se il test sopra ha mostrato che `sonar-space` non Ã¨ installato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ed94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ INSTALLAZIONE MANUALE SONAR-SPACE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Installazione con output completo (no -q)\n",
    "print(\"\\nğŸ“¦ Installazione sonar-space con dipendenze...\")\n",
    "!pip install \"sonar-space>=0.5.0\" --no-cache-dir\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… INSTALLAZIONE COMPLETATA!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verifica immediata\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"show\", \"sonar-space\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\nâœ… sonar-space Ã¨ stato installato correttamente!\")\n",
    "    print(f\"\\n{result.stdout}\")\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"âš ï¸  RIAVVIA IL RUNTIME ORA!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nğŸ“ Dopo il riavvio:\")\n",
    "    print(\"   1. Riesegui Celle 1, 2\")\n",
    "    print(\"   2. Esegui cella 'Test Importazione SONAR'\")\n",
    "    print(\"   3. Se funziona âœ… â†’ Procedi con Quick Test\")\n",
    "else:\n",
    "    print(\"\\nâŒ Installazione fallita!\")\n",
    "    print(\"\\nğŸ”§ ERRORI DA VERIFICARE:\")\n",
    "    print(\"   - CompatibilitÃ  versioni PyTorch/fairseq2?\")\n",
    "    print(\"   - Dipendenze mancanti?\")\n",
    "    print(\"\\nğŸ’¡ Prova versione specifica:\")\n",
    "    print('   !pip install \"sonar-space==0.5.0\" --no-cache-dir')\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e3756b",
   "metadata": {},
   "source": [
    "### ğŸ”§ Alternativa: Installazione con Versione Specifica\n",
    "\n",
    "**Esegui SOLO se l'installazione sopra ha dato errori**. Usa versione esatta invece di `>=0.5.0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ INSTALLAZIONE SONAR-SPACE (Versione Esatta)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Disinstalla prima se esiste\n",
    "print(\"\\n1ï¸âƒ£ Rimozione versione precedente (se esiste)...\")\n",
    "!pip uninstall -y sonar-space\n",
    "\n",
    "# Installa versione specifica 0.5.0\n",
    "print(\"\\n2ï¸âƒ£ Installazione sonar-space==0.5.0...\")\n",
    "!pip install \"sonar-space==0.5.0\" --no-cache-dir -v\n",
    "\n",
    "# Verifica\n",
    "print(\"\\n3ï¸âƒ£ Verifica installazione...\")\n",
    "!pip show sonar-space\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âš ï¸  RIAVVIA IL RUNTIME!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nDopo riavvio: Celle 1, 2 â†’ Test Importazione\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0cb8a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### âœ… AGGIORNAMENTO: train_sonar_finetuning.py Ã¨ stato CORRETTO!\n",
    "\n",
    "**Problema (RISOLTO)**: Lo script cercava di importare:\n",
    "```python\n",
    "from fairseq2.models.sonar import load_sonar_text_decoder  # âŒ NON ESISTE\n",
    "```\n",
    "\n",
    "**Soluzione (APPLICATA)**: Lo script ora usa:\n",
    "```python\n",
    "from sonar.inference_pipelines.text import (\n",
    "    TextToEmbeddingModelPipeline,\n",
    "    EmbeddingToTextModelPipeline,\n",
    ")\n",
    "```\n",
    "\n",
    "**Dettagli**:\n",
    "- **Nome pacchetto**: `sonar-space` (su PyPI)\n",
    "- **Import corretto**: `from sonar.inference_pipelines.text import ...`\n",
    "- **Documentazione**: https://github.com/facebookresearch/SONAR\n",
    "\n",
    "**âœ… Lo script Ã¨ stato riscritto e dovrebbe funzionare dopo l'installazione di sonar-space!**\n",
    "\n",
    "Vedi dettagli completi in: `SONAR_SCRIPT_FIX.md`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ae365",
   "metadata": {},
   "source": [
    "### ğŸ§ª Test Importazione SONAR (pacchetto corretto)\n",
    "\n",
    "**PROBLEMA RISOLTO**: `fairseq2.models.sonar` NON ESISTE!\n",
    "\n",
    "SONAR Ã¨ un **pacchetto separato** chiamato `sonar-space`, non parte di fairseq2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9430b",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ bis - Verifica Setup (DOPO RIAVVIO)\n",
    "\n",
    "âœ… **Esegui questa cella DOPO aver riavviato il runtime dalla cella precedente**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“Š VERIFICA DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Conta features (supporta .pt e .npy)\n",
    "train_features = len(list(Path(\"features/train\").glob(\"*.pt\"))) + len(\n",
    "    list(Path(\"features/train\").glob(\"*.npy\"))\n",
    ")\n",
    "val_features = len(list(Path(\"features/val\").glob(\"*.pt\"))) + len(\n",
    "    list(Path(\"features/val\").glob(\"*.npy\"))\n",
    ")\n",
    "test_features = len(list(Path(\"features/test\").glob(\"*.pt\"))) + len(\n",
    "    list(Path(\"features/test\").glob(\"*.npy\"))\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“¦ FEATURES DISPONIBILI:\")\n",
    "print(f\"   Train: {train_features:>4} files\")\n",
    "print(f\"   Val:   {val_features:>4} files\")\n",
    "print(f\"   Test:  {test_features:>4} files\")\n",
    "print(f\"   {'â”€' * 20}\")\n",
    "print(f\"   TOTAL: {train_features + val_features + test_features:>4} files\")\n",
    "\n",
    "# 2. Verifica manifests\n",
    "print(\"\\nğŸ“‹ MANIFESTS:\")\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    manifest_path = Path(f\"manifests/{split}.tsv\")\n",
    "    if manifest_path.exists():\n",
    "        n_lines = sum(1 for _ in open(manifest_path)) - 1  # -1 header\n",
    "        print(f\"   âœ… {split}.tsv: {n_lines} samples\")\n",
    "    else:\n",
    "        print(f\"   âŒ {split}.tsv: NOT FOUND\")\n",
    "\n",
    "# 3. Verifica sample feature\n",
    "sample_files = list(Path(\"features/train\").glob(\"*.pt\")) + list(\n",
    "    Path(\"features/train\").glob(\"*.npy\")\n",
    ")\n",
    "if sample_files:\n",
    "    sample_file = sample_files[0]\n",
    "    print(f\"\\nğŸ“ SAMPLE FEATURE:\")\n",
    "\n",
    "    if sample_file.suffix == \".pt\":\n",
    "        import torch\n",
    "\n",
    "        data = torch.load(sample_file, map_location=\"cpu\")\n",
    "        features = data[\"features\"]\n",
    "        print(f\"   Shape: {features.shape}\")\n",
    "        print(f\"   Format: PyTorch (.pt)\")\n",
    "        print(f\"   Video ID: {data.get('video_id', 'N/A')}\")\n",
    "        print(f\"   Text: {data.get('text', 'N/A')[:60]}...\")\n",
    "    else:\n",
    "        import numpy as np\n",
    "\n",
    "        features = np.load(sample_file)\n",
    "        print(f\"   Shape: {features.shape}\")\n",
    "        print(f\"   Format: NumPy (.npy)\")\n",
    "        print(f\"   File: {sample_file.name}\")\n",
    "else:\n",
    "    print(\"\\nâŒ Nessuna feature trovata!\")\n",
    "\n",
    "# 4. Verifica encoder checkpoint\n",
    "encoder_ckpt = Path(\"checkpoints/sonar_encoder_finetuned/best_encoder.pt\")\n",
    "print(f\"\\nğŸ” ENCODER CHECKPOINT:\")\n",
    "if encoder_ckpt.exists():\n",
    "    import torch\n",
    "\n",
    "    ckpt = torch.load(encoder_ckpt, map_location=\"cpu\")\n",
    "    print(f\"   âœ… Found: {encoder_ckpt}\")\n",
    "    print(f\"   Epoch: {ckpt.get('epoch', 'N/A')}\")\n",
    "    print(\n",
    "        f\"   Val Loss: {ckpt.get('val_loss', 'N/A'):.4f}\"\n",
    "        if \"val_loss\" in ckpt\n",
    "        else \"   Val Loss: N/A\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"   âš ï¸ NOT FOUND - training partirÃ  da zero\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b5d14",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Verifica Dataset e Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01fa42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Cambia directory al progetto\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/How2Sign_SONAR')\n",
    "\n",
    "print(\"âœ… Google Drive montato\")\n",
    "print(\"\\nğŸ“‚ Struttura directory:\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25224618",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Mount Google Drive e Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0c7fb",
   "metadata": {},
   "source": [
    "# ğŸ“ SONAR Encoder-Decoder Fine-Tuning su How2Sign\n",
    "\n",
    "Questo notebook esegue il fine-tuning completo di **SONAR Encoder + SONAR Decoder** per traduzione ASLâ†’English.\n",
    "\n",
    "## ğŸ“‹ Pipeline:\n",
    "\n",
    "1. **SONAR Encoder** (fine-tuned su ASL) â†’ Embedding 1024-dim\n",
    "2. **SONAR Decoder** (pre-trained multilingue) â†’ Testo inglese\n",
    "\n",
    "## ğŸ¯ Obiettivo:\n",
    "\n",
    "- BLEU Score atteso: **30-40%** (vs 0% con approcci errati)\n",
    "- Dataset: How2Sign (train, val, test)\n",
    "\n",
    "---\n",
    "\n",
    "**Autore**: Ignazio Picciche  \n",
    "**Data**: Novembre 2024\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
