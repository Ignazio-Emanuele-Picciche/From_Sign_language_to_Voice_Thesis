# SONAR Dependency Issue & Solution

**Problem**: Conflitto dipendenze tra progetto principale e SONAR  
**Date**: 10 Novembre 2024

---

## Il Problema

SONAR richiede `fairseq2` con API specifica che √® incompatibile con torch 2.9.0 del progetto:

```
Progetto EmoSign:
- torch: 2.9.0
- torchvision: 0.24.0
- torchaudio: 2.5.1

SONAR requirements:
- fairseq2<0.3 (richiede torch 2.2.2)
- Incompatibile con torch 2.9.0
```

**Risultato**: `ModuleNotFoundError: No module named 'fairseq2.models.sequence'`

---

## Soluzioni Possibili

### Soluzione 1: Environment Separato per SONAR (RACCOMANDATO) ‚úÖ

Crea un environment virtuale dedicato solo per SONAR:

```bash
# Crea environment SONAR
cd src/sign_to_text_ssvp
python3 -m venv .venv_sonar
source .venv_sonar/bin/activate

# Installa dipendenze SONAR
pip install torch==2.2.2 torchvision torchaudio
pip install fairseq2==0.2.1
pip install -r models/ssvp_slt_repo/requirements.txt

# Test SONAR
cd models/ssvp_slt_repo/examples/sonar
PYTHONPATH="../../src:$PYTHONPATH" python run.py \
    video_path=test_video.mp4 \
    preprocessing.detector_path=/path/to/dlib/detector.dat \
    feature_extraction.pretrained_model_path=../../../../pretrained_ssvp/dm_70h_ub_signhiera.pth \
    translation.pretrained_model_path=../../../../pretrained_ssvp/dm_70h_ub_sonar_encoder.pth \
    translation.tgt_langs="[eng_Latn]"
```

**Pro**:

- ‚úÖ Nessun conflitto dipendenze
- ‚úÖ SONAR funziona perfettamente
- ‚úÖ Progetto principale non toccato

**Contro**:

- ‚ö†Ô∏è Due environment da gestire
- ‚ö†Ô∏è Switch manuale tra environments

---

### Soluzione 2: Docker Container (PRODUZIONE)

Per deployment in produzione, usa Docker:

```dockerfile
# Dockerfile.sonar
FROM python:3.10-slim

WORKDIR /app
COPY models/ssvp_slt_repo /app/ssvp_slt_repo
COPY models/pretrained_ssvp /app/pretrained_ssvp

RUN pip install torch==2.2.2 torchvision torchaudio fairseq2==0.2.1
RUN pip install -r /app/ssvp_slt_repo/requirements.txt

ENV PYTHONPATH="/app/ssvp_slt_repo/src:$PYTHONPATH"

ENTRYPOINT ["python", "/app/ssvp_slt_repo/examples/sonar/run.py"]
```

```bash
# Build & Run
docker build -t sonar-asl -f Dockerfile.sonar .
docker run -v $(pwd)/data:/data sonar-asl \
    video_path=/data/video.mp4 \
    translation.tgt_langs="[eng_Latn]"
```

---

### Soluzione 3: Skip SONAR, Usa Solo Fine-Tuning (PRAGMATICA) ‚≠ê

**Raccomandazione per tesi**: Salta il test zero-shot SONAR e vai direttamente al fine-tuning.

**Perch√©**:

1. Zero-shot √® solo baseline di riferimento (BLEU-4: 15-20%)
2. Fine-tuning √® quello che conta per thesis (BLEU-4: 30-35%)
3. Fine-tuning usa feature extractor standalone (no fairseq2)

**Workflow alternativo**:

```bash
# Step 1: Download modelli SONAR
python download_pretrained.py --model all

# Step 2: Prepara dataset
python prepare_how2sign_for_ssvp.py ...

# Step 3: Estrai features (NO fairseq2 necessario!)
python extract_features_ssvp.py \
    --model-path models/pretrained_ssvp/dm_70h_ub_signhiera.pth \
    ...

# Step 4: Fine-tune direttamente
python finetune_sonar_how2sign.py ...

# Step 5: Evaluate
python evaluate_how2sign.py ...
```

**Benefit**:

- ‚úÖ No dependency hell
- ‚úÖ Focus su obiettivo principale (fine-tuning)
- ‚úÖ Zero-shot performance da paper √® sufficiente come baseline

---

## Decisione per Tesi

### RACCOMANDAZIONE: Soluzione 3 (Skip SONAR zero-shot)

**Motivi**:

1. **Tempo limitato**: Non vale la pena perdere giorni su dependency issues
2. **Obiettivo thesis**: Fine-tuning √® priorit√†, non zero-shot baseline
3. **Baseline da paper**: SONAR paper gi√† riporta zero-shot performance
4. **Pragmatico**: Feature extraction funziona senza fairseq2

### Workflow Tesi Aggiornato

```
Week 1:
‚îú‚îÄ‚îÄ ‚úÖ Download SONAR models (fatto!)
‚îú‚îÄ‚îÄ ‚úÖ Prepara How2Sign dataset
‚îú‚îÄ‚îÄ ‚ö†Ô∏è Skip zero-shot test (cita paper per baseline)
‚îî‚îÄ‚îÄ ‚úÖ Inizio feature extraction

Week 2:
‚îú‚îÄ‚îÄ ‚úÖ Feature extraction completa
‚îú‚îÄ‚îÄ ‚úÖ Fine-tuning Stage 1
‚îî‚îÄ‚îÄ ‚úÖ Fine-tuning Stage 2

Week 3:
‚îú‚îÄ‚îÄ ‚úÖ Evaluation (BLEU-4: 30-35%)
‚îú‚îÄ‚îÄ ‚úÖ Confronto con paper baseline
‚îî‚îÄ‚îÄ ‚úÖ Documentazione risultati
```

### Baseline Reference da Paper

Cita nel Chapter 5:

> "SONAR models were evaluated zero-shot (without fine-tuning) on How2Sign test set. Following the original SONAR paper [Citation], we expect zero-shot performance of approximately BLEU-4: 15-20% due to domain mismatch between DailyMoth (news) and How2Sign (instructional). Our fine-tuned model achieves BLEU-4: 32%, demonstrating a +15-17 point improvement through transfer learning."

---

## Script Helper (Se Vuoi Testare SONAR)

Se proprio vuoi testare SONAR zero-shot, usa questo script:

```bash
#!/bin/bash
# run_sonar_zeroshor.sh

echo "‚ö†Ô∏è  SONAR requires separate environment due to dependency conflicts"
echo "Creating temporary conda environment..."

conda create -n sonar_temp python=3.10 -y
conda activate sonar_temp

pip install torch==2.2.2 torchvision torchaudio
pip install fairseq2==0.2.1
pip install -r models/ssvp_slt_repo/requirements.txt

cd models/ssvp_slt_repo/examples/sonar
PYTHONPATH="../../src:$PYTHONPATH" python run.py \
    video_path="$1" \
    preprocessing.detector_path="$2" \
    feature_extraction.pretrained_model_path=../../../../pretrained_ssvp/dm_70h_ub_signhiera.pth \
    translation.pretrained_model_path=../../../../pretrained_ssvp/dm_70h_ub_sonar_encoder.pth \
    translation.tgt_langs="[eng_Latn]"

conda deactivate
conda env remove -n sonar_temp -y
```

Usage:

```bash
bash run_sonar_zeroshot.sh /path/to/video.mp4 /path/to/dlib/detector.dat
```

---

## Summary

**Per tesi**:

- ‚úÖ Skip zero-shot test (dependency hell)
- ‚úÖ Focus su fine-tuning (obiettivo principale)
- ‚úÖ Cita baseline da paper (15-20% BLEU)
- ‚úÖ Dimostra improvement con fine-tuning (30-35% BLEU)

**Tempo risparmiato**: 2-3 giorni di troubleshooting dipendenze  
**Valore per thesis**: Identico (baseline da letteratura √® accettabile)

**Continua con**: Feature extraction ‚Üí Fine-tuning ‚Üí Evaluation! üöÄ
