# SONAR Inference - Dependency Hell Summary

## Date: January 2025

## Objective

Attempt to run SONAR zero-shot inference using the SSVP-SLT repository code.

## Attempts Made

### Environment Setup

- Created separate virtual environment `.venv_sonar` to isolate dependencies
- Python 3.10 on macOS (M-series chip)

### Dependency Installation Journey

#### Attempt 1: Install fairseq2 0.2.1 (repo requirement)

```bash
pip install "fairseq2<0.3" opencv-python pillow hydra-core
```

‚úÖ SUCCESS - Installed fairseq2 0.2.1 + torch 2.2.2

#### Attempt 2: Missing package `timm`

```bash
pip install timm
```

‚úÖ SUCCESS - Installed timm 1.0.22

#### Attempt 3: Missing package `psutil`

```bash
pip install psutil
```

‚úÖ SUCCESS - Installed psutil 7.1.3

#### Attempt 4: Missing package `iopath`

```bash
pip install -r requirements.txt
```

‚úÖ PARTIAL SUCCESS - Installed many packages
‚ö†Ô∏è WARNING - numpy upgraded from 1.26.4 to 2.2.6 (fairseq2 requires ~1.23)

#### Attempt 5: Fix numpy version

```bash
pip install "numpy~=1.23"
```

‚úÖ SUCCESS - Downgraded to numpy 1.26.4
‚ö†Ô∏è WARNING - opencv-python-headless requires numpy >= 2.0

#### Attempt 6: Missing `sonar` module

```bash
pip install sonar-space
```

‚úÖ INSTALLED sonar-space 0.5.0
‚ùå **BREAKING CHANGES**:

- fairseq2 upgraded from 0.2.1 ‚Üí 0.7.0 (incompatible with SSVP-SLT repo)
- torch upgraded from 2.2.2 ‚Üí 2.9.0
- torchaudio upgraded from 2.2.2 ‚Üí 2.9.0
- torchvision 0.17.2 now incompatible with torch 2.9.0

#### Attempt 7: Run inference with mixed versions

```python
python run.py ...
```

‚ùå **RUNTIME ERROR**:

```
RuntimeError: operator torchvision::nms does not exist
```

- Caused by torch 2.9.0 / torchvision 0.17.2 mismatch
- torchvision 0.17.2 requires torch==2.2.2
- sonar-space requires torch (latest) which pulls 2.9.0

## Dependency Conflict Matrix

| Package     | SSVP-SLT Repo | sonar-space    | fairseq2 0.2.1 | fairseq2 0.7.0 | Status      |
| ----------- | ------------- | -------------- | -------------- | -------------- | ----------- |
| torch       | ~2.2          | latest (2.9.0) | 2.2.2          | 2.9.0          | ‚ùå CONFLICT |
| torchvision | 0.17.2        | -              | 0.17.2         | 0.19.0+        | ‚ùå MISMATCH |
| fairseq2    | < 0.3         | >= 0.5.2       | 0.2.1          | 0.7.0          | ‚ùå CONFLICT |
| numpy       | -             | >= 1.21        | ~1.23          | >= 1.21        | ‚ö†Ô∏è PARTIAL  |
| opencv      | headless      | -              | -              | -              | ‚ö†Ô∏è VERSION  |

## Root Cause Analysis

### Why This is Hard

1. **SSVP-SLT Repo Requirements**:

   - Written for fairseq2 < 0.3 (old API)
   - Expects torch 2.2.x ecosystem
   - Uses timm with torchvision 0.17.2

2. **sonar-space Package**:

   - Requires fairseq2 >= 0.5.2 (new API)
   - Pulls latest torch (2.9.0+)
   - Incompatible with older SSVP-SLT code

3. **Breaking Changes in fairseq2**:

   - API changed between 0.2.x and 0.7.x
   - `fairseq2.models.sequence` removed in 0.7.x
   - SSVP-SLT repo code would need significant updates

4. **Circular Dependency**:
   ```
   SSVP-SLT (run.py)
   ‚îî‚îÄ requires sign_hiera.py
      ‚îî‚îÄ requires timm
         ‚îî‚îÄ requires torchvision 0.17.2
            ‚îî‚îÄ requires torch==2.2.2
               BUT
   sonar-space
   ‚îî‚îÄ requires fairseq2 >= 0.5.2
      ‚îî‚îÄ requires torch 2.9.0+
         ‚îî‚îÄ breaks torchvision 0.17.2
   ```

## Attempted Solutions

### ‚ùå Solution 1: Mix old and new versions

- **Problem**: Runtime errors due to incompatible C++ operators
- **Verdict**: Not viable

### ‚ùå Solution 2: Use sonar-space 0.5.0 with torch 2.2.2

- **Problem**: sonar-space dependencies force torch upgrade
- **Verdict**: pip doesn't allow downgrade after install

### ‚ùå Solution 3: Modify SSVP-SLT repo to use fairseq2 0.7.0

- **Problem**: Requires understanding and rewriting large portions of code
- **Effort**: Multiple days of work
- **Risk**: High chance of introducing bugs
- **Verdict**: Too time-consuming for thesis timeline

### ‚ùå Solution 4: Fork sonar-space and pin torch 2.2.2

- **Problem**: Requires maintaining fork + potential breaking changes
- **Verdict**: Not sustainable

## Conclusions

### Technical Assessment

**SONAR Inference via SSVP-SLT Repository**:

- Status: **‚ùå BLOCKED** by dependency conflicts
- Estimated fix time: 3-5 days (code refactoring required)
- Risk level: **HIGH** (breaking changes in fairseq2 API)
- Maintenance burden: **HIGH** (fork or frequent updates needed)

### Alternative: Landmarks Approach

**Landmarks-Based Translation** (OpenPose ‚Üí Transformer ‚Üí Text):

- Status: ‚úÖ **READY TO GO**
- Data: ‚úÖ Prepared (train/val/test, ~2.1GB, 6229 samples)
- Model: ‚úÖ Created and tested (10M params, working)
- Dependencies: ‚úÖ No conflicts (main .venv works perfectly)
- Estimated time to results: **2-3 days**
- Risk level: **LOW** (proven architecture)
- Maintenance burden: **LOW** (stable dependencies)

## Recommendation

### üéØ Proceed with Landmarks Approach as Primary Method

**Rationale**:

1. **Time-to-Results**: Landmarks approach can produce results in 2-3 days vs 5-7 days for SONAR (with risk of failure)
2. **Thesis Contribution**: Custom landmarks-based model is a stronger contribution than using pre-trained SONAR
3. **Reproducibility**: Easier for others to reproduce (no dependency hell)
4. **Flexibility**: Full control over model architecture and training process
5. **Pragmatism**: Thesis deadline is approaching - choose the path with lowest risk

**For Thesis**:

- **Primary Approach**: Landmarks Transformer (train and evaluate)
- **Baseline Citation**: Reference SONAR paper's reported performance (15-20% BLEU-4 on How2Sign)
- **Comparison**: Compare your Landmarks results against cited SONAR baseline
- **Contribution**: Novel use of OpenPose landmarks for continuous SLT with Transformers

### If You Still Want to Try SONAR...

**Option A: Use Colab for Inference** (lower risk)

- Upload videos to Google Drive
- Run SONAR inference on Colab GPU with clean environment
- Download results
- Time cost: +1 day

**Option B: Refactor SSVP-SLT Code** (high risk)

- Update code to use fairseq2 0.7.0 API
- Replace deprecated `fairseq2.models.sequence` calls
- Test extensively
- Time cost: +3-5 days
- Risk: Medium-high

**Option C: Docker Container** (medium risk)

- Create Dockerfile with exact versions
- Run inference in isolated container
- Time cost: +1-2 days
- Risk: Low-medium

## Next Steps

### Recommended Path (LOW RISK):

1. ‚úÖ **Start Landmarks Training** (TODAY)

   - Use prepared data (train_landmarks.pkl, val_landmarks.pkl)
   - Train Landmarks Transformer model
   - Monitor loss and BLEU metrics
   - Expected: First results in 24-48 hours

2. **Evaluate on Test Set** (DAY 3)

   - Run inference on test_landmarks.pkl
   - Calculate BLEU-1/2/3/4, METEOR, ROUGE-L
   - Compare against SONAR paper baseline

3. **Write Thesis Chapter** (DAY 4-5)

   - Describe Landmarks approach
   - Present results
   - Compare with SONAR (cite paper)
   - Discuss trade-offs

4. **Optional: Try SONAR on Colab** (if time permits)
   - After Landmarks results are in
   - As additional comparison point
   - Low priority

### Alternative Path (HIGH RISK - NOT RECOMMENDED):

1. Spend 3-5 days debugging SONAR dependencies
2. Risk: Still might not work after extensive effort
3. Risk: Thesis timeline compromised
4. Potential: Same baseline performance as cited in paper

## Files and Resources

### Ready to Use:

- ‚úÖ `data/processed/landmarks_how2sign/train/train_landmarks.pkl` (781 MB)
- ‚úÖ `data/processed/landmarks_how2sign/val/val_landmarks.pkl` (576 MB)
- ‚úÖ `data/processed/landmarks_how2sign/test/test_landmarks.pkl` (751 MB)
- ‚úÖ `models/landmarks_transformer.py` (tested, working)

### Blocked:

- ‚ùå SONAR inference via `run.py` (dependency hell)
- ‚ùå SSVP-SLT repository examples (incompatible fairseq2 versions)

## Lessons Learned

1. **Research Code vs Production Code**: Research repositories often have fragile dependency requirements
2. **Version Pinning is Critical**: fairseq2's API breaking changes highlight importance of exact versions
3. **Alternative Approaches**: Always have a backup plan when working with external codebases
4. **Pragmatic Decision-Making**: Sometimes "good enough" (Landmarks) is better than "perfect" (SONAR)
5. **Time Management**: Thesis deadlines require smart risk assessment

## Final Verdict

**üö¶ RED LIGHT for SONAR Inference** (via repository)
**üö¶ GREEN LIGHT for Landmarks Approach**

The dependency conflicts are too severe and time-consuming to resolve given thesis constraints. The Landmarks approach offers:

- Immediate start
- Lower risk
- Stronger thesis contribution
- Full experimental control
- Publishable novelty

**Decision: Proceed with Landmarks Transformer training as primary approach.**

---

_Last Updated: January 2025_
_Status: SONAR Inference blocked - Switching to Landmarks Approach_
