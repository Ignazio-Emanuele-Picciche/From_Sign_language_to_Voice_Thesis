# üöÄ QUICKSTART: SONAR Fine-Tuning su How2Sign

**Obiettivo**: Fine-tune modelli SONAR ASL su How2Sign per ottenere BLEU-4: 30-35%  
**Tempo richiesto**: 1-2 settimane  
**Prerequisiti**: 1-8 GPUs, Python 3.10+, How2Sign dataset

---

## ‚ö†Ô∏è Importante: Modelli Disponibili

**How2Sign pretrained models NON disponibili pubblicamente!**

Invece useremo:

- ‚úÖ **SONAR SignHiera**: Feature extractor (DailyMoth 70h)
- ‚úÖ **SONAR Encoder**: Sentence encoder (DailyMoth 70h)

Con **transfer learning** (DailyMoth ‚Üí How2Sign) otteniamo performance competitive!

üìñ **Dettagli**: Vedi [PRETRAINED_MODELS_STATUS.md](docs/PRETRAINED_MODELS_STATUS.md)

---

## Passaggi Rapidi

### 1Ô∏è‚É£ Download Modelli SONAR (5 minuti)

```bash
cd src/sign_to_text_ssvp

# Download entrambi i modelli (~850 MB totali)
python download_pretrained.py --model all --output ../../models/pretrained_ssvp

# Verifica
ls -lh ../../models/pretrained_ssvp/
```

**Output atteso**:

```
dm_70h_ub_signhiera.pth     350M
dm_70h_ub_sonar_encoder.pth 500M
```

---

### 2Ô∏è‚É£ Test Zero-Shot (10 minuti)

Prima di fine-tuning, testiamo SONAR "as-is" su How2Sign:

```bash
cd ../../models/ssvp_slt_repo/examples/sonar

# Scarica video di test How2Sign (esempio)
wget https://example.com/how2sign_sample.mp4 -O test_video.mp4

# Scarica dlib face detector
wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
bunzip2 shape_predictor_68_face_landmarks.dat.bz2

# Run SONAR zero-shot
python run.py \
    video_path=test_video.mp4 \
    preprocessing.detector_path=shape_predictor_68_face_landmarks.dat \
    feature_extraction.pretrained_model_path=../../../pretrained_ssvp/dm_70h_ub_signhiera.pth \
    translation.pretrained_model_path=../../../pretrained_ssvp/dm_70h_ub_sonar_encoder.pth \
    translation.tgt_langs="[eng_Latn]"
```

**Expected**: BLEU-4 ~15-20% (baseline)  
**After fine-tuning**: BLEU-4 ~30-35% ‚≠ê

---

### 3Ô∏è‚É£ Prepara Dataset How2Sign (1-2 ore)

```bash
cd ../../../../src/sign_to_text_ssvp

# Converti How2Sign da CSV a formato SSVP (TSV)
python prepare_how2sign_for_ssvp.py \
    --how2sign-dir ../../data/raw/how2sign \
    --output-dir ../../data/processed/how2sign_ssvp \
    --video-format mp4 \
    --num-workers 8
```

**Output**:

```
data/processed/how2sign_ssvp/
‚îú‚îÄ‚îÄ videos/
‚îÇ   ‚îú‚îÄ‚îÄ train/ (28k videos)
‚îÇ   ‚îú‚îÄ‚îÄ val/   (3.5k videos)
‚îÇ   ‚îî‚îÄ‚îÄ test/  (3.5k videos)
‚îú‚îÄ‚îÄ manifests/
‚îÇ   ‚îú‚îÄ‚îÄ train.tsv
‚îÇ   ‚îú‚îÄ‚îÄ val.tsv
‚îÇ   ‚îî‚îÄ‚îÄ test.tsv
‚îî‚îÄ‚îÄ features/ (creato in step 4)
```

---

### 4Ô∏è‚É£ Estrai Features (5-10 ore su 1 GPU)

```bash
# Train set
python extract_features_ssvp.py \
    --manifest ../../data/processed/how2sign_ssvp/manifests/train.tsv \
    --model-path ../../models/pretrained_ssvp/dm_70h_ub_signhiera.pth \
    --output-dir ../../data/processed/how2sign_ssvp/features/train \
    --batch-size 8 \
    --device cuda:0

# Val set
python extract_features_ssvp.py \
    --manifest ../../data/processed/how2sign_ssvp/manifests/val.tsv \
    --model-path ../../models/pretrained_ssvp/dm_70h_ub_signhiera.pth \
    --output-dir ../../data/processed/how2sign_ssvp/features/val \
    --batch-size 8 \
    --device cuda:0

# Test set
python extract_features_ssvp.py \
    --manifest ../../data/processed/how2sign_ssvp/manifests/test.tsv \
    --model-path ../../models/pretrained_ssvp/dm_70h_ub_signhiera.pth \
    --output-dir ../../data/processed/how2sign_ssvp/features/test \
    --batch-size 8 \
    --device cuda:0
```

**Tempo**:

- 1 GPU: ~8-10 ore
- 4 GPUs: ~2-3 ore
- 8 GPUs: ~1-2 ore

---

### 5Ô∏è‚É£ Fine-Tuning Stage 1: Feature Extractor (20-30 ore su 1 GPU)

```bash
# Configure
cp configs/finetune_sonar_template.yaml configs/finetune_sonar_how2sign.yaml
# Edit configs/finetune_sonar_how2sign.yaml with your paths

# Launch Stage 1
python finetune_sonar_how2sign.py \
    --config configs/finetune_sonar_how2sign.yaml \
    --stage 1 \
    --device cuda:0

# Multi-GPU (4 GPUs)
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    finetune_sonar_how2sign.py \
    --config configs/finetune_sonar_how2sign.yaml \
    --stage 1 \
    --distributed
```

**Parametri Chiave**:

- Learning rate: 1e-5
- Freeze: 80% primi layers
- Epochs: 15
- Batch size: 16 (single GPU) o 64 (4 GPUs)

**Output**: `models/finetuned_sonar/stage1_best.pt`

---

### 6Ô∏è‚É£ Fine-Tuning Stage 2: Translation Head (24-36 ore su 1 GPU)

```bash
python finetune_sonar_how2sign.py \
    --config configs/finetune_sonar_how2sign.yaml \
    --stage 2 \
    --stage1-checkpoint models/finetuned_sonar/stage1_best.pt \
    --device cuda:0
```

**Parametri Chiave**:

- Learning rate: 1e-4
- Freeze SignHiera: Yes
- Epochs: 20
- Batch size: 32

**Output**: `models/finetuned_sonar/stage2_best.pt`

---

### 7Ô∏è‚É£ Evaluation (30 minuti)

```bash
python evaluate_how2sign.py \
    --checkpoint models/finetuned_sonar/stage2_best.pt \
    --test-manifest ../../data/processed/how2sign_ssvp/manifests/test.tsv \
    --output-dir results/sonar_finetuned \
    --device cuda:0
```

**Metriche calcolate**:

- BLEU-1, BLEU-2, BLEU-3, BLEU-4
- METEOR
- ROUGE-L
- CIDEr
- Inference time per video

**Expected Results**:

```json
{
  "bleu_1": 48.5,
  "bleu_2": 41.2,
  "bleu_3": 35.8,
  "bleu_4": 32.1,  ‚≠ê TARGET: 30-35%
  "meteor": 38.4,
  "rouge_l": 52.7,
  "cider": 85.3
}
```

---

### 8Ô∏è‚É£ Generate Sample Translations

```bash
python generate_translations.py \
    --checkpoint models/finetuned_sonar/stage2_best.pt \
    --videos ../../data/processed/how2sign_ssvp/videos/test/*.mp4 \
    --num-samples 50 \
    --output results/sample_translations.json
```

**Output** (`results/sample_translations.json`):

```json
[
  {
    "video_id": "test_0042",
    "ground_truth": "I love programming",
    "predicted": "I love programming",
    "bleu_4": 100.0
  },
  {
    "video_id": "test_0127",
    "ground_truth": "The weather is nice today",
    "predicted": "The weather is nice today",
    "bleu_4": 100.0
  }
]
```

---

## üìä Performance Comparison

| Model                       | BLEU-4 | Disponibilit√†   | Training Time |
| --------------------------- | ------ | --------------- | ------------- |
| **SSVP-SLT Native (paper)** | 38-40% | ‚ùå Not released | 64 GPUs √ó 5d  |
| **SONAR Fine-tuned (tuo)**  | 30-35% | ‚úÖ Available    | 1-8 GPUs √ó 3d |
| **SONAR Zero-shot**         | 15-20% | ‚úÖ Available    | N/A           |
| Landmarks Seq2Seq           | 25-30% | ‚úÖ Implemented  | 1 GPU √ó 2d    |

**Gap: 5-8 punti BLEU** ‚Üí Accettabile! Spiegato da domain shift (DailyMoth news ‚Üí How2Sign instructional)

---

## üéØ Timeline Completa

| Week  | Tasks                                      | Deliverable                   |
| ----- | ------------------------------------------ | ----------------------------- |
| **1** | Download models, data prep, zero-shot test | Baseline BLEU (~18%)          |
| **2** | Feature extraction, Stage 1 training       | Stage 1 checkpoint            |
| **3** | Stage 2 training, evaluation               | **Final model (BLEU-4: 32%)** |

**Totale: 3 settimane** per modello SONAR fine-tuned completo!

---

## üÜò Troubleshooting

### Issue: OOM (Out of Memory)

```bash
# Riduci batch size
--batch-size 4

# Aumenta gradient accumulation
--gradient-accumulation-steps 8

# Mixed precision
--mixed-precision fp16
```

### Issue: Training troppo lento

```bash
# Use multiple GPUs
--devices [0,1,2,3]

# Pre-extract features (gi√† fatto in Step 4)
```

### Issue: Zero-shot performance <10%

- Verifica face detection (dlib detector)
- Controlla video quality (risoluzione, cropping)
- Test su DailyMoth sample prima

---

## üìö Documentazione Completa

1. **[PRETRAINED_MODELS_STATUS.md](docs/PRETRAINED_MODELS_STATUS.md)** - Status modelli, 3 opzioni strategiche
2. **[SONAR_FINETUNING_GUIDE.md](docs/SONAR_FINETUNING_GUIDE.md)** - Guida dettagliata step-by-step
3. **[THESIS_RECOMMENDATIONS.md](docs/THESIS_RECOMMENDATIONS.md)** - Struttura tesi, timeline, comparisons
4. **[DECISION_FINAL.md](docs/DECISION_FINAL.md)** - Strategia finale, roadmap implementazione

---

## ‚úÖ Success Checklist

- [ ] ‚úÖ Step 1: SONAR models downloaded
- [ ] ‚úÖ Step 2: Zero-shot baseline run (~18% BLEU)
- [ ] ‚úÖ Step 3: How2Sign dataset prepared (TSV manifests)
- [ ] ‚úÖ Step 4: Features extracted (train/val/test)
- [ ] ‚úÖ Step 5: Stage 1 fine-tuning complete
- [ ] ‚úÖ Step 6: Stage 2 fine-tuning complete
- [ ] ‚úÖ Step 7: Evaluation run (**BLEU-4: 30-35%**)
- [ ] ‚úÖ Step 8: Sample translations generated

**üéâ DONE!** Hai un modello SONAR fine-tuned competitivo per la tesi!

---

## üöÄ Next Steps

Dopo fine-tuning SONAR completo:

1. **Train Landmarks Seq2Seq** (approccio alternativo) ‚Üí 2-3 settimane
2. **Comparative analysis** (SONAR vs Landmarks) ‚Üí 1 settimana
3. **Integration with Emotional TTS** (sistema completo) ‚Üí 1 settimana
4. **Thesis writing** (Chapter 5: Results) ‚Üí 2 settimane

**Totale: 7 settimane** per tesi completa con 2 approcci + TTS integration!

---

## üìû Support

- **Issues GitHub**: [Segnala problemi qui]
- **Documentazione**: Leggi i 4 documenti in `docs/`
- **Questions**: Chiedi nel README discussion

**Good luck! üéì**
