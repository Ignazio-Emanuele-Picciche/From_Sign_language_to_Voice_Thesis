============================================================
TRAINING GRID SEARCH + VALIDATION SET ESPLICITO
============================================================
--- Caricamento TRAIN SET ---
‚úÖ TRAIN SET caricato. Shape: (4065, 10)
--- Caricamento VAL SET ---
‚úÖ VAL SET caricato. Shape: (1739, 10)

Feature utilizzate (6): ['lstm_prob_negative', 'lstm_prob_neutral', 'lstm_prob_positive', 'roberta_prob_negative', 'roberta_prob_neutral', 'roberta_prob_positive']
Classi codificate: {'Negative': 0, 'Neutral': 1, 'Positive': 2}

üîç Tuning Decision Tree (5-Fold CV su Train)...
Fitting 5 folds for each of 32 candidates, totalling 160 fits
   ‚úÖ Migliori parametri: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 5}
   ‚úÖ Miglior Score CV (Train): 0.7728

üìä Analisi Pesi/Importanza per Decision Tree:
   roberta_prob_negative         : 0.6363
   roberta_prob_positive         : 0.2858
   roberta_prob_neutral          : 0.0653
   lstm_prob_negative            : 0.0054
   lstm_prob_neutral             : 0.0050
   lstm_prob_positive            : 0.0021

--- Valutazione Decision Tree su VALIDATION SET ---
  Accuracy:              0.7499
  Weighted F1-Score:     0.7496

üîç Tuning Logistic Regression (5-Fold CV su Train)...
Fitting 5 folds for each of 10 candidates, totalling 50 fits
   ‚úÖ Migliori parametri: {'C': 100, 'solver': 'liblinear'}
   ‚úÖ Miglior Score CV (Train): 0.7759

üìä Analisi Pesi/Importanza per Logistic Regression:
   (Media assoluta dei coefficienti su tutte le classi)
   roberta_prob_neutral          : 6.1737
   roberta_prob_positive         : 3.7342
   roberta_prob_negative         : 2.5678
   lstm_prob_neutral             : 1.3567
   lstm_prob_positive            : 0.9304
   lstm_prob_negative            : 0.8400

--- Valutazione Logistic Regression su VALIDATION SET ---
  Accuracy:              0.7539
  Weighted F1-Score:     0.7546

üîç Tuning Random Forest (5-Fold CV su Train)...
Fitting 5 folds for each of 120 candidates, totalling 600 fits
   ‚úÖ Migliori parametri: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'n_estimators': 100}
   ‚úÖ Miglior Score CV (Train): 0.7825

üìä Analisi Pesi/Importanza per Random Forest:
   roberta_prob_positive         : 0.3894
   roberta_prob_negative         : 0.3170
   roberta_prob_neutral          : 0.2193
   lstm_prob_negative            : 0.0274
   lstm_prob_positive            : 0.0238
   lstm_prob_neutral             : 0.0231

--- Valutazione Random Forest su VALIDATION SET ---
  Accuracy:              0.7533
  Weighted F1-Score:     0.7542

üîç Tuning SVM (5-Fold CV su Train)...
Fitting 5 folds for each of 32 candidates, totalling 160 fits
   ‚úÖ Migliori parametri: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}
   ‚úÖ Miglior Score CV (Train): 0.7591

üìä Analisi Pesi/Importanza per SVM:
   ‚ö†Ô∏è  Pesi diretti non disponibili (es. Kernel non lineare).

--- Valutazione SVM su VALIDATION SET ---
  Accuracy:              0.7343
  Weighted F1-Score:     0.7393

============================================================
CONFRONTO FINALE (Basato su Validation Set)
Decision Tree            : 0.7496
Logistic Regression      : 0.7546
Random Forest            : 0.7542
SVM                      : 0.7393
------------------------------------------------------------
üèÜ VINCITORE: Logistic Regression (F1 Val: 0.7546)
============================================================

‚úÖ Modello OTTIMIZZATO salvato in: src/models/three_classes/text_plus_video_metalearner_to_sentiment/models/metalearner/metalearner_logistic_regression_tuned.joblib
‚ö†Ô∏è  RICORDA: Aggiorna MODEL_PATH in 'test_metalearner_final.py' con questo nuovo file!
