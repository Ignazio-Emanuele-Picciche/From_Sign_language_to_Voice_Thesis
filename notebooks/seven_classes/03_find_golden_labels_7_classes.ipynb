{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44da3eb6",
   "metadata": {},
   "source": [
    "# Identificazione delle \"Golden Labels\" per il Test Set - 7 Classi\n",
    "\n",
    "**Obiettivo dello script:**\n",
    "Questo script adatta il processo di identificazione delle \"golden labels\" per il sistema a 7 classi di emozioni. Confronta il dataset ASLLRP classificato con 7 classi con il dataset EmoSign per creare un test set affidabile e un training/validation set separato.\n",
    "\n",
    "### Le 7 Classi di Emozioni:\n",
    "\n",
    "1. **Estremamente Negativo** (Strongly Negative / Extremely Negative)\n",
    "2. **Negativo** (Negative)\n",
    "3. **Un po' Negativo** (Somewhat Negative)\n",
    "4. **Neutro** (Neutral)\n",
    "5. **Un po' Positivo** (Somewhat Positive)\n",
    "6. **Positivo** (Positive)\n",
    "7. **Estremamente Positivo** (Strongly Positive / Extremely Positive)\n",
    "\n",
    "**Funzionamento dello script:**\n",
    "\n",
    "1.  **Caricamento dei Dataset:**\n",
    "\n",
    "    - **Dataset EmoSign (da Hugging Face):** Ground truth validato manualmente\n",
    "    - **Dataset Locale (7 classi):** File `asllrp_video_sentiment_data_7_classes.csv` generato nel notebook precedente\n",
    "\n",
    "2.  **Estrazione degli ID Comuni:**\n",
    "\n",
    "    - Estrae l'`utterance_id` univoco da entrambi i dataset\n",
    "    - Trova l'intersezione tra i due insiemi di ID\n",
    "\n",
    "3.  **Identificazione delle \"Golden Labels\":**\n",
    "\n",
    "    - Le corrispondenze trovate costituiscono le **\"golden labels\"**\n",
    "    - Queste sono etichette affidabili, validate da una fonte esterna\n",
    "\n",
    "4.  **Creazione e Salvataggio dei Dataset:**\n",
    "    - **Test Set (Golden Labels):** Utilizzato esclusivamente per valutazione finale\n",
    "    - **Training/Validation Set:** Tutti gli altri dati, per addestramento e validazione\n",
    "    - Garantisce separazione netta tra train e test set\n",
    "\n",
    "### Importanza delle Golden Labels:\n",
    "\n",
    "- **Affidabilit√†:** Confermate da studi precedenti (EmoSign)\n",
    "- **Comparabilit√†:** Permettono di confrontare risultati con altri studi\n",
    "- **Validazione robusta:** Test set di alta qualit√† per valutazione finale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84226c41",
   "metadata": {},
   "source": [
    "## Fase 1: Importazione delle Librerie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71f55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f62b6a",
   "metadata": {},
   "source": [
    "## Fase 2: Caricamento del Dataset EmoSign da Hugging Face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0149da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del dataset EmoSign da Hugging Face...\n",
      "Nota: Potrebbe essere necessario autenticarsi con 'huggingface-cli login'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ignazioemanuelepicciche/Documents/TESI Magistrale UCBM/Improved_EmoSign_Thesis/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset EmoSign caricato con successo.\n",
      "Trovati 200 ID unici nel dataset EmoSign.\n",
      "\n",
      "Colonne EmoSign: ['video_name', 'Sentiment', 'joy', 'excited', 'surprise_pos', 'surprise_neg', 'worry', 'sadness', 'fear', 'disgust', 'frustration', 'anger', 'Reasoning_1', 'Reasoning_2', 'Reasoning_3', 'utterance_id']\n",
      "Numero totale di righe: 200\n"
     ]
    }
   ],
   "source": [
    "# Caricamento del dataset EmoSign da Hugging Face\n",
    "print(\"Caricamento del dataset EmoSign da Hugging Face...\")\n",
    "print(\"Nota: Potrebbe essere necessario autenticarsi con 'huggingface-cli login'\\n\")\n",
    "\n",
    "try:\n",
    "    df_emosign = pd.read_csv(\"hf://datasets/catfang/emosign/emosign_dataset.csv\")\n",
    "    print(\"‚úÖ Dataset EmoSign caricato con successo.\")\n",
    "\n",
    "    # Estrai l'ID utterance dalla colonna 'video_name'\n",
    "    # L'ID √® la parte numerica dopo il trattino basso '_'\n",
    "    df_emosign[\"utterance_id\"] = (\n",
    "        df_emosign[\"video_name\"].str.split(\"_\").str[-1].astype(str)\n",
    "    )\n",
    "\n",
    "    emosign_ids = set(df_emosign[\"utterance_id\"])\n",
    "    print(f\"Trovati {len(emosign_ids)} ID unici nel dataset EmoSign.\")\n",
    "\n",
    "    # Mostra alcune informazioni sul dataset\n",
    "    print(f\"\\nColonne EmoSign: {list(df_emosign.columns)}\")\n",
    "    print(f\"Numero totale di righe: {len(df_emosign)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore durante il caricamento del dataset da Hugging Face: {e}\")\n",
    "    print(\"\\nüí° Suggerimenti:\")\n",
    "    print(\"1. Esegui 'huggingface-cli login' nel terminale\")\n",
    "    print(\"2. Verifica la connessione internet\")\n",
    "    print(\"3. Controlla che il dataset 'catfang/emosign' sia accessibile\")\n",
    "    emosign_ids = set()\n",
    "    df_emosign = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9caec",
   "metadata": {},
   "source": [
    "## Fase 3: Caricamento del Dataset Locale (7 Classi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be1c0f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caricamento del dataset locale con sentiment a 7 classi...\n",
      "‚úÖ Dataset locale caricato con successo.\n",
      "Trovati 2118 ID unici nel dataset locale.\n",
      "\n",
      "Colonne dataset locale: ['video_name', 'caption', 'compound_score', 'emotion', 'utterance_id']\n",
      "Numero totale di righe: 2118\n",
      "\n",
      "Distribuzione delle emozioni nel dataset locale:\n",
      "  Extremely Negative       :     9 ( 0.42%)\n",
      "  Extremely Positive       :    68 ( 3.21%)\n",
      "  Negative                 :   183 ( 8.64%)\n",
      "  Neutral                  :  1007 (47.54%)\n",
      "  Positive                 :   435 (20.54%)\n",
      "  Somewhat Negative        :   202 ( 9.54%)\n",
      "  Somewhat Positive        :   214 (10.10%)\n"
     ]
    }
   ],
   "source": [
    "# Caricamento del dataset locale con 7 classi\n",
    "if emosign_ids:\n",
    "    print(\"\\nCaricamento del dataset locale con sentiment a 7 classi...\")\n",
    "    local_csv_path = \"../../data/processed/asllrp_video_sentiment_data_7_classes.csv\"\n",
    "\n",
    "    try:\n",
    "        df_local = pd.read_csv(local_csv_path)\n",
    "        print(\"‚úÖ Dataset locale caricato con successo.\")\n",
    "\n",
    "        # Estrai l'ID utterance dalla colonna 'video_name'\n",
    "        # Rimuovi l'estensione '.mp4'\n",
    "        df_local[\"utterance_id\"] = (\n",
    "            df_local[\"video_name\"].str.replace(\".mp4\", \"\", regex=False).astype(str)\n",
    "        )\n",
    "\n",
    "        local_ids = set(df_local[\"utterance_id\"])\n",
    "        print(f\"Trovati {len(local_ids)} ID unici nel dataset locale.\")\n",
    "\n",
    "        # Mostra informazioni sul dataset\n",
    "        print(f\"\\nColonne dataset locale: {list(df_local.columns)}\")\n",
    "        print(f\"Numero totale di righe: {len(df_local)}\")\n",
    "\n",
    "        # Mostra la distribuzione delle classi\n",
    "        print(\"\\nDistribuzione delle emozioni nel dataset locale:\")\n",
    "        emotion_dist = df_local[\"emotion\"].value_counts().sort_index()\n",
    "        for emotion, count in emotion_dist.items():\n",
    "            percentage = (count / len(df_local)) * 100\n",
    "            print(f\"  {emotion:25s}: {count:5d} ({percentage:5.2f}%)\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Errore: File non trovato a '{local_csv_path}'\")\n",
    "        print(\n",
    "            \"\\nüí° Assicurati di aver eseguito il notebook '02_sentiment_analysis_ASLLRP_7_classes.ipynb' prima.\"\n",
    "        )\n",
    "        df_local = pd.DataFrame()\n",
    "        local_ids = set()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante il caricamento: {e}\")\n",
    "        df_local = pd.DataFrame()\n",
    "        local_ids = set()\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Salto il caricamento del dataset locale a causa di errori precedenti.\")\n",
    "    df_local = pd.DataFrame()\n",
    "    local_ids = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be81ec",
   "metadata": {},
   "source": [
    "## Fase 4: Identificazione delle Corrispondenze (\"Golden Labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618013fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "IDENTIFICAZIONE GOLDEN LABELS\n",
      "============================================================\n",
      "\n",
      "ID nel dataset EmoSign: 200\n",
      "ID nel dataset locale: 2118\n",
      "\n",
      "‚ú® GOLDEN LABELS TROVATE: 200\n",
      "============================================================\n",
      "\n",
      "Percentuale rispetto al dataset locale: 9.44%\n",
      "Percentuale rispetto al dataset EmoSign: 100.00%\n",
      "\n",
      "Distribuzione delle emozioni nelle Golden Labels:\n",
      "  Extremely Negative       :     5 ( 2.50%)\n",
      "  Extremely Positive       :    30 (15.00%)\n",
      "  Negative                 :    78 (39.00%)\n",
      "  Positive                 :    71 (35.50%)\n",
      "  Somewhat Negative        :    16 ( 8.00%)\n",
      "\n",
      "Prime 5 golden labels:\n",
      "      video_name                                            caption  \\\n",
      "26  83664512.mp4  I was like, ‚ÄúOh, wow, that`s fine.‚Äù He wanted ...   \n",
      "31     25328.mp4  There are so many things that are wrong with t...   \n",
      "38    253715.mp4  Then they would ask the HIT group about the ca...   \n",
      "39    255438.mp4  Or they will ask another group SMASHED about t...   \n",
      "40    253816.mp4  Or ask the COLLIDED group about the car and if...   \n",
      "\n",
      "    compound_score   emotion  \n",
      "26          0.7430  Positive  \n",
      "31         -0.4767  Negative  \n",
      "38         -0.4767  Negative  \n",
      "39         -0.4767  Negative  \n",
      "40         -0.4767  Negative  \n"
     ]
    }
   ],
   "source": [
    "# Trova le corrispondenze tra i due dataset\n",
    "if not df_local.empty and emosign_ids:\n",
    "    # Trova gli ID in comune\n",
    "    golden_ids = local_ids.intersection(emosign_ids)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"IDENTIFICAZIONE GOLDEN LABELS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nID nel dataset EmoSign: {len(emosign_ids)}\")\n",
    "    print(f\"ID nel dataset locale: {len(local_ids)}\")\n",
    "    print(f\"\\n‚ú® GOLDEN LABELS TROVATE: {len(golden_ids)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Calcola percentuali\n",
    "    percentage_of_local = (len(golden_ids) / len(local_ids)) * 100 if local_ids else 0\n",
    "    percentage_of_emosign = (\n",
    "        (len(golden_ids) / len(emosign_ids)) * 100 if emosign_ids else 0\n",
    "    )\n",
    "\n",
    "    print(f\"\\nPercentuale rispetto al dataset locale: {percentage_of_local:.2f}%\")\n",
    "    print(f\"Percentuale rispetto al dataset EmoSign: {percentage_of_emosign:.2f}%\")\n",
    "\n",
    "    # Filtra il DataFrame locale per mantenere solo le golden labels\n",
    "    golden_labels_df = df_local[df_local[\"utterance_id\"].isin(golden_ids)].copy()\n",
    "\n",
    "    # Mostra la distribuzione delle emozioni nelle golden labels\n",
    "    print(\"\\nDistribuzione delle emozioni nelle Golden Labels:\")\n",
    "    golden_emotion_dist = golden_labels_df[\"emotion\"].value_counts().sort_index()\n",
    "    for emotion, count in golden_emotion_dist.items():\n",
    "        percentage = (count / len(golden_labels_df)) * 100\n",
    "        print(f\"  {emotion:25s}: {count:5d} ({percentage:5.2f}%)\")\n",
    "\n",
    "    print(\"\\nPrime 5 golden labels:\")\n",
    "    print(\n",
    "        golden_labels_df[[\"video_name\", \"caption\", \"compound_score\", \"emotion\"]].head()\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"\\n‚ùå Impossibile trovare le corrispondenze a causa di errori nel caricamento dei dati.\"\n",
    "    )\n",
    "    golden_labels_df = pd.DataFrame()\n",
    "    golden_ids = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8629b522",
   "metadata": {},
   "source": [
    "## Fase 5: Creazione del Test Set (Golden Labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff89b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SET SALVATO\n",
      "============================================================\n",
      "\n",
      "‚úÖ File salvato: ../../data/processed/golden_label_sentiment_7_classes.csv\n",
      "Numero di righe: 200\n",
      "Colonne: ['video_name', 'caption', 'compound_score', 'emotion']\n",
      "\n",
      "üìä Statistiche salvate: ../../data/processed/golden_label_sentiment_7_classes_stats.txt\n"
     ]
    }
   ],
   "source": [
    "# Salva le golden labels come test set\n",
    "if not golden_labels_df.empty:\n",
    "    # Rimuovi la colonna 'utterance_id' di supporto\n",
    "    golden_labels_output = golden_labels_df.drop(columns=[\"utterance_id\"]).copy()\n",
    "\n",
    "    # Definisci il percorso di output\n",
    "    output_path = \"../../data/processed/golden_label_sentiment_7_classes.csv\"\n",
    "\n",
    "    # Crea la directory se non esiste\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Salva il file\n",
    "    golden_labels_output.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST SET SALVATO\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n‚úÖ File salvato: {output_path}\")\n",
    "    print(f\"Numero di righe: {len(golden_labels_output)}\")\n",
    "    print(f\"Colonne: {list(golden_labels_output.columns)}\")\n",
    "\n",
    "    # Salva anche statistiche dettagliate\n",
    "    stats_path = output_path.replace(\".csv\", \"_stats.txt\")\n",
    "    with open(stats_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"STATISTICHE GOLDEN LABELS (TEST SET) - 7 CLASSI\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Data generazione: {pd.Timestamp.now()}\\n\")\n",
    "        f.write(f\"Numero totale di golden labels: {len(golden_labels_output)}\\n\\n\")\n",
    "\n",
    "        f.write(\"Distribuzione delle emozioni:\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        for emotion, count in golden_emotion_dist.items():\n",
    "            percentage = (count / len(golden_labels_output)) * 100\n",
    "            f.write(f\"{emotion:25s}: {count:5d} ({percentage:5.2f}%)\\n\")\n",
    "\n",
    "        f.write(\"\\nStatistiche compound scores:\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        f.write(f\"Media: {golden_labels_output['compound_score'].mean():.4f}\\n\")\n",
    "        f.write(f\"Mediana: {golden_labels_output['compound_score'].median():.4f}\\n\")\n",
    "        f.write(f\"Dev. Standard: {golden_labels_output['compound_score'].std():.4f}\\n\")\n",
    "        f.write(f\"Min: {golden_labels_output['compound_score'].min():.4f}\\n\")\n",
    "        f.write(f\"Max: {golden_labels_output['compound_score'].max():.4f}\\n\")\n",
    "\n",
    "    print(f\"\\nüìä Statistiche salvate: {stats_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå Nessun dato da salvare per le golden labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722fbfd",
   "metadata": {},
   "source": [
    "## Fase 6: Creazione del Training/Validation Set (Senza Golden Labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3887638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING/VALIDATION SET SALVATO\n",
      "============================================================\n",
      "\n",
      "‚úÖ File salvato: ../../data/processed/asllrp_video_sentiment_data_7_classes_without_golden.csv\n",
      "Numero di righe: 1918\n",
      "\n",
      "Verifica numerica:\n",
      "  Righe originali: 2118\n",
      "  Golden Labels: 200\n",
      "  Righe rimanenti: 1918\n",
      "  Somma (golden + rimanenti): 2118\n",
      "  ‚úÖ Verifica superata: Nessuna riga persa!\n",
      "\n",
      "Distribuzione delle emozioni nel Training/Validation Set:\n",
      "  Extremely Negative       :     4 ( 0.21%)\n",
      "  Extremely Positive       :    38 ( 1.98%)\n",
      "  Negative                 :   105 ( 5.47%)\n",
      "  Neutral                  :  1007 (52.50%)\n",
      "  Positive                 :   364 (18.98%)\n",
      "  Somewhat Negative        :   186 ( 9.70%)\n",
      "  Somewhat Positive        :   214 (11.16%)\n",
      "\n",
      "üìä Statistiche salvate: ../../data/processed/asllrp_video_sentiment_data_7_classes_without_golden_stats.txt\n"
     ]
    }
   ],
   "source": [
    "# Salva il dataset escludendo le golden labels (per training/validation)\n",
    "if not df_local.empty and golden_ids:\n",
    "    # Filtra per escludere le golden labels\n",
    "    df_without_golden = df_local[~df_local[\"utterance_id\"].isin(golden_ids)].copy()\n",
    "\n",
    "    # Rimuovi la colonna 'utterance_id' di supporto\n",
    "    df_without_golden = df_without_golden.drop(columns=[\"utterance_id\"])\n",
    "\n",
    "    # Definisci il percorso di output\n",
    "    output_path_without_golden = (\n",
    "        \"../../data/processed/asllrp_video_sentiment_data_7_classes_without_golden.csv\"\n",
    "    )\n",
    "\n",
    "    # Salva il file\n",
    "    df_without_golden.to_csv(output_path_without_golden, index=False)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING/VALIDATION SET SALVATO\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n‚úÖ File salvato: {output_path_without_golden}\")\n",
    "    print(f\"Numero di righe: {len(df_without_golden)}\")\n",
    "\n",
    "    print(f\"\\nVerifica numerica:\")\n",
    "    print(f\"  Righe originali: {len(df_local)}\")\n",
    "    print(f\"  Golden Labels: {len(golden_ids)}\")\n",
    "    print(f\"  Righe rimanenti: {len(df_without_golden)}\")\n",
    "    print(f\"  Somma (golden + rimanenti): {len(golden_ids) + len(df_without_golden)}\")\n",
    "\n",
    "    if len(golden_ids) + len(df_without_golden) == len(df_local):\n",
    "        print(\"  ‚úÖ Verifica superata: Nessuna riga persa!\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  Attenzione: Discrepanza nel numero di righe!\")\n",
    "\n",
    "    # Mostra la distribuzione delle emozioni nel training set\n",
    "    print(\"\\nDistribuzione delle emozioni nel Training/Validation Set:\")\n",
    "    train_emotion_dist = df_without_golden[\"emotion\"].value_counts().sort_index()\n",
    "    for emotion, count in train_emotion_dist.items():\n",
    "        percentage = (count / len(df_without_golden)) * 100\n",
    "        print(f\"  {emotion:25s}: {count:5d} ({percentage:5.2f}%)\")\n",
    "\n",
    "    # Salva statistiche anche per il training set\n",
    "    stats_path = output_path_without_golden.replace(\".csv\", \"_stats.txt\")\n",
    "    with open(stats_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"STATISTICHE TRAINING/VALIDATION SET - 7 CLASSI\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(f\"Data generazione: {pd.Timestamp.now()}\\n\")\n",
    "        f.write(f\"Numero totale di righe: {len(df_without_golden)}\\n\\n\")\n",
    "\n",
    "        f.write(\"Distribuzione delle emozioni:\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        for emotion, count in train_emotion_dist.items():\n",
    "            percentage = (count / len(df_without_golden)) * 100\n",
    "            f.write(f\"{emotion:25s}: {count:5d} ({percentage:5.2f}%)\\n\")\n",
    "\n",
    "        f.write(\"\\nStatistiche compound scores:\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        f.write(f\"Media: {df_without_golden['compound_score'].mean():.4f}\\n\")\n",
    "        f.write(f\"Mediana: {df_without_golden['compound_score'].median():.4f}\\n\")\n",
    "        f.write(f\"Dev. Standard: {df_without_golden['compound_score'].std():.4f}\\n\")\n",
    "        f.write(f\"Min: {df_without_golden['compound_score'].min():.4f}\\n\")\n",
    "        f.write(f\"Max: {df_without_golden['compound_score'].max():.4f}\\n\")\n",
    "\n",
    "    print(f\"\\nüìä Statistiche salvate: {stats_path}\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"\\n‚ùå Impossibile creare il training/validation set a causa di errori precedenti.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a6310",
   "metadata": {},
   "source": [
    "## Fase 7: Confronto delle Distribuzioni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f7b013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Grafico di confronto salvato: ../../reports/figures/test_train_distribution_comparison_7_classes.png\n"
     ]
    }
   ],
   "source": [
    "# Confronta le distribuzioni tra test set e training set\n",
    "if not golden_labels_df.empty and not df_without_golden.empty:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "\n",
    "    matplotlib.use(\"Agg\")\n",
    "\n",
    "    emotions_order = [\n",
    "        \"Extremely Negative\",\n",
    "        \"Negative\",\n",
    "        \"Somewhat Negative\",\n",
    "        \"Neutral\",\n",
    "        \"Somewhat Positive\",\n",
    "        \"Positive\",\n",
    "        \"Extremely Positive\",\n",
    "    ]\n",
    "\n",
    "    # Prepara i dati per il grafico\n",
    "    test_counts = [golden_emotion_dist.get(emotion, 0) for emotion in emotions_order]\n",
    "    train_counts = [train_emotion_dist.get(emotion, 0) for emotion in emotions_order]\n",
    "\n",
    "    # Normalizza in percentuali\n",
    "    test_percentages = [(count / len(golden_labels_df)) * 100 for count in test_counts]\n",
    "    train_percentages = [\n",
    "        (count / len(df_without_golden)) * 100 for count in train_counts\n",
    "    ]\n",
    "\n",
    "    # Crea il grafico\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    colors = [\n",
    "        \"#8B0000\",\n",
    "        \"#DC143C\",\n",
    "        \"#FFA07A\",\n",
    "        \"#808080\",\n",
    "        \"#90EE90\",\n",
    "        \"#32CD32\",\n",
    "        \"#006400\",\n",
    "    ]\n",
    "\n",
    "    # Test Set\n",
    "    ax1 = axes[0]\n",
    "    bars1 = ax1.bar(range(len(emotions_order)), test_percentages, color=colors)\n",
    "    ax1.set_title(\"Test Set (Golden Labels)\", fontsize=13, fontweight=\"bold\")\n",
    "    ax1.set_xlabel(\"Emozione\", fontsize=11)\n",
    "    ax1.set_ylabel(\"Percentuale (%)\", fontsize=11)\n",
    "    ax1.set_xticks(range(len(emotions_order)))\n",
    "    ax1.set_xticklabels(\n",
    "        [\n",
    "            \"Estr.\\nNeg.\",\n",
    "            \"Neg.\",\n",
    "            \"Po'\\nNeg.\",\n",
    "            \"Neutro\",\n",
    "            \"Po'\\nPos.\",\n",
    "            \"Pos.\",\n",
    "            \"Estr.\\nPos.\",\n",
    "        ],\n",
    "        fontsize=9,\n",
    "    )\n",
    "    ax1.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    for bar, count in zip(bars1, test_counts):\n",
    "        height = bar.get_height()\n",
    "        if count > 0:\n",
    "            ax1.text(\n",
    "                bar.get_x() + bar.get_width() / 2.0,\n",
    "                height,\n",
    "                f\"{int(count)}\\n({height:.1f}%)\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "    # Training/Validation Set\n",
    "    ax2 = axes[1]\n",
    "    bars2 = ax2.bar(range(len(emotions_order)), train_percentages, color=colors)\n",
    "    ax2.set_title(\"Training/Validation Set\", fontsize=13, fontweight=\"bold\")\n",
    "    ax2.set_xlabel(\"Emozione\", fontsize=11)\n",
    "    ax2.set_ylabel(\"Percentuale (%)\", fontsize=11)\n",
    "    ax2.set_xticks(range(len(emotions_order)))\n",
    "    ax2.set_xticklabels(\n",
    "        [\n",
    "            \"Estr.\\nNeg.\",\n",
    "            \"Neg.\",\n",
    "            \"Po'\\nNeg.\",\n",
    "            \"Neutro\",\n",
    "            \"Po'\\nPos.\",\n",
    "            \"Pos.\",\n",
    "            \"Estr.\\nPos.\",\n",
    "        ],\n",
    "        fontsize=9,\n",
    "    )\n",
    "    ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    for bar, count in zip(bars2, train_counts):\n",
    "        height = bar.get_height()\n",
    "        if count > 0:\n",
    "            ax2.text(\n",
    "                bar.get_x() + bar.get_width() / 2.0,\n",
    "                height,\n",
    "                f\"{int(count)}\\n({height:.1f}%)\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Salva il grafico\n",
    "    output_folder = \"../../reports/figures\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    comparison_path = os.path.join(\n",
    "        output_folder, \"test_train_distribution_comparison_7_classes.png\"\n",
    "    )\n",
    "    plt.savefig(comparison_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\nüìä Grafico di confronto salvato: {comparison_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c7d87",
   "metadata": {},
   "source": [
    "## Riepilogo Finale\n",
    "\n",
    "‚úÖ **Processo completato con successo!**\n",
    "\n",
    "### File generati:\n",
    "\n",
    "1. **Test Set (Golden Labels)**:\n",
    "\n",
    "   - `golden_label_sentiment_7_classes.csv` - Dati per la valutazione finale\n",
    "   - `golden_label_sentiment_7_classes_stats.txt` - Statistiche del test set\n",
    "\n",
    "2. **Training/Validation Set**:\n",
    "\n",
    "   - `asllrp_video_sentiment_data_7_classes_without_golden.csv` - Dati per addestramento\n",
    "   - `asllrp_video_sentiment_data_7_classes_without_golden_stats.txt` - Statistiche del training set\n",
    "\n",
    "3. **Visualizzazioni**:\n",
    "   - `test_train_distribution_comparison_7_classes.png` - Confronto distribuzioni\n",
    "\n",
    "### Separazione dei dati:\n",
    "\n",
    "- ‚úÖ **Test Set**: Contiene solo le golden labels validate da EmoSign\n",
    "- ‚úÖ **Training Set**: Contiene tutti gli altri dati, senza overlap con il test set\n",
    "- ‚úÖ **Nessuna contaminazione**: Separazione netta garantita\n",
    "\n",
    "### Prossimi passi:\n",
    "\n",
    "1. Utilizzare il Training/Validation Set per:\n",
    "\n",
    "   - Addestramento dei modelli\n",
    "   - Cross-validation\n",
    "   - Tuning degli iperparametri\n",
    "\n",
    "2. Utilizzare il Test Set (Golden Labels) per:\n",
    "\n",
    "   - Valutazione finale delle performance\n",
    "   - Confronto con altri studi\n",
    "   - Validazione robusta dei risultati\n",
    "\n",
    "3. Considerare tecniche di data augmentation per le classi meno rappresentate\n",
    "\n",
    "4. Applicare class weights durante il training per gestire lo sbilanciamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc139f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca2c1c62",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è IMPORTANTE: Perch√© Solo 5 Classi su 7 nelle Golden Labels?\n",
    "\n",
    "### üìä Situazione Attuale:\n",
    "\n",
    "Le golden labels contengono solo **5 delle 7 classi emotive**:\n",
    "\n",
    "‚úÖ **Classi Presenti:**\n",
    "\n",
    "- Extremely Negative: 5 esempi (2.50%)\n",
    "- Negative: 78 esempi (39.00%)\n",
    "- Somewhat Negative: 16 esempi (8.00%)\n",
    "- Positive: 71 esempi (35.50%)\n",
    "- Extremely Positive: 30 esempi (15.00%)\n",
    "\n",
    "‚ùå **Classi Mancanti:**\n",
    "\n",
    "- **Neutral**: 0 esempi (0%)\n",
    "- **Somewhat Positive**: 0 esempi (0%)\n",
    "\n",
    "---\n",
    "\n",
    "### ü§î Spiegazione:\n",
    "\n",
    "#### 1. **Dataset EmoSign Originale (3 Classi)**\n",
    "\n",
    "Il dataset EmoSign da cui provengono le golden labels originariamente ha solo **3 classi** (Positive, Negative, Neutral), etichettate manualmente. Quando abbiamo applicato il nostro sistema a 7 classi basato su VADER:\n",
    "\n",
    "- I video etichettati come \"Positive\" ‚Üí hanno generato compound scores che li hanno classificati come **Positive** o **Extremely Positive**\n",
    "- I video etichettati come \"Negative\" ‚Üí hanno generato compound scores che li hanno classificati in varie categorie negative\n",
    "- I video etichettati come \"Neutral\" ‚Üí potrebbero non essere presenti nelle 200 corrispondenze trovate, o hanno compound scores che li hanno classificati diversamente\n",
    "\n",
    "#### 2. **Distribuzione dei Compound Scores**\n",
    "\n",
    "Dalle statistiche:\n",
    "\n",
    "- **Media**: 0.1057 (appena sopra la soglia Neutral)\n",
    "- **Mediana**: 0.5994 (nell'intervallo Positive)\n",
    "- **Range**: da -0.9440 a 0.8910\n",
    "\n",
    "Questo indica che:\n",
    "\n",
    "- Il dataset √® leggermente **sbilanciato verso il positivo**\n",
    "- L'area \"Somewhat Positive\" (0.10 to 0.40) √® una **zona di transizione** poco rappresentata\n",
    "- L'area \"Neutral\" (-0.10 to 0.10) √® molto **stretta** e potrebbe contenere pochi video\n",
    "\n",
    "#### 3. **Soglie Config 2 (Concentrata)**\n",
    "\n",
    "La configurazione scelta ha un'area Neutral pi√π ampia (0.20) ma comunque selettiva:\n",
    "\n",
    "```\n",
    "Neutral:          -0.10 to  0.10  (area 0.20)\n",
    "Somewhat Positive: 0.10 to  0.40  (area 0.30)\n",
    "```\n",
    "\n",
    "Con una media di 0.1057, molti video sono **appena sopra** la soglia Neutral, ma non tutti finiscono in \"Somewhat Positive\" perch√© molti hanno compound scores pi√π alti.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Questo √® Normale?\n",
    "\n",
    "**S√¨, √® completamente normale e previsto!** Ecco perch√©:\n",
    "\n",
    "1. **Le golden labels derivano da un dataset con 3 classi**, non 7\n",
    "2. **La classificazione a 7 classi √® il nostro raffinamento**, non la ground truth originale\n",
    "3. **I video validati manualmente** probabilmente avevano emozioni chiaramente positive o negative, non intermedie\n",
    "4. **Le aree intermedie** (Somewhat Positive, Neutral) sono pi√π difficili da validare manualmente\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Implicazioni Pratiche:\n",
    "\n",
    "#### ‚úÖ **Vantaggi:**\n",
    "\n",
    "- Le golden labels sono **affidabili** per le 5 classi presenti\n",
    "- Hai una **buona copertura** delle emozioni negative e positive\n",
    "- Le classi estreme (Extremely Negative/Positive) sono rappresentate\n",
    "\n",
    "#### ‚ö†Ô∏è **Limitazioni:**\n",
    "\n",
    "- **Non puoi validare** le classi \"Neutral\" e \"Somewhat Positive\" con le golden labels\n",
    "- **Test set parziale**: Valuta solo 5 classi su 7\n",
    "- **Sbilanciamento**: Negative (78) e Positive (71) dominano\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Soluzioni Possibili:\n",
    "\n",
    "#### Opzione 1: **Accettare la Situazione** (CONSIGLIATO)\n",
    "\n",
    "- Usare le golden labels per validare le 5 classi presenti\n",
    "- Usare **validazione incrociata** sul training set per le altre 2 classi\n",
    "- Riportare nei risultati che le golden labels coprono solo 5/7 classi\n",
    "\n",
    "#### Opzione 2: **Creare Golden Labels Sintetiche**\n",
    "\n",
    "- Validare **manualmente** alcuni video del training set nelle classi mancanti\n",
    "- Aggiungere queste nuove golden labels al test set\n",
    "- ‚ö†Ô∏è Richiede lavoro manuale significativo\n",
    "\n",
    "#### Opzione 3: **Modificare le Soglie**\n",
    "\n",
    "- Usare una configurazione diversa (es. Config 1 Uniforme) che potrebbe generare pi√π classi\n",
    "- ‚ö†Ô∏è Potrebbe ridurre la precisione semantica delle classificazioni\n",
    "\n",
    "#### Opzione 4: **Aggregare le Classi per il Test**\n",
    "\n",
    "- Nel test finale, aggregare:\n",
    "  - Neutral + Somewhat Positive + Somewhat Negative ‚Üí **\"Neutral-ish\"**\n",
    "  - Positive + Extremely Positive ‚Üí **\"Positive\"**\n",
    "  - Negative + Extremely Negative ‚Üí **\"Negative\"**\n",
    "- Tornare a un sistema a **3 classi** per il test con golden labels\n",
    "- Mantenere 7 classi per l'analisi sul training set\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Raccomandazione Finale:\n",
    "\n",
    "**Accettare la situazione (Opzione 1)** √® la scelta migliore perch√©:\n",
    "\n",
    "1. Le golden labels rimangono affidabili e validate\n",
    "2. Non introduci bias con etichette sintetiche\n",
    "3. √à una limitazione **comune** nei dataset di sentiment analysis\n",
    "4. Puoi comunque valutare il modello su 5 classi significative\n",
    "5. Usi cross-validation per le classi non coperte\n",
    "\n",
    "Nei risultati della tesi, basta **documentare chiaramente** che:\n",
    "\n",
    "- Le golden labels coprono 5/7 classi (200 esempi)\n",
    "- Le classi Neutral e Somewhat Positive sono valutate solo sul training set\n",
    "- Questo √® dovuto alla natura del dataset EmoSign originale (3 classi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
