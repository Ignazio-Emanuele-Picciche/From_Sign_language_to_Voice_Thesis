{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc314f7a",
   "metadata": {},
   "source": [
    "# Trovare le \"Golden Labels\"\n",
    "\n",
    "Questo notebook confronta due dataset per identificare le \"golden labels\".\n",
    "\n",
    "1.  **Dataset EmoSign (Hugging Face)**: Contiene i nomi dei video con un ID utterance.\n",
    "2.  **Dataset ASLLRP Sentiment**: Il nostro dataset locale con analisi del sentiment, generato in precedenza.\n",
    "\n",
    "L'obiettivo è trovare le righe nel nostro dataset locale che hanno un ID utterance corrispondente nel dataset EmoSign. Queste righe verranno considerate \"golden labels\" e salvate in un nuovo file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e4f9155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del dataset EmoSign da Hugging Face...\n",
      "Dataset EmoSign caricato con successo.\n",
      "Trovati 200 ID unici nel dataset EmoSign.\n",
      "\n",
      "Caricamento del dataset locale con sentiment...\n",
      "Dataset locale caricato con successo.\n",
      "Trovati 830 ID unici nel dataset locale.\n",
      "Dataset EmoSign caricato con successo.\n",
      "Trovati 200 ID unici nel dataset EmoSign.\n",
      "\n",
      "Caricamento del dataset locale con sentiment...\n",
      "Dataset locale caricato con successo.\n",
      "Trovati 830 ID unici nel dataset locale.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Caricare i dataset e preparare gli ID\n",
    "import pandas as pd\n",
    "\n",
    "# --- Caricamento e preparazione del dataset EmoSign da Hugging Face ---\n",
    "print(\"Caricamento del dataset EmoSign da Hugging Face...\")\n",
    "try:\n",
    "    # Per accedere a questo dataset, potrebbe essere necessario un login tramite `huggingface-cli login`\n",
    "    df_emosign = pd.read_csv(\"hf://datasets/catfang/emosign/emosign_dataset.csv\")\n",
    "    print(\"Dataset EmoSign caricato con successo.\")\n",
    "\n",
    "    # Estrai l'ID utterance dalla colonna 'video_name'\n",
    "    # L'ID è la parte numerica dopo il trattino basso '_'\n",
    "    df_emosign[\"utterance_id\"] = (\n",
    "        df_emosign[\"video_name\"].str.split(\"_\").str[-1].astype(str)\n",
    "    )\n",
    "    emosign_ids = set(df_emosign[\"utterance_id\"])\n",
    "    print(f\"Trovati {len(emosign_ids)} ID unici nel dataset EmoSign.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Errore durante il caricamento del dataset da Hugging Face: {e}\")\n",
    "    print(\n",
    "        \"Assicurati di aver effettuato l'accesso con 'huggingface-cli login' nel tuo terminale.\"\n",
    "    )\n",
    "    emosign_ids = set()\n",
    "\n",
    "# --- Caricamento e preparazione del dataset locale ---\n",
    "if emosign_ids:\n",
    "    print(\"\\nCaricamento del dataset locale con sentiment...\")\n",
    "    local_csv_path = \"../data/processed/asllrp_video_sentiment_data_0.34.csv\"\n",
    "    try:\n",
    "        df_local = pd.read_csv(local_csv_path)\n",
    "        print(\"Dataset locale caricato con successo.\")\n",
    "\n",
    "        # Estrai l'ID utterance dalla colonna 'Utterance video filename'\n",
    "        # Rimuovi l'estensione '.mp4'\n",
    "        df_local[\"utterance_id\"] = (\n",
    "            df_local[\"Utterance video filename\"]\n",
    "            .str.replace(\".mp4\", \"\", regex=False)\n",
    "            .astype(str)\n",
    "        )\n",
    "        local_ids = set(df_local[\"utterance_id\"])\n",
    "        print(f\"Trovati {len(local_ids)} ID unici nel dataset locale.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Errore: File non trovato a '{local_csv_path}'\")\n",
    "        df_local = pd.DataFrame()\n",
    "else:\n",
    "    print(\"\\nSalto il caricamento del dataset locale a causa di errori precedenti.\")\n",
    "    df_local = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b17bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trovate 200 corrispondenze ('golden labels').\n",
      "\n",
      "Prime 5 righe delle 'golden labels':\n",
      "  Utterance video filename                                        translation  \\\n",
      "4             83664512.mp4  I was like, “Oh, wow, that`s fine.” He wanted ...   \n",
      "6                25328.mp4  There are so many things that are wrong with t...   \n",
      "7               253715.mp4  Then they would ask the HIT group about the ca...   \n",
      "8               255438.mp4  Or they will ask another group SMASHED about t...   \n",
      "9               253816.mp4  Or ask the COLLIDED group about the car and if...   \n",
      "\n",
      "    emotion  \n",
      "4  Positive  \n",
      "6  Negative  \n",
      "7  Negative  \n",
      "8  Negative  \n",
      "9  Negative  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Trovare le corrispondenze (\"Golden Labels\")\n",
    "if \"df_local\" in locals() and not df_local.empty and emosign_ids:\n",
    "    # Trova gli ID in comune tra i due dataset\n",
    "    golden_ids = local_ids.intersection(emosign_ids)\n",
    "    print(f\"\\nTrovate {len(golden_ids)} corrispondenze ('golden labels').\")\n",
    "\n",
    "    # Filtra il DataFrame locale per mantenere solo le righe con gli ID corrispondenti\n",
    "    golden_labels_df = df_local[df_local[\"utterance_id\"].isin(golden_ids)].copy()\n",
    "\n",
    "    # Rimuovi la colonna 'utterance_id' di supporto se non più necessaria\n",
    "    golden_labels_df.drop(columns=[\"utterance_id\"], inplace=True)\n",
    "\n",
    "    print(\"\\nPrime 5 righe delle 'golden labels':\")\n",
    "    print(golden_labels_df.head())\n",
    "else:\n",
    "    print(\n",
    "        \"\\nImpossibile trovare le corrispondenze a causa di errori nel caricamento dei dati.\"\n",
    "    )\n",
    "    golden_labels_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96906acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File 'golden_label_sentiment.csv' salvato con successo in '../data/processed/golden_label_sentiment.csv'.\n",
      "Il file contiene 200 righe.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Salvare il nuovo DataFrame\n",
    "if not golden_labels_df.empty:\n",
    "    output_path = \"../data/processed/golden_label_sentiment.csv\"\n",
    "    golden_labels_df.to_csv(output_path, index=False)\n",
    "    print(\n",
    "        f\"\\nFile 'golden_label_sentiment.csv' salvato con successo in '{output_path}'.\"\n",
    "    )\n",
    "    print(f\"Il file contiene {len(golden_labels_df)} righe.\")\n",
    "else:\n",
    "    print(\"\\nNessun dato da salvare.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d463ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File 'asllrp_video_sentiment_data_0.34_without_golden.csv' salvato con successo.\n",
      "Contiene 630 righe (righe originali - golden labels).\n",
      "Righe originali: 830, Golden Labels: 200, Righe rimanenti: 630\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Salvare il dataset locale escludendo le \"Golden Labels\"\n",
    "if \"df_local\" in locals() and not df_local.empty and \"golden_ids\" in locals():\n",
    "    # Filtra il DataFrame locale per escludere le righe con gli ID \"golden\"\n",
    "    df_without_golden = df_local[~df_local[\"utterance_id\"].isin(golden_ids)].copy()\n",
    "\n",
    "    # Rimuovi la colonna 'utterance_id' di supporto\n",
    "    df_without_golden.drop(columns=[\"utterance_id\"], inplace=True)\n",
    "\n",
    "    # Definisci il percorso del nuovo file CSV\n",
    "    # Prende il nome del file originale e aggiunge \"_without_golden\"\n",
    "    original_path = \"../data/processed/asllrp_video_sentiment_data_0.34.csv\"\n",
    "    base, ext = os.path.splitext(original_path)\n",
    "    output_path_without_golden = f\"{base}_without_golden{ext}\"\n",
    "\n",
    "    # Salva il nuovo DataFrame\n",
    "    df_without_golden.to_csv(output_path_without_golden, index=False)\n",
    "\n",
    "    print(\n",
    "        f\"\\nFile '{os.path.basename(output_path_without_golden)}' salvato con successo.\"\n",
    "    )\n",
    "    print(f\"Contiene {len(df_without_golden)} righe (righe originali - golden labels).\")\n",
    "    print(\n",
    "        f\"Righe originali: {len(df_local)}, Golden Labels: {len(golden_ids)}, Righe rimanenti: {len(df_without_golden)}\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"\\nImpossibile creare il file senza golden labels a causa di errori precedenti o dati mancanti.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab060c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
