{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc314f7a",
   "metadata": {},
   "source": [
    "# Identificazione delle \"Golden Labels\" per la Creazione del Test Set\n",
    "\n",
    "**Obiettivo dello script:**\n",
    "Questo script è fondamentale per suddividere il nostro dataset in un set di addestramento/validazione e un set di test affidabile. L'idea è quella di creare un **test set \"golden\"**, ovvero un insieme di dati la cui validità è corroborata da una fonte esterna. Per fare ciò, confrontiamo il nostro dataset (con sentiment generato tramite VADER) con il dataset **EmoSign**, che è stato validato manualmente. Le corrispondenze trovate tra i due dataset costituiranno le nostre \"golden labels\" e verranno usate esclusivamente per il testing.\n",
    "\n",
    "**Funzionamento dello script:**\n",
    "\n",
    "1.  **Caricamento dei Dataset:**\n",
    "\n",
    "    - **Dataset EmoSign (da Hugging Face):** Viene caricato il dataset `catfang/emosign`. Questo è considerato la nostra \"ground truth\" o fonte di validazione, poiché contiene video di utterance già selezionati e usati in studi precedenti.\n",
    "    - **Dataset Locale (con Sentiment):** Viene caricato il nostro file CSV locale (`asllrp_video_sentiment_data_with_neutral_0.34.csv`), che contiene le etichette di sentiment (Positivo, Negativo, Neutro) che abbiamo generato nello script precedente.\n",
    "\n",
    "2.  **Estrazione degli ID Comuni:**\n",
    "\n",
    "    - Da entrambi i dataset, viene estratto un identificatore univoco per ogni video, l'`utterance_id`. Questo ID permette di collegare in modo univoco i video tra i due dataset.\n",
    "    - Per il dataset EmoSign, l'ID viene estratto dal nome del file.\n",
    "    - Per il nostro dataset locale, l'ID corrisponde al nome del file senza l'estensione `.mp4`.\n",
    "\n",
    "3.  **Identificazione delle \"Golden Labels\":**\n",
    "\n",
    "    - Lo script confronta gli insiemi di `utterance_id` dei due dataset e trova l'intersezione. Le righe nel nostro dataset locale i cui `utterance_id` sono presenti anche nel dataset EmoSign vengono identificate come **\"golden labels\"**.\n",
    "    - Queste sono le etichette di cui ci fidiamo di più, poiché confermate da una fonte esterna.\n",
    "\n",
    "4.  **Creazione e Salvataggio dei Nuovi Dataset:**\n",
    "    - **Test Set (Golden Labels):** Le \"golden labels\" vengono salvate in un nuovo file CSV (`golden_label_sentiment_with_neutral.csv`). Questo file sarà utilizzato **esclusivamente come test set** per valutare le performance finali dei modelli.\n",
    "    - **Training/Validation Set:** Tutte le altre righe del nostro dataset locale (quelle che _non_ sono golden labels) vengono salvate in un altro file CSV (`..._without_golden.csv`). Questo file verrà utilizzato per l'**addestramento e la validazione** dei modelli, garantendo una separazione netta tra i dati di training e quelli di test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e4f9155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del dataset EmoSign da Hugging Face...\n",
      "Dataset EmoSign caricato con successo.\n",
      "Trovati 200 ID unici nel dataset EmoSign.\n",
      "\n",
      "Caricamento del dataset locale con sentiment...\n",
      "Dataset locale caricato con successo.\n",
      "Trovati 2118 ID unici nel dataset locale.\n",
      "Dataset EmoSign caricato con successo.\n",
      "Trovati 200 ID unici nel dataset EmoSign.\n",
      "\n",
      "Caricamento del dataset locale con sentiment...\n",
      "Dataset locale caricato con successo.\n",
      "Trovati 2118 ID unici nel dataset locale.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Caricare i dataset e preparare gli ID\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Caricamento e preparazione del dataset EmoSign da Hugging Face ---\n",
    "print(\"Caricamento del dataset EmoSign da Hugging Face...\")\n",
    "try:\n",
    "    # Per accedere a questo dataset, potrebbe essere necessario un login tramite `huggingface-cli login`\n",
    "    df_emosign = pd.read_csv(\"hf://datasets/catfang/emosign/emosign_dataset.csv\")\n",
    "    print(\"Dataset EmoSign caricato con successo.\")\n",
    "\n",
    "    # Estrai l'ID utterance dalla colonna 'video_name'\n",
    "    # L'ID è la parte numerica dopo il trattino basso '_'\n",
    "    df_emosign[\"utterance_id\"] = (\n",
    "        df_emosign[\"video_name\"].str.split(\"_\").str[-1].astype(str)\n",
    "    )\n",
    "    emosign_ids = set(df_emosign[\"utterance_id\"])\n",
    "    print(f\"Trovati {len(emosign_ids)} ID unici nel dataset EmoSign.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Errore durante il caricamento del dataset da Hugging Face: {e}\")\n",
    "    print(\n",
    "        \"Assicurati di aver effettuato l'accesso con 'huggingface-cli login' nel tuo terminale.\"\n",
    "    )\n",
    "    emosign_ids = set()\n",
    "\n",
    "# --- Caricamento e preparazione del dataset locale ---\n",
    "if emosign_ids:\n",
    "    print(\"\\nCaricamento del dataset locale con sentiment...\")\n",
    "    # local_csv_path = \"../data/processed/asllrp_video_sentiment_data_0.34.csv\" # Vecchio path\n",
    "    local_csv_path = \"../data/processed/asllrp_video_sentiment_data_with_neutral_0.4.csv\"  # Nuovo path con neutrali\n",
    "    try:\n",
    "        df_local = pd.read_csv(local_csv_path)\n",
    "        print(\"Dataset locale caricato con successo.\")\n",
    "\n",
    "        # Estrai l'ID utterance dalla colonna 'video_name'\n",
    "        # Rimuovi l'estensione '.mp4'\n",
    "        df_local[\"utterance_id\"] = (\n",
    "            df_local[\"video_name\"].str.replace(\".mp4\", \"\", regex=False).astype(str)\n",
    "        )\n",
    "        local_ids = set(df_local[\"utterance_id\"])\n",
    "        print(f\"Trovati {len(local_ids)} ID unici nel dataset locale.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Errore: File non trovato a '{local_csv_path}'\")\n",
    "        df_local = pd.DataFrame()\n",
    "else:\n",
    "    print(\"\\nSalto il caricamento del dataset locale a causa di errori precedenti.\")\n",
    "    df_local = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9b17bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trovate 200 corrispondenze ('golden labels').\n",
      "\n",
      "Prime 5 righe delle 'golden labels':\n",
      "      video_name                                            caption   emotion\n",
      "26  83664512.mp4  I was like, “Oh, wow, that`s fine.” He wanted ...  Positive\n",
      "31     25328.mp4  There are so many things that are wrong with t...  Negative\n",
      "38    253715.mp4  Then they would ask the HIT group about the ca...  Negative\n",
      "39    255438.mp4  Or they will ask another group SMASHED about t...  Negative\n",
      "40    253816.mp4  Or ask the COLLIDED group about the car and if...  Negative\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Trovare le corrispondenze (\"Golden Labels\")\n",
    "if \"df_local\" in locals() and not df_local.empty and emosign_ids:\n",
    "    # Trova gli ID in comune tra i due dataset\n",
    "    golden_ids = local_ids.intersection(emosign_ids)\n",
    "    print(f\"\\nTrovate {len(golden_ids)} corrispondenze ('golden labels').\")\n",
    "\n",
    "    # Filtra il DataFrame locale per mantenere solo le righe con gli ID corrispondenti\n",
    "    golden_labels_df = df_local[df_local[\"utterance_id\"].isin(golden_ids)].copy()\n",
    "\n",
    "    # Rimuovi la colonna 'utterance_id' di supporto se non più necessaria\n",
    "    golden_labels_df.drop(columns=[\"utterance_id\"], inplace=True)\n",
    "\n",
    "    print(\"\\nPrime 5 righe delle 'golden labels':\")\n",
    "    print(golden_labels_df.head())\n",
    "else:\n",
    "    print(\n",
    "        \"\\nImpossibile trovare le corrispondenze a causa di errori nel caricamento dei dati.\"\n",
    "    )\n",
    "    golden_labels_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96906acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File 'golden_label_sentiment_with_neutral.csv' salvato con successo in '../data/processed'.\n",
      "Il file contiene 200 righe.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Salvare il nuovo DataFrame\n",
    "if not golden_labels_df.empty:\n",
    "    # output_path = \"../data/processed/golden_label_sentiment.csv\" # Vecchio path\n",
    "    output_path = \"../data/processed/golden_label_sentiment_with_neutral.csv\"  # Nuovo path con neutrali\n",
    "    golden_labels_df.to_csv(output_path, index=False)\n",
    "    print(\n",
    "        f\"\\nFile '{os.path.basename(output_path)}' salvato con successo in '{os.path.dirname(output_path)}'.\"\n",
    "    )\n",
    "    print(f\"Il file contiene {len(golden_labels_df)} righe.\")\n",
    "else:\n",
    "    print(\"\\nNessun dato da salvare.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d463ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File 'asllrp_video_sentiment_data_with_neutral_0.5_without_golden.csv' salvato con successo.\n",
      "Contiene 1918 righe (righe originali - golden labels).\n",
      "Righe originali: 2118, Golden Labels: 200, Righe rimanenti: 1918\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Salvare il dataset locale escludendo le \"Golden Labels\"\n",
    "if \"df_local\" in locals() and not df_local.empty and \"golden_ids\" in locals():\n",
    "    # Filtra il DataFrame locale per escludere le righe con gli ID \"golden\"\n",
    "    df_without_golden = df_local[~df_local[\"utterance_id\"].isin(golden_ids)].copy()\n",
    "\n",
    "    # Rimuovi la colonna 'utterance_id' di supporto\n",
    "    df_without_golden.drop(columns=[\"utterance_id\"], inplace=True)\n",
    "\n",
    "    # Definisci il percorso del nuovo file CSV\n",
    "    # Prende il nome del file originale e aggiunge \"_without_golden\"\n",
    "    # original_path = \"../data/processed/asllrp_video_sentiment_data_0.34.csv\" # Vecchio path\n",
    "    original_path = \"../data/processed/asllrp_video_sentiment_data_with_neutral_0.5.csv\"  # Nuovo path con neutrali\n",
    "    base, ext = os.path.splitext(original_path)\n",
    "    output_path_without_golden = f\"{base}_without_golden{ext}\"\n",
    "\n",
    "    # Salva il nuovo DataFrame\n",
    "    df_without_golden.to_csv(output_path_without_golden, index=False)\n",
    "\n",
    "    print(\n",
    "        f\"\\nFile '{os.path.basename(output_path_without_golden)}' salvato con successo.\"\n",
    "    )\n",
    "    print(f\"Contiene {len(df_without_golden)} righe (righe originali - golden labels).\")\n",
    "    print(\n",
    "        f\"Righe originali: {len(df_local)}, Golden Labels: {len(golden_ids)}, Righe rimanenti: {len(df_without_golden)}\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"\\nImpossibile creare il file senza golden labels a causa di errori precedenti o dati mancanti.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab060c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
